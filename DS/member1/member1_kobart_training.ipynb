{"cells":[{"cell_type":"code","execution_count":null,"id":"3ed3dd74","metadata":{"id":"3ed3dd74"},"outputs":[],"source":["# 코랩 끊김 방지 코드\n","'''\n","function ClickConnect(){\n","\tconsole.log(\"Working\"); \n"," \tdocument.querySelector(\"colab-toolbar-button\").click() \n"," } setInterval(ClickConnect, 1800000)\n","'''"]},{"cell_type":"code","execution_count":null,"id":"9e0ce44a","metadata":{"id":"9e0ce44a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673921618073,"user_tz":-540,"elapsed":22284,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}},"outputId":"9b47f786-9843-4de0-b035-9d7fd6c9bccf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/gdrive')"]},{"cell_type":"code","source":["cd /gdrive/MyDrive/Colab_Notebooks/KoBART-summarization"],"metadata":{"id":"hfYNTPIyyCUp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673921621176,"user_tz":-540,"elapsed":269,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}},"outputId":"ff64ac52-395e-42f3-836c-6253bba5bdda"},"id":"hfYNTPIyyCUp","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization\n"]}]},{"cell_type":"code","source":["pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgOZ4pRfTiWa","executionInfo":{"status":"ok","timestamp":1673921704861,"user_tz":-540,"elapsed":79770,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}},"outputId":"55f55bc2-dd52-42ec-c9dc-7238fdf98f33"},"id":"rgOZ4pRfTiWa","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Collecting torch==1.10.0\n","  Downloading torch-1.10.0-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m877.4/881.9 MB\u001b[0m \u001b[31m170.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1102381056 bytes == 0x380d2000 @  0x7f1136cfc615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.8.2\n","  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-lightning==1.3.8\n","  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.4/813.4 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting streamlit==1.1.0\n","  Downloading streamlit-1.1.0-py2.py3-none-any.whl (8.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.0->-r requirements.txt (line 2)) (4.4.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (2.25.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (2022.6.2)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (3.9.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (6.0)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.3.tar.gz (840 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torchmetrics>=0.2.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2.9.1)\n","Collecting pyyaml\n","  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2022.11.0)\n","Collecting blinker\n","  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (4.2.0)\n","Collecting base58\n","  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (1.5.1)\n","Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (3.19.6)\n","Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (0.8.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (0.10.2)\n","Collecting validators\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (9.0.0)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (22.2.0)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (6.0.4)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (5.2.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (7.1.2)\n","Collecting watchdog\n","  Downloading watchdog-2.2.1-py3-none-manylinux2014_x86_64.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gitpython!=3.1.19\n","  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.7)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (0.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (2.11.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.8.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit==1.1.0->-r requirements.txt (line 5)) (1.15.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.4.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.51.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.38.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.3.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (57.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (4.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.8.2->-r requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators->streamlit==1.1.0->-r requirements.txt (line 5)) (4.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.3.3)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (2.0.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (5.10.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (0.19.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (6.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.2.2)\n","Building wheels for collected packages: future, sacremoses, validators\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492036 sha256=0c9978b803f76a1e3902925d30bef825725ee36a2fa5cbda19bc3cf18ad5b37b\n","  Stored in directory: /root/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0e0b74a16b3d7d91c34c022bd8e7413d0bbde2acc6a024e52adb44fcb06aa0bd\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19581 sha256=8ab5c20a78f224a524f37f36745e57720dd55a36b73c8dc4ad0c8a46db7dde7c\n","  Stored in directory: /root/.cache/pip/wheels/19/09/72/3eb74d236bb48bd0f3c6c3c83e4e0c5bbfcbcad7c6c3539db8\n","Successfully built future sacremoses validators\n","Installing collected packages: tokenizers, watchdog, validators, torch, smmap, sacremoses, pyyaml, pyDeprecate, future, blinker, base58, torchmetrics, pydeck, huggingface-hub, gitdb, transformers, gitpython, streamlit, pytorch-lightning\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.10.0 which is incompatible.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.0 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed base58-2.1.1 blinker-1.5 future-0.18.3 gitdb-4.0.10 gitpython-3.1.30 huggingface-hub-0.0.12 pyDeprecate-0.3.0 pydeck-0.8.0 pytorch-lightning-1.3.8 pyyaml-5.4.1 sacremoses-0.0.53 smmap-5.0.0 streamlit-1.1.0 tokenizers-0.10.3 torch-1.10.0 torchmetrics-0.11.0 transformers-4.8.2 validators-0.20.0 watchdog-2.2.1\n"]}]},{"cell_type":"code","source":["pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9AOEtUAQVC1C","executionInfo":{"status":"ok","timestamp":1673921836961,"user_tz":-540,"elapsed":80699,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}},"outputId":"fb92a82e-cd27-4fdd-e292-697bb17197a5"},"id":"9AOEtUAQVC1C","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.8.1+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1982177280 bytes == 0x236c000 @  0x7fd8b89341e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2477727744 bytes == 0x785c6000 @  0x7fd8b8935615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941\n","tcmalloc: large alloc 1982177280 bytes == 0x236c000 @  0x7fd8b89341e7 0x4d30a0 0x5dede2 0x6758aa 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4fe318 0x5da092 0x62042c 0x5d8d8c 0x561f80 0x4fd2db 0x4997c7 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m934.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.9.1+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.1+cu111) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.1+cu111) (4.4.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0\n","    Uninstalling torch-1.10.0:\n","      Successfully uninstalled torch-1.10.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.0+cu116\n","    Uninstalling torchvision-0.14.0+cu116:\n","      Successfully uninstalled torchvision-0.14.0+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.8.1+cu111 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.8.1+cu111 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.8.1+cu111 torchvision-0.9.1+cu111\n"]}]},{"cell_type":"code","source":["pip install torchmetrics==0.6.0 torchtext==0.9.1 pytorch_lightning==1.5.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkimVBidByxk","executionInfo":{"status":"ok","timestamp":1673921942710,"user_tz":-540,"elapsed":6607,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}},"outputId":"a762d481-746a-456e-af50-e123f0ff1ec3"},"id":"LkimVBidByxk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics==0.6.0\n","  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.4/329.4 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchtext==0.9.1\n","  Downloading torchtext-0.9.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch_lightning==1.5.2\n","  Downloading pytorch_lightning-1.5.2-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.6.0) (21.3)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.6.0) (1.8.1+cu111)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics==0.6.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.1) (2.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.1) (4.64.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.5.2) (2022.11.0)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.5.2) (0.18.3)\n","Collecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.5.2) (2.9.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.5.2) (4.4.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.5.2) (5.4.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (3.8.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics==0.6.0) (3.0.9)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (2.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.3.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.38.4)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.19.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.51.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.6.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.1) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.1) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.1) (4.0.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (22.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (6.0.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.15.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (5.2.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (6.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.2.2)\n","Installing collected packages: pyDeprecate, torchtext, torchmetrics, pytorch_lightning\n","  Attempting uninstall: pyDeprecate\n","    Found existing installation: pyDeprecate 0.3.0\n","    Uninstalling pyDeprecate-0.3.0:\n","      Successfully uninstalled pyDeprecate-0.3.0\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.14.0\n","    Uninstalling torchtext-0.14.0:\n","      Successfully uninstalled torchtext-0.14.0\n","  Attempting uninstall: torchmetrics\n","    Found existing installation: torchmetrics 0.11.0\n","    Uninstalling torchmetrics-0.11.0:\n","      Successfully uninstalled torchmetrics-0.11.0\n","  Attempting uninstall: pytorch_lightning\n","    Found existing installation: pytorch-lightning 1.3.8\n","    Uninstalling pytorch-lightning-1.3.8:\n","      Successfully uninstalled pytorch-lightning-1.3.8\n","Successfully installed pyDeprecate-0.3.1 pytorch_lightning-1.5.2 torchmetrics-0.6.0 torchtext-0.9.1\n"]}]},{"cell_type":"code","source":["# 모델 학습\n","# test를 먼저 실행한 후 튜닝을 하려 하면 위의 설치를 다시 할 것\n","\n","#GPU\n","# !python train.py --gradient_clip_val 1.0 --max_epochs 1 --default_root_dir logs --gpus 1 --batch_size 5 --num_workers 4 # baseline"],"metadata":{"id":"KPpFRYsinRwv"},"id":"KPpFRYsinRwv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --gradient_clip_val 1.0 --max_epochs 5 --default_root_dir logs --gpus 1 --batch_size 8 --num_workers 4 --lr 3e-5 --max_len 256\n","# 여기서 max_len은 문장당 글자의 수가 아니라, 문장을 쪼개어 얻은 토큰의 수라는 점에 유의\n","\n","'''\n","Epoch 0, global step 30450 : epoch=00-val_loss = 1.502\n","Epoch 1, global step 60901 : epoch=01-val_loss = 1.520\n","Epoch 2, global step 91352 : epoch=02-val_loss = 1.491\n","Epoch 3, global step 121803 : epoch=03-val_loss = ?? not in top 3\n","Epoch 4, global step 152254 : epoch=04-val_loss =1.516\n","'''"],"metadata":{"id":"R1z02FcYmyh_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23b6d60a-9b16-48b6-de13-76d68f0a7de7","executionInfo":{"status":"ok","timestamp":1673873406038,"user_tz":-540,"elapsed":1658360,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}}},"id":"R1z02FcYmyh_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-16 09:00:00.042281: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=8, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=None, checkpoint_path=None, default_root_dir='logs', detect_anomaly=False, deterministic=False, devices=None, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, flush_logs_every_n_steps=None, gpus=1, gradient_clip_algorithm=None, gradient_clip_val=1.0, ipus=None, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=3e-05, max_epochs=5, max_len=256, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, model_path=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=4, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=None, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, stochastic_weight_avg=False, strategy=None, sync_batchnorm=False, terminate_on_nan=None, test_file='data/test.tsv', tpu_cores=None, track_grad_norm=-1, train_file='data/train.tsv', val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Downloading: 100% 1.36k/1.36k [00:00<00:00, 1.22MB/s]\n","Downloading: 100% 496M/496M [00:08<00:00, 57.6MB/s]\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:root:number of workers 4, data length 30451\n","INFO:root:num_train_steps : 4757\n","INFO:root:num_warmup_steps : 475\n","\n","  | Name  | Type                         | Params\n","-------------------------------------------------------\n","0 | model | BartForConditionalGeneration | 123 M \n","-------------------------------------------------------\n","123 M     Trainable params\n","0         Non-trainable params\n","123 M     Total params\n","495.440   Total estimated model params size (MB)\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","Epoch 0:  89% 30452/34216 [43:57<05:26, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  89% 30454/34216 [43:57<05:25, 11.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30459/34216 [43:58<05:25, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30464/34216 [43:58<05:24, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30469/34216 [43:58<05:24, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30474/34216 [43:58<05:23, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30479/34216 [43:58<05:23, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30484/34216 [43:58<05:23, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30489/34216 [43:58<05:22, 11.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30494/34216 [43:58<05:22, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30499/34216 [43:58<05:21, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30504/34216 [43:59<05:21, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30509/34216 [43:59<05:20, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30514/34216 [43:59<05:20, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30519/34216 [43:59<05:19, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30524/34216 [43:59<05:19, 11.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30529/34216 [43:59<05:18, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30534/34216 [43:59<05:18, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30539/34216 [43:59<05:17, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30544/34216 [43:59<05:17, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30549/34216 [44:00<05:16, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30555/34216 [44:00<05:16, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30561/34216 [44:00<05:15, 11.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30567/34216 [44:00<05:15, 11.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30573/34216 [44:00<05:14, 11.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30579/34216 [44:00<05:14, 11.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30585/34216 [44:00<05:13, 11.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30591/34216 [44:00<05:12, 11.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30597/34216 [44:01<05:12, 11.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30603/34216 [44:01<05:11, 11.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30609/34216 [44:01<05:11, 11.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30615/34216 [44:01<05:10, 11.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  89% 30621/34216 [44:01<05:10, 11.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30627/34216 [44:01<05:09, 11.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30633/34216 [44:01<05:08, 11.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30639/34216 [44:01<05:08, 11.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30645/34216 [44:01<05:07, 11.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:   5% 194/3765 [00:04<01:13, 48.53it/s]\u001b[A\n","Epoch 0:  90% 30651/34216 [44:02<05:07, 11.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30657/34216 [44:02<05:06, 11.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30663/34216 [44:02<05:06, 11.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30669/34216 [44:02<05:05, 11.61it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30675/34216 [44:02<05:05, 11.61it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30681/34216 [44:02<05:04, 11.61it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30687/34216 [44:02<05:03, 11.61it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30693/34216 [44:02<05:03, 11.61it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30699/34216 [44:03<05:02, 11.61it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30705/34216 [44:03<05:02, 11.62it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:   7% 254/3765 [00:05<01:13, 47.58it/s]\u001b[A\n","Epoch 0:  90% 30711/34216 [44:03<05:01, 11.62it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30717/34216 [44:03<05:01, 11.62it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30723/34216 [44:03<05:00, 11.62it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30729/34216 [44:03<04:59, 11.62it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30735/34216 [44:03<04:59, 11.63it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30741/34216 [44:03<04:58, 11.63it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:   8% 290/3765 [00:06<01:11, 48.54it/s]\u001b[A\n","Epoch 0:  90% 30747/34216 [44:04<04:58, 11.63it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30753/34216 [44:04<04:57, 11.63it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30759/34216 [44:04<04:57, 11.63it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30765/34216 [44:04<04:56, 11.63it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30771/34216 [44:04<04:56, 11.64it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:   8% 320/3765 [00:06<01:13, 46.82it/s]\u001b[A\n","Epoch 0:  90% 30777/34216 [44:04<04:55, 11.64it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30783/34216 [44:04<04:54, 11.64it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30789/34216 [44:04<04:54, 11.64it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30795/34216 [44:05<04:53, 11.64it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30801/34216 [44:05<04:53, 11.64it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30807/34216 [44:05<04:52, 11.65it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30813/34216 [44:05<04:52, 11.65it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30819/34216 [44:05<04:51, 11.65it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30825/34216 [44:05<04:51, 11.65it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30831/34216 [44:05<04:50, 11.65it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30837/34216 [44:05<04:49, 11.65it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30843/34216 [44:06<04:49, 11.66it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30849/34216 [44:06<04:48, 11.66it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30855/34216 [44:06<04:48, 11.66it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30861/34216 [44:06<04:47, 11.66it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30867/34216 [44:06<04:47, 11.66it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30873/34216 [44:06<04:46, 11.66it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30879/34216 [44:06<04:46, 11.67it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30885/34216 [44:06<04:45, 11.67it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  12% 434/3765 [00:09<01:07, 49.65it/s]\u001b[A\n","Epoch 0:  90% 30891/34216 [44:07<04:44, 11.67it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30897/34216 [44:07<04:44, 11.67it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30903/34216 [44:07<04:43, 11.67it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30909/34216 [44:07<04:43, 11.68it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30915/34216 [44:07<04:42, 11.68it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30921/34216 [44:07<04:42, 11.68it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30927/34216 [44:07<04:41, 11.68it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30933/34216 [44:07<04:41, 11.68it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30939/34216 [44:07<04:40, 11.68it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30945/34216 [44:08<04:39, 11.69it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30951/34216 [44:08<04:39, 11.69it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30957/34216 [44:08<04:38, 11.69it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  90% 30963/34216 [44:08<04:38, 11.69it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 30969/34216 [44:08<04:37, 11.69it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 30975/34216 [44:08<04:37, 11.69it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 30981/34216 [44:08<04:36, 11.70it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 30987/34216 [44:08<04:36, 11.70it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 30993/34216 [44:09<04:35, 11.70it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 30999/34216 [44:09<04:34, 11.70it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31005/34216 [44:09<04:34, 11.70it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31011/34216 [44:09<04:33, 11.70it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31017/34216 [44:09<04:33, 11.71it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31023/34216 [44:09<04:32, 11.71it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31029/34216 [44:09<04:32, 11.71it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  15% 578/3765 [00:12<01:07, 47.39it/s]\u001b[A\n","Epoch 0:  91% 31035/34216 [44:09<04:31, 11.71it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31041/34216 [44:10<04:31, 11.71it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31047/34216 [44:10<04:30, 11.72it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31053/34216 [44:10<04:29, 11.72it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31059/34216 [44:10<04:29, 11.72it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  16% 608/3765 [00:12<01:04, 48.57it/s]\u001b[A\n","Epoch 0:  91% 31065/34216 [44:10<04:28, 11.72it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31071/34216 [44:10<04:28, 11.72it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31077/34216 [44:10<04:27, 11.72it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31083/34216 [44:10<04:27, 11.73it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31089/34216 [44:11<04:26, 11.73it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  17% 638/3765 [00:13<01:05, 48.04it/s]\u001b[A\n","Epoch 0:  91% 31095/34216 [44:11<04:26, 11.73it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31101/34216 [44:11<04:25, 11.73it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31107/34216 [44:11<04:24, 11.73it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31113/34216 [44:11<04:24, 11.73it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31119/34216 [44:11<04:23, 11.74it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31125/34216 [44:11<04:23, 11.74it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31131/34216 [44:11<04:22, 11.74it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31137/34216 [44:12<04:22, 11.74it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31143/34216 [44:12<04:21, 11.74it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31149/34216 [44:12<04:21, 11.74it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31155/34216 [44:12<04:20, 11.75it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31161/34216 [44:12<04:20, 11.75it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31167/34216 [44:12<04:19, 11.75it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31173/34216 [44:12<04:18, 11.75it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31179/34216 [44:12<04:18, 11.75it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31185/34216 [44:12<04:17, 11.75it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31191/34216 [44:13<04:17, 11.76it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31197/34216 [44:13<04:16, 11.76it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31203/34216 [44:13<04:16, 11.76it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31209/34216 [44:13<04:15, 11.76it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31215/34216 [44:13<04:15, 11.76it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31221/34216 [44:13<04:14, 11.77it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31227/34216 [44:13<04:14, 11.77it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31233/34216 [44:13<04:13, 11.77it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31239/34216 [44:14<04:12, 11.77it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31245/34216 [44:14<04:12, 11.77it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31251/34216 [44:14<04:11, 11.77it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31257/34216 [44:14<04:11, 11.78it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31263/34216 [44:14<04:10, 11.78it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31269/34216 [44:14<04:10, 11.78it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31275/34216 [44:14<04:09, 11.78it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31281/34216 [44:14<04:09, 11.78it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31287/34216 [44:14<04:08, 11.78it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31293/34216 [44:15<04:08, 11.79it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31299/34216 [44:15<04:07, 11.79it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  91% 31305/34216 [44:15<04:06, 11.79it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31311/34216 [44:15<04:06, 11.79it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31317/34216 [44:15<04:05, 11.79it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31323/34216 [44:15<04:05, 11.79it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31329/34216 [44:15<04:04, 11.80it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31335/34216 [44:15<04:04, 11.80it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31341/34216 [44:16<04:03, 11.80it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31347/34216 [44:16<04:03, 11.80it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31353/34216 [44:16<04:02, 11.80it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31359/34216 [44:16<04:02, 11.81it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31365/34216 [44:16<04:01, 11.81it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31371/34216 [44:16<04:00, 11.81it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31377/34216 [44:16<04:00, 11.81it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31383/34216 [44:16<03:59, 11.81it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31389/34216 [44:16<03:59, 11.81it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31395/34216 [44:17<03:58, 11.82it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31401/34216 [44:17<03:58, 11.82it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  25% 950/3765 [00:19<00:59, 47.46it/s]\u001b[A\n","Epoch 0:  92% 31407/34216 [44:17<03:57, 11.82it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31413/34216 [44:17<03:57, 11.82it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31419/34216 [44:17<03:56, 11.82it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31425/34216 [44:17<03:56, 11.82it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31431/34216 [44:17<03:55, 11.83it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31437/34216 [44:18<03:54, 11.83it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31443/34216 [44:18<03:54, 11.83it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  26% 992/3765 [00:20<01:02, 44.63it/s]\u001b[A\n","Epoch 0:  92% 31449/34216 [44:18<03:53, 11.83it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31455/34216 [44:18<03:53, 11.83it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31461/34216 [44:18<03:52, 11.83it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31467/34216 [44:18<03:52, 11.84it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31473/34216 [44:18<03:51, 11.84it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  27% 1022/3765 [00:21<01:00, 45.70it/s]\u001b[A\n","Epoch 0:  92% 31479/34216 [44:18<03:51, 11.84it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31485/34216 [44:19<03:50, 11.84it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31491/34216 [44:19<03:50, 11.84it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31497/34216 [44:19<03:49, 11.84it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31503/34216 [44:19<03:49, 11.85it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31509/34216 [44:19<03:48, 11.85it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31515/34216 [44:19<03:47, 11.85it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31521/34216 [44:19<03:47, 11.85it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  28% 1070/3765 [00:22<00:54, 49.68it/s]\u001b[A\n","Epoch 0:  92% 31527/34216 [44:19<03:46, 11.85it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31533/34216 [44:20<03:46, 11.85it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31539/34216 [44:20<03:45, 11.86it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31545/34216 [44:20<03:45, 11.86it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31551/34216 [44:20<03:44, 11.86it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31557/34216 [44:20<03:44, 11.86it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31563/34216 [44:20<03:43, 11.86it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31569/34216 [44:20<03:43, 11.86it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31575/34216 [44:20<03:42, 11.87it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31581/34216 [44:20<03:42, 11.87it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31587/34216 [44:21<03:41, 11.87it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31593/34216 [44:21<03:40, 11.87it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31599/34216 [44:21<03:40, 11.87it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31605/34216 [44:21<03:39, 11.88it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31611/34216 [44:21<03:39, 11.88it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31617/34216 [44:21<03:38, 11.88it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31623/34216 [44:21<03:38, 11.88it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31629/34216 [44:21<03:37, 11.88it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31635/34216 [44:22<03:37, 11.88it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31641/34216 [44:22<03:36, 11.89it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  92% 31647/34216 [44:22<03:36, 11.89it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31653/34216 [44:22<03:35, 11.89it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31659/34216 [44:22<03:35, 11.89it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31665/34216 [44:22<03:34, 11.89it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31671/34216 [44:22<03:33, 11.89it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31677/34216 [44:22<03:33, 11.90it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31683/34216 [44:23<03:32, 11.90it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31689/34216 [44:23<03:32, 11.90it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31695/34216 [44:23<03:31, 11.90it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31701/34216 [44:23<03:31, 11.90it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31707/34216 [44:23<03:30, 11.90it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31713/34216 [44:23<03:30, 11.91it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31719/34216 [44:23<03:29, 11.91it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31725/34216 [44:23<03:29, 11.91it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  34% 1274/3765 [00:26<00:50, 49.50it/s]\u001b[A\n","Epoch 0:  93% 31731/34216 [44:24<03:28, 11.91it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31737/34216 [44:24<03:28, 11.91it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31743/34216 [44:24<03:27, 11.91it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31749/34216 [44:24<03:27, 11.92it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31755/34216 [44:24<03:26, 11.92it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31761/34216 [44:24<03:25, 11.92it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31767/34216 [44:24<03:25, 11.92it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  35% 1316/3765 [00:27<00:50, 48.70it/s]\u001b[A\n","Epoch 0:  93% 31773/34216 [44:24<03:24, 11.92it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31779/34216 [44:25<03:24, 11.92it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31785/34216 [44:25<03:23, 11.93it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31791/34216 [44:25<03:23, 11.93it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31797/34216 [44:25<03:22, 11.93it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  36% 1346/3765 [00:27<00:50, 47.80it/s]\u001b[A\n","Epoch 0:  93% 31803/34216 [44:25<03:22, 11.93it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31809/34216 [44:25<03:21, 11.93it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31815/34216 [44:25<03:21, 11.93it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31821/34216 [44:25<03:20, 11.94it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31827/34216 [44:25<03:20, 11.94it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  37% 1376/3765 [00:28<00:49, 48.71it/s]\u001b[A\n","Epoch 0:  93% 31833/34216 [44:26<03:19, 11.94it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31839/34216 [44:26<03:19, 11.94it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31845/34216 [44:26<03:18, 11.94it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31851/34216 [44:26<03:17, 11.95it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31857/34216 [44:26<03:17, 11.95it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31863/34216 [44:26<03:16, 11.95it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31869/34216 [44:26<03:16, 11.95it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31875/34216 [44:26<03:15, 11.95it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31881/34216 [44:27<03:15, 11.95it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31887/34216 [44:27<03:14, 11.96it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31893/34216 [44:27<03:14, 11.96it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31899/34216 [44:27<03:13, 11.96it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31905/34216 [44:27<03:13, 11.96it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31911/34216 [44:27<03:12, 11.96it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31917/34216 [44:27<03:12, 11.96it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31923/34216 [44:27<03:11, 11.97it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31929/34216 [44:27<03:11, 11.97it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31935/34216 [44:28<03:10, 11.97it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31941/34216 [44:28<03:10, 11.97it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31947/34216 [44:28<03:09, 11.97it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31953/34216 [44:28<03:08, 11.97it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31959/34216 [44:28<03:08, 11.98it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31965/34216 [44:28<03:07, 11.98it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31971/34216 [44:28<03:07, 11.98it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31977/34216 [44:28<03:06, 11.98it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31983/34216 [44:29<03:06, 11.98it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  93% 31989/34216 [44:29<03:05, 11.98it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 31995/34216 [44:29<03:05, 11.99it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32001/34216 [44:29<03:04, 11.99it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32007/34216 [44:29<03:04, 11.99it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32013/34216 [44:29<03:03, 11.99it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32019/34216 [44:29<03:03, 11.99it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32025/34216 [44:29<03:02, 11.99it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32031/34216 [44:30<03:02, 12.00it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32037/34216 [44:30<03:01, 12.00it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32043/34216 [44:30<03:01, 12.00it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32049/34216 [44:30<03:00, 12.00it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32055/34216 [44:30<03:00, 12.00it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32061/34216 [44:30<02:59, 12.00it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32067/34216 [44:30<02:58, 12.01it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32073/34216 [44:30<02:58, 12.01it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32079/34216 [44:31<02:57, 12.01it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32085/34216 [44:31<02:57, 12.01it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32091/34216 [44:31<02:56, 12.01it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32097/34216 [44:31<02:56, 12.02it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32103/34216 [44:31<02:55, 12.02it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32109/34216 [44:31<02:55, 12.02it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32115/34216 [44:31<02:54, 12.02it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32121/34216 [44:31<02:54, 12.02it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32127/34216 [44:31<02:53, 12.02it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32133/34216 [44:32<02:53, 12.03it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32139/34216 [44:32<02:52, 12.03it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32145/34216 [44:32<02:52, 12.03it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32151/34216 [44:32<02:51, 12.03it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32157/34216 [44:32<02:51, 12.03it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32163/34216 [44:32<02:50, 12.03it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32169/34216 [44:32<02:50, 12.04it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32175/34216 [44:32<02:49, 12.04it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32181/34216 [44:32<02:49, 12.04it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32187/34216 [44:33<02:48, 12.04it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32193/34216 [44:33<02:47, 12.04it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32199/34216 [44:33<02:47, 12.04it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  46% 1748/3765 [00:35<00:40, 49.89it/s]\u001b[A\n","Epoch 0:  94% 32205/34216 [44:33<02:46, 12.05it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32211/34216 [44:33<02:46, 12.05it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32217/34216 [44:33<02:45, 12.05it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32223/34216 [44:33<02:45, 12.05it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32229/34216 [44:33<02:44, 12.05it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  47% 1778/3765 [00:36<00:40, 49.14it/s]\u001b[A\n","Epoch 0:  94% 32235/34216 [44:34<02:44, 12.05it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32241/34216 [44:34<02:43, 12.06it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32247/34216 [44:34<02:43, 12.06it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32253/34216 [44:34<02:42, 12.06it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32259/34216 [44:34<02:42, 12.06it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32265/34216 [44:34<02:41, 12.06it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  48% 1814/3765 [00:37<00:40, 47.60it/s]\u001b[A\n","Epoch 0:  94% 32271/34216 [44:34<02:41, 12.06it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32277/34216 [44:34<02:40, 12.07it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32283/34216 [44:35<02:40, 12.07it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32289/34216 [44:35<02:39, 12.07it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32295/34216 [44:35<02:39, 12.07it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  49% 1844/3765 [00:37<00:40, 47.98it/s]\u001b[A\n","Epoch 0:  94% 32301/34216 [44:35<02:38, 12.07it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32307/34216 [44:35<02:38, 12.07it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32313/34216 [44:35<02:37, 12.08it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32319/34216 [44:35<02:37, 12.08it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  94% 32325/34216 [44:35<02:36, 12.08it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  50% 1874/3765 [00:38<00:39, 48.03it/s]\u001b[A\n","Epoch 0:  94% 32331/34216 [44:36<02:36, 12.08it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32337/34216 [44:36<02:35, 12.08it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32343/34216 [44:36<02:34, 12.08it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32349/34216 [44:36<02:34, 12.09it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32355/34216 [44:36<02:33, 12.09it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  51% 1904/3765 [00:38<00:38, 47.97it/s]\u001b[A\n","Epoch 0:  95% 32361/34216 [44:36<02:33, 12.09it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32367/34216 [44:36<02:32, 12.09it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32373/34216 [44:36<02:32, 12.09it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32379/34216 [44:37<02:31, 12.09it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32385/34216 [44:37<02:31, 12.10it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  51% 1934/3765 [00:39<00:38, 47.86it/s]\u001b[A\n","Epoch 0:  95% 32391/34216 [44:37<02:30, 12.10it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32397/34216 [44:37<02:30, 12.10it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32403/34216 [44:37<02:29, 12.10it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32409/34216 [44:37<02:29, 12.10it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32415/34216 [44:37<02:28, 12.10it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32421/34216 [44:37<02:28, 12.11it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  52% 1970/3765 [00:40<00:37, 47.78it/s]\u001b[A\n","Epoch 0:  95% 32427/34216 [44:38<02:27, 12.11it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32433/34216 [44:38<02:27, 12.11it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32439/34216 [44:38<02:26, 12.11it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32445/34216 [44:38<02:26, 12.11it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32451/34216 [44:38<02:25, 12.11it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  53% 2000/3765 [00:40<00:37, 46.85it/s]\u001b[A\n","Epoch 0:  95% 32457/34216 [44:38<02:25, 12.12it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32463/34216 [44:38<02:24, 12.12it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32469/34216 [44:38<02:24, 12.12it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32475/34216 [44:39<02:23, 12.12it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32481/34216 [44:39<02:23, 12.12it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  54% 2030/3765 [00:41<00:36, 47.58it/s]\u001b[A\n","Epoch 0:  95% 32487/34216 [44:39<02:22, 12.12it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32493/34216 [44:39<02:22, 12.13it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32499/34216 [44:39<02:21, 12.13it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32505/34216 [44:39<02:21, 12.13it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32511/34216 [44:39<02:20, 12.13it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  55% 2060/3765 [00:42<00:35, 48.49it/s]\u001b[A\n","Epoch 0:  95% 32517/34216 [44:39<02:20, 12.13it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32523/34216 [44:40<02:19, 12.13it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32529/34216 [44:40<02:19, 12.14it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32535/34216 [44:40<02:18, 12.14it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32541/34216 [44:40<02:17, 12.14it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  56% 2090/3765 [00:42<00:34, 48.87it/s]\u001b[A\n","Epoch 0:  95% 32547/34216 [44:40<02:17, 12.14it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32553/34216 [44:40<02:16, 12.14it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32559/34216 [44:40<02:16, 12.15it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32565/34216 [44:40<02:15, 12.15it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32571/34216 [44:41<02:15, 12.15it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32577/34216 [44:41<02:14, 12.15it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32583/34216 [44:41<02:14, 12.15it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32589/34216 [44:41<02:13, 12.15it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  57% 2138/3765 [00:43<00:32, 49.80it/s]\u001b[A\n","Epoch 0:  95% 32595/34216 [44:41<02:13, 12.16it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32601/34216 [44:41<02:12, 12.16it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32607/34216 [44:41<02:12, 12.16it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32613/34216 [44:41<02:11, 12.16it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32619/34216 [44:42<02:11, 12.16it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  58% 2168/3765 [00:44<00:32, 49.19it/s]\u001b[A\n","Epoch 0:  95% 32625/34216 [44:42<02:10, 12.16it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32631/34216 [44:42<02:10, 12.17it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32637/34216 [44:42<02:09, 12.17it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32643/34216 [44:42<02:09, 12.17it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32649/34216 [44:42<02:08, 12.17it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32655/34216 [44:42<02:08, 12.17it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  59% 2204/3765 [00:45<00:31, 49.46it/s]\u001b[A\n","Epoch 0:  95% 32661/34216 [44:42<02:07, 12.17it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32667/34216 [44:43<02:07, 12.18it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  95% 32673/34216 [44:43<02:06, 12.18it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32679/34216 [44:43<02:06, 12.18it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32685/34216 [44:43<02:05, 12.18it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  59% 2234/3765 [00:45<00:31, 48.73it/s]\u001b[A\n","Epoch 0:  96% 32691/34216 [44:43<02:05, 12.18it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32697/34216 [44:43<02:04, 12.18it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32703/34216 [44:43<02:04, 12.19it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32709/34216 [44:43<02:03, 12.19it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32715/34216 [44:44<02:03, 12.19it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32721/34216 [44:44<02:02, 12.19it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32727/34216 [44:44<02:02, 12.19it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  60% 2276/3765 [00:46<00:29, 49.64it/s]\u001b[A\n","Epoch 0:  96% 32733/34216 [44:44<02:01, 12.19it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32739/34216 [44:44<02:01, 12.20it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32745/34216 [44:44<02:00, 12.20it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32751/34216 [44:44<02:00, 12.20it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32757/34216 [44:44<01:59, 12.20it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32763/34216 [44:44<01:59, 12.20it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32769/34216 [44:45<01:58, 12.20it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32775/34216 [44:45<01:58, 12.21it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  62% 2324/3765 [00:47<00:29, 49.46it/s]\u001b[A\n","Epoch 0:  96% 32781/34216 [44:45<01:57, 12.21it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32787/34216 [44:45<01:57, 12.21it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32793/34216 [44:45<01:56, 12.21it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32799/34216 [44:45<01:56, 12.21it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32805/34216 [44:45<01:55, 12.21it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32811/34216 [44:45<01:55, 12.22it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  63% 2360/3765 [00:48<00:28, 49.23it/s]\u001b[A\n","Epoch 0:  96% 32817/34216 [44:46<01:54, 12.22it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32823/34216 [44:46<01:54, 12.22it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32829/34216 [44:46<01:53, 12.22it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32835/34216 [44:46<01:52, 12.22it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32841/34216 [44:46<01:52, 12.22it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  63% 2390/3765 [00:48<00:28, 48.80it/s]\u001b[A\n","Epoch 0:  96% 32847/34216 [44:46<01:51, 12.23it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32853/34216 [44:46<01:51, 12.23it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32859/34216 [44:46<01:50, 12.23it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32865/34216 [44:47<01:50, 12.23it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32871/34216 [44:47<01:49, 12.23it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  64% 2420/3765 [00:49<00:28, 47.70it/s]\u001b[A\n","Epoch 0:  96% 32877/34216 [44:47<01:49, 12.23it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32883/34216 [44:47<01:48, 12.24it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32889/34216 [44:47<01:48, 12.24it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32895/34216 [44:47<01:47, 12.24it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32901/34216 [44:47<01:47, 12.24it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  65% 2450/3765 [00:50<00:28, 46.66it/s]\u001b[A\n","Epoch 0:  96% 32907/34216 [44:47<01:46, 12.24it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32913/34216 [44:48<01:46, 12.24it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32919/34216 [44:48<01:45, 12.25it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32925/34216 [44:48<01:45, 12.25it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32931/34216 [44:48<01:44, 12.25it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  66% 2480/3765 [00:50<00:29, 44.13it/s]\u001b[A\n","Epoch 0:  96% 32937/34216 [44:48<01:44, 12.25it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32943/34216 [44:48<01:43, 12.25it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32949/34216 [44:48<01:43, 12.25it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32955/34216 [44:49<01:42, 12.26it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32961/34216 [44:49<01:42, 12.26it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  67% 2510/3765 [00:51<00:27, 45.27it/s]\u001b[A\n","Epoch 0:  96% 32967/34216 [44:49<01:41, 12.26it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32973/34216 [44:49<01:41, 12.26it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32979/34216 [44:49<01:40, 12.26it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32985/34216 [44:49<01:40, 12.26it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 32991/34216 [44:49<01:39, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  67% 2540/3765 [00:52<00:27, 44.79it/s]\u001b[A\n","Epoch 0:  96% 32997/34216 [44:49<01:39, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 33003/34216 [44:50<01:38, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 33009/34216 [44:50<01:38, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  96% 33015/34216 [44:50<01:37, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33021/34216 [44:50<01:37, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  68% 2570/3765 [00:52<00:25, 46.17it/s]\u001b[A\n","Epoch 0:  97% 33027/34216 [44:50<01:36, 12.27it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33033/34216 [44:50<01:36, 12.28it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33039/34216 [44:50<01:35, 12.28it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33045/34216 [44:51<01:35, 12.28it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33051/34216 [44:51<01:34, 12.28it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  69% 2600/3765 [00:53<00:24, 47.91it/s]\u001b[A\n","Epoch 0:  97% 33057/34216 [44:51<01:34, 12.28it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33063/34216 [44:51<01:33, 12.28it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33069/34216 [44:51<01:33, 12.29it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33075/34216 [44:51<01:32, 12.29it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33081/34216 [44:51<01:32, 12.29it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  70% 2630/3765 [00:54<00:23, 48.85it/s]\u001b[A\n","Epoch 0:  97% 33087/34216 [44:51<01:31, 12.29it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33093/34216 [44:52<01:31, 12.29it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33099/34216 [44:52<01:30, 12.29it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33105/34216 [44:52<01:30, 12.30it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33111/34216 [44:52<01:29, 12.30it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33117/34216 [44:52<01:29, 12.30it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  71% 2666/3765 [00:54<00:22, 48.78it/s]\u001b[A\n","Epoch 0:  97% 33123/34216 [44:52<01:28, 12.30it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33129/34216 [44:52<01:28, 12.30it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33135/34216 [44:52<01:27, 12.30it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33141/34216 [44:52<01:27, 12.31it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33147/34216 [44:53<01:26, 12.31it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33153/34216 [44:53<01:26, 12.31it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33159/34216 [44:53<01:25, 12.31it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33165/34216 [44:53<01:25, 12.31it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33171/34216 [44:53<01:24, 12.31it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33177/34216 [44:53<01:24, 12.32it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33183/34216 [44:53<01:23, 12.32it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33189/34216 [44:53<01:23, 12.32it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33195/34216 [44:54<01:22, 12.32it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33201/34216 [44:54<01:22, 12.32it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33207/34216 [44:54<01:21, 12.32it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33213/34216 [44:54<01:21, 12.33it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  73% 2762/3765 [00:56<00:20, 49.33it/s]\u001b[A\n","Epoch 0:  97% 33219/34216 [44:54<01:20, 12.33it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33225/34216 [44:54<01:20, 12.33it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33231/34216 [44:54<01:19, 12.33it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33237/34216 [44:54<01:19, 12.33it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33243/34216 [44:55<01:18, 12.33it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33249/34216 [44:55<01:18, 12.34it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33255/34216 [44:55<01:17, 12.34it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33261/34216 [44:55<01:17, 12.34it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33267/34216 [44:55<01:16, 12.34it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33273/34216 [44:55<01:16, 12.34it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33279/34216 [44:55<01:15, 12.35it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33285/34216 [44:55<01:15, 12.35it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33291/34216 [44:55<01:14, 12.35it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33297/34216 [44:56<01:14, 12.35it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33303/34216 [44:56<01:13, 12.35it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33309/34216 [44:56<01:13, 12.35it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33315/34216 [44:56<01:12, 12.36it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33321/34216 [44:56<01:12, 12.36it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33327/34216 [44:56<01:11, 12.36it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33333/34216 [44:56<01:11, 12.36it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33339/34216 [44:56<01:10, 12.36it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33345/34216 [44:57<01:10, 12.36it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33351/34216 [44:57<01:09, 12.37it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  97% 33357/34216 [44:57<01:09, 12.37it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33363/34216 [44:57<01:08, 12.37it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33369/34216 [44:57<01:08, 12.37it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33375/34216 [44:57<01:07, 12.37it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33381/34216 [44:57<01:07, 12.37it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33387/34216 [44:57<01:06, 12.38it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33393/34216 [44:57<01:06, 12.38it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33399/34216 [44:58<01:06, 12.38it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33405/34216 [44:58<01:05, 12.38it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33411/34216 [44:58<01:05, 12.38it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33417/34216 [44:58<01:04, 12.38it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33423/34216 [44:58<01:04, 12.39it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33429/34216 [44:58<01:03, 12.39it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33435/34216 [44:58<01:03, 12.39it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33441/34216 [44:58<01:02, 12.39it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33447/34216 [44:59<01:02, 12.39it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33453/34216 [44:59<01:01, 12.39it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33459/34216 [44:59<01:01, 12.40it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33465/34216 [44:59<01:00, 12.40it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33471/34216 [44:59<01:00, 12.40it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33477/34216 [44:59<00:59, 12.40it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33483/34216 [44:59<00:59, 12.40it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33489/34216 [44:59<00:58, 12.40it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33495/34216 [44:59<00:58, 12.41it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33501/34216 [45:00<00:57, 12.41it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33507/34216 [45:00<00:57, 12.41it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33513/34216 [45:00<00:56, 12.41it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33519/34216 [45:00<00:56, 12.41it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33525/34216 [45:00<00:55, 12.41it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33531/34216 [45:00<00:55, 12.42it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33537/34216 [45:00<00:54, 12.42it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33543/34216 [45:00<00:54, 12.42it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33549/34216 [45:01<00:53, 12.42it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33555/34216 [45:01<00:53, 12.42it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33561/34216 [45:01<00:52, 12.42it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33567/34216 [45:01<00:52, 12.43it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33573/34216 [45:01<00:51, 12.43it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33579/34216 [45:01<00:51, 12.43it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33585/34216 [45:01<00:50, 12.43it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33591/34216 [45:01<00:50, 12.43it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33597/34216 [45:02<00:49, 12.43it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33603/34216 [45:02<00:49, 12.44it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33609/34216 [45:02<00:48, 12.44it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33615/34216 [45:02<00:48, 12.44it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33621/34216 [45:02<00:47, 12.44it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33627/34216 [45:02<00:47, 12.44it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33633/34216 [45:02<00:46, 12.44it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33639/34216 [45:02<00:46, 12.45it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33645/34216 [45:02<00:45, 12.45it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33651/34216 [45:03<00:45, 12.45it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33657/34216 [45:03<00:44, 12.45it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  85% 3206/3765 [01:05<00:11, 49.10it/s]\u001b[A\n","Epoch 0:  98% 33663/34216 [45:03<00:44, 12.45it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33669/34216 [45:03<00:43, 12.45it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33675/34216 [45:03<00:43, 12.46it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33681/34216 [45:03<00:42, 12.46it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33687/34216 [45:03<00:42, 12.46it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  86% 3236/3765 [01:06<00:10, 49.00it/s]\u001b[A\n","Epoch 0:  98% 33693/34216 [45:03<00:41, 12.46it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  98% 33699/34216 [45:04<00:41, 12.46it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33705/34216 [45:04<00:40, 12.46it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33711/34216 [45:04<00:40, 12.47it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33717/34216 [45:04<00:40, 12.47it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  87% 3266/3765 [01:06<00:10, 48.70it/s]\u001b[A\n","Epoch 0:  99% 33723/34216 [45:04<00:39, 12.47it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33729/34216 [45:04<00:39, 12.47it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33735/34216 [45:04<00:38, 12.47it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33741/34216 [45:04<00:38, 12.47it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33747/34216 [45:05<00:37, 12.48it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  88% 3296/3765 [01:07<00:09, 48.65it/s]\u001b[A\n","Epoch 0:  99% 33753/34216 [45:05<00:37, 12.48it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33759/34216 [45:05<00:36, 12.48it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33765/34216 [45:05<00:36, 12.48it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33771/34216 [45:05<00:35, 12.48it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33777/34216 [45:05<00:35, 12.48it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33783/34216 [45:05<00:34, 12.49it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33789/34216 [45:05<00:34, 12.49it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33795/34216 [45:06<00:33, 12.49it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  89% 3344/3765 [01:08<00:08, 49.32it/s]\u001b[A\n","Epoch 0:  99% 33801/34216 [45:06<00:33, 12.49it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33807/34216 [45:06<00:32, 12.49it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33813/34216 [45:06<00:32, 12.49it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33819/34216 [45:06<00:31, 12.50it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33825/34216 [45:06<00:31, 12.50it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33831/34216 [45:06<00:30, 12.50it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33837/34216 [45:06<00:30, 12.50it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33843/34216 [45:07<00:29, 12.50it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33849/34216 [45:07<00:29, 12.50it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33855/34216 [45:07<00:28, 12.51it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33861/34216 [45:07<00:28, 12.51it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33867/34216 [45:07<00:27, 12.51it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33873/34216 [45:07<00:27, 12.51it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  91% 3422/3765 [01:09<00:06, 49.47it/s]\u001b[A\n","Epoch 0:  99% 33879/34216 [45:07<00:26, 12.51it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33885/34216 [45:07<00:26, 12.51it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33891/34216 [45:07<00:25, 12.52it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33897/34216 [45:08<00:25, 12.52it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33903/34216 [45:08<00:25, 12.52it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33909/34216 [45:08<00:24, 12.52it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33915/34216 [45:08<00:24, 12.52it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33921/34216 [45:08<00:23, 12.52it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  92% 3470/3765 [01:10<00:05, 49.31it/s]\u001b[A\n","Epoch 0:  99% 33927/34216 [45:08<00:23, 12.53it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33933/34216 [45:08<00:22, 12.53it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33939/34216 [45:08<00:22, 12.53it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33945/34216 [45:09<00:21, 12.53it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33951/34216 [45:09<00:21, 12.53it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33957/34216 [45:09<00:20, 12.53it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  93% 3506/3765 [01:11<00:05, 48.70it/s]\u001b[A\n","Epoch 0:  99% 33963/34216 [45:09<00:20, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33969/34216 [45:09<00:19, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33975/34216 [45:09<00:19, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33981/34216 [45:09<00:18, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33987/34216 [45:09<00:18, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  94% 3536/3765 [01:12<00:04, 49.36it/s]\u001b[A\n","Epoch 0:  99% 33993/34216 [45:10<00:17, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 33999/34216 [45:10<00:17, 12.54it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 34005/34216 [45:10<00:16, 12.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 34011/34216 [45:10<00:16, 12.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 34017/34216 [45:10<00:15, 12.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  95% 3566/3765 [01:12<00:04, 49.13it/s]\u001b[A\n","Epoch 0:  99% 34023/34216 [45:10<00:15, 12.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 34029/34216 [45:10<00:14, 12.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 34035/34216 [45:10<00:14, 12.55it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0:  99% 34041/34216 [45:11<00:13, 12.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34047/34216 [45:11<00:13, 12.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating:  96% 3596/3765 [01:13<00:03, 47.60it/s]\u001b[A\n","Epoch 0: 100% 34053/34216 [45:11<00:12, 12.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34059/34216 [45:11<00:12, 12.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34065/34216 [45:11<00:12, 12.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34071/34216 [45:11<00:11, 12.56it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34077/34216 [45:11<00:11, 12.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34083/34216 [45:11<00:10, 12.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34089/34216 [45:12<00:10, 12.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34095/34216 [45:12<00:09, 12.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34101/34216 [45:12<00:09, 12.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34107/34216 [45:12<00:08, 12.57it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34113/34216 [45:12<00:08, 12.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34119/34216 [45:12<00:07, 12.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34125/34216 [45:12<00:07, 12.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34131/34216 [45:12<00:06, 12.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34137/34216 [45:12<00:06, 12.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34143/34216 [45:13<00:05, 12.58it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34149/34216 [45:13<00:05, 12.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34155/34216 [45:13<00:04, 12.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34161/34216 [45:13<00:04, 12.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34167/34216 [45:13<00:03, 12.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34173/34216 [45:13<00:03, 12.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34179/34216 [45:13<00:02, 12.59it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34185/34216 [45:13<00:02, 12.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34191/34216 [45:14<00:01, 12.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34197/34216 [45:14<00:01, 12.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34203/34216 [45:14<00:01, 12.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Validating: 100% 3752/3765 [01:16<00:00, 49.56it/s]\u001b[A\n","Epoch 0: 100% 34209/34216 [45:14<00:00, 12.60it/s, loss=1.57, v_num=4, train_loss=2.380]\n","Epoch 0: 100% 34216/34216 [45:14<00:00, 12.60it/s, loss=1.57, v_num=4, train_loss=2.380, val_loss=1.500]\n","                                                   \u001b[AEpoch 0, global step 30450: val_loss reached 1.50220 (best 1.50220), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=00-val_loss=1.502.ckpt\" as top 3\n","tcmalloc: large alloc 1095270400 bytes == 0x1744ea000 @  0x7f5b09540615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f5ade98d734 0x7f5ade9f8389 0x7f5a6d099665 0x7f5a6d095bca 0x7f5a6d09a079 0x7f5ade9f8922 0x7f5ade63ecae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 1369088000 bytes == 0x7f56e8656000 @  0x7f5b09540615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f5ade98d734 0x7f5ade9f8389 0x7f5a6d099665 0x7f5a6d095bca 0x7f5a6d09a079 0x7f5ade9f8922 0x7f5ade63ecae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 1711366144 bytes == 0x14014a000 @  0x7f5b09540615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f5ade98d734 0x7f5ade9f8389 0x7f5a6d099665 0x7f5a6d095bca 0x7f5a6d09a079 0x7f5ade9f8922 0x7f5ade63ecae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 1711366144 bytes == 0x7f5682640000 @  0x7f5b09540615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f5ade98d734 0x7f5ade9f8389 0x7f5a6d099665 0x7f5a6d095bca 0x7f5a6d09a079 0x7f5ade9f8922 0x7f5ade63ecae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","Epoch 1:  89% 30451/34216 [43:59<05:26, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  89% 30453/34216 [44:00<05:26, 11.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30458/34216 [44:00<05:25, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30463/34216 [44:00<05:25, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30468/34216 [44:00<05:24, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30473/34216 [44:00<05:24, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30478/34216 [44:00<05:23, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30483/34216 [44:00<05:23, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30488/34216 [44:01<05:22, 11.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30493/34216 [44:01<05:22, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30498/34216 [44:01<05:21, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30503/34216 [44:01<05:21, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30508/34216 [44:01<05:21, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30513/34216 [44:01<05:20, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30518/34216 [44:01<05:20, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30523/34216 [44:01<05:19, 11.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30528/34216 [44:01<05:19, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30533/34216 [44:02<05:18, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30538/34216 [44:02<05:18, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30543/34216 [44:02<05:17, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30548/34216 [44:02<05:17, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30554/34216 [44:02<05:16, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30560/34216 [44:02<05:16, 11.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30566/34216 [44:02<05:15, 11.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30572/34216 [44:02<05:15, 11.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30578/34216 [44:02<05:14, 11.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30584/34216 [44:03<05:13, 11.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30590/34216 [44:03<05:13, 11.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30596/34216 [44:03<05:12, 11.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30602/34216 [44:03<05:12, 11.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30608/34216 [44:03<05:11, 11.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30614/34216 [44:03<05:11, 11.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  89% 30620/34216 [44:03<05:10, 11.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:   4% 169/3765 [00:04<01:12, 49.75it/s]\u001b[A\n","Epoch 1:  90% 30626/34216 [44:03<05:09, 11.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30632/34216 [44:04<05:09, 11.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30638/34216 [44:04<05:08, 11.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30644/34216 [44:04<05:08, 11.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30650/34216 [44:04<05:07, 11.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:   5% 199/3765 [00:04<01:13, 48.82it/s]\u001b[A\n","Epoch 1:  90% 30656/34216 [44:04<05:07, 11.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30662/34216 [44:04<05:06, 11.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30668/34216 [44:04<05:05, 11.60it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30674/34216 [44:04<05:05, 11.60it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30680/34216 [44:05<05:04, 11.60it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:   6% 229/3765 [00:05<01:11, 49.27it/s]\u001b[A\n","Epoch 1:  90% 30686/34216 [44:05<05:04, 11.60it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30692/34216 [44:05<05:03, 11.60it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30698/34216 [44:05<05:03, 11.60it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30704/34216 [44:05<05:02, 11.61it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30710/34216 [44:05<05:02, 11.61it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30716/34216 [44:05<05:01, 11.61it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30722/34216 [44:05<05:00, 11.61it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30728/34216 [44:06<05:00, 11.61it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30734/34216 [44:06<04:59, 11.61it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30740/34216 [44:06<04:59, 11.62it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30746/34216 [44:06<04:58, 11.62it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30752/34216 [44:06<04:58, 11.62it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30758/34216 [44:06<04:57, 11.62it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:   8% 307/3765 [00:06<01:10, 49.27it/s]\u001b[A\n","Epoch 1:  90% 30764/34216 [44:06<04:56, 11.62it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30770/34216 [44:06<04:56, 11.63it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30776/34216 [44:06<04:55, 11.63it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30782/34216 [44:07<04:55, 11.63it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30788/34216 [44:07<04:54, 11.63it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30794/34216 [44:07<04:54, 11.63it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30800/34216 [44:07<04:53, 11.63it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30806/34216 [44:07<04:53, 11.64it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30812/34216 [44:07<04:52, 11.64it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30818/34216 [44:07<04:51, 11.64it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30824/34216 [44:07<04:51, 11.64it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30830/34216 [44:08<04:50, 11.64it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30836/34216 [44:08<04:50, 11.64it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30842/34216 [44:08<04:49, 11.65it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  10% 391/3765 [00:08<01:07, 49.94it/s]\u001b[A\n","Epoch 1:  90% 30848/34216 [44:08<04:49, 11.65it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30854/34216 [44:08<04:48, 11.65it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30860/34216 [44:08<04:48, 11.65it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30866/34216 [44:08<04:47, 11.65it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30872/34216 [44:08<04:46, 11.65it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  11% 421/3765 [00:09<01:08, 49.06it/s]\u001b[A\n","Epoch 1:  90% 30878/34216 [44:09<04:46, 11.66it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30884/34216 [44:09<04:45, 11.66it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30890/34216 [44:09<04:45, 11.66it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30896/34216 [44:09<04:44, 11.66it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30902/34216 [44:09<04:44, 11.66it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  12% 451/3765 [00:09<01:07, 49.13it/s]\u001b[A\n","Epoch 1:  90% 30908/34216 [44:09<04:43, 11.66it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30914/34216 [44:09<04:43, 11.67it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30920/34216 [44:09<04:42, 11.67it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30926/34216 [44:10<04:41, 11.67it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30932/34216 [44:10<04:41, 11.67it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30938/34216 [44:10<04:40, 11.67it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30944/34216 [44:10<04:40, 11.68it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30950/34216 [44:10<04:39, 11.68it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30956/34216 [44:10<04:39, 11.68it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  90% 30962/34216 [44:10<04:38, 11.68it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 30968/34216 [44:10<04:38, 11.68it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 30974/34216 [44:10<04:37, 11.68it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 30980/34216 [44:11<04:36, 11.69it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 30986/34216 [44:11<04:36, 11.69it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 30992/34216 [44:11<04:35, 11.69it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 30998/34216 [44:11<04:35, 11.69it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31004/34216 [44:11<04:34, 11.69it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31010/34216 [44:11<04:34, 11.69it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31016/34216 [44:11<04:33, 11.70it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31022/34216 [44:11<04:33, 11.70it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31028/34216 [44:12<04:32, 11.70it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31034/34216 [44:12<04:31, 11.70it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31040/34216 [44:12<04:31, 11.70it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31046/34216 [44:12<04:30, 11.70it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  16% 595/3765 [00:12<01:03, 49.95it/s]\u001b[A\n","Epoch 1:  91% 31052/34216 [44:12<04:30, 11.71it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31058/34216 [44:12<04:29, 11.71it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31064/34216 [44:12<04:29, 11.71it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31070/34216 [44:12<04:28, 11.71it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31076/34216 [44:13<04:28, 11.71it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31082/34216 [44:13<04:27, 11.72it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31088/34216 [44:13<04:26, 11.72it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31094/34216 [44:13<04:26, 11.72it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31100/34216 [44:13<04:25, 11.72it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31106/34216 [44:13<04:25, 11.72it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31112/34216 [44:13<04:24, 11.72it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31118/34216 [44:13<04:24, 11.73it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31124/34216 [44:13<04:23, 11.73it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31130/34216 [44:14<04:23, 11.73it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31136/34216 [44:14<04:22, 11.73it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31142/34216 [44:14<04:22, 11.73it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31148/34216 [44:14<04:21, 11.73it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31154/34216 [44:14<04:20, 11.74it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31160/34216 [44:14<04:20, 11.74it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31166/34216 [44:14<04:19, 11.74it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31172/34216 [44:14<04:19, 11.74it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31178/34216 [44:15<04:18, 11.74it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  19% 727/3765 [00:15<01:00, 49.87it/s]\u001b[A\n","Epoch 1:  91% 31184/34216 [44:15<04:18, 11.74it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31190/34216 [44:15<04:17, 11.75it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31196/34216 [44:15<04:17, 11.75it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31202/34216 [44:15<04:16, 11.75it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31208/34216 [44:15<04:15, 11.75it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31214/34216 [44:15<04:15, 11.75it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  20% 763/3765 [00:15<01:01, 49.04it/s]\u001b[A\n","Epoch 1:  91% 31220/34216 [44:15<04:14, 11.75it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31226/34216 [44:16<04:14, 11.76it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31232/34216 [44:16<04:13, 11.76it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31238/34216 [44:16<04:13, 11.76it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31244/34216 [44:16<04:12, 11.76it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31250/34216 [44:16<04:12, 11.76it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31256/34216 [44:16<04:11, 11.77it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31262/34216 [44:16<04:11, 11.77it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31268/34216 [44:16<04:10, 11.77it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31274/34216 [44:16<04:09, 11.77it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31280/34216 [44:17<04:09, 11.77it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31286/34216 [44:17<04:08, 11.77it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31292/34216 [44:17<04:08, 11.78it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31298/34216 [44:17<04:07, 11.78it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  91% 31304/34216 [44:17<04:07, 11.78it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31310/34216 [44:17<04:06, 11.78it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31316/34216 [44:17<04:06, 11.78it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31322/34216 [44:17<04:05, 11.78it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  23% 871/3765 [00:18<00:58, 49.09it/s]\u001b[A\n","Epoch 1:  92% 31328/34216 [44:18<04:05, 11.79it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31334/34216 [44:18<04:04, 11.79it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31340/34216 [44:18<04:03, 11.79it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31346/34216 [44:18<04:03, 11.79it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31352/34216 [44:18<04:02, 11.79it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31358/34216 [44:18<04:02, 11.79it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31364/34216 [44:18<04:01, 11.80it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31370/34216 [44:18<04:01, 11.80it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  24% 919/3765 [00:19<00:57, 49.30it/s]\u001b[A\n","Epoch 1:  92% 31376/34216 [44:19<04:00, 11.80it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31382/34216 [44:19<04:00, 11.80it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31388/34216 [44:19<03:59, 11.80it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31394/34216 [44:19<03:59, 11.80it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31400/34216 [44:19<03:58, 11.81it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31406/34216 [44:19<03:57, 11.81it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31412/34216 [44:19<03:57, 11.81it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31418/34216 [44:19<03:56, 11.81it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31424/34216 [44:19<03:56, 11.81it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31430/34216 [44:20<03:55, 11.82it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31436/34216 [44:20<03:55, 11.82it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31442/34216 [44:20<03:54, 11.82it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31448/34216 [44:20<03:54, 11.82it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31454/34216 [44:20<03:53, 11.82it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31460/34216 [44:20<03:53, 11.82it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31466/34216 [44:20<03:52, 11.83it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31472/34216 [44:20<03:52, 11.83it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31478/34216 [44:21<03:51, 11.83it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31484/34216 [44:21<03:50, 11.83it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31490/34216 [44:21<03:50, 11.83it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31496/34216 [44:21<03:49, 11.83it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31502/34216 [44:21<03:49, 11.84it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31508/34216 [44:21<03:48, 11.84it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31514/34216 [44:21<03:48, 11.84it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31520/34216 [44:21<03:47, 11.84it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31526/34216 [44:22<03:47, 11.84it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31532/34216 [44:22<03:46, 11.84it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31538/34216 [44:22<03:46, 11.85it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31544/34216 [44:22<03:45, 11.85it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31550/34216 [44:22<03:44, 11.85it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31556/34216 [44:22<03:44, 11.85it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31562/34216 [44:22<03:43, 11.85it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31568/34216 [44:22<03:43, 11.85it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31574/34216 [44:22<03:42, 11.86it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31580/34216 [44:23<03:42, 11.86it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31586/34216 [44:23<03:41, 11.86it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31592/34216 [44:23<03:41, 11.86it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31598/34216 [44:23<03:40, 11.86it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31604/34216 [44:23<03:40, 11.87it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31610/34216 [44:23<03:39, 11.87it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31616/34216 [44:23<03:39, 11.87it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31622/34216 [44:23<03:38, 11.87it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31628/34216 [44:24<03:37, 11.87it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31634/34216 [44:24<03:37, 11.87it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31640/34216 [44:24<03:36, 11.88it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  92% 31646/34216 [44:24<03:36, 11.88it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31652/34216 [44:24<03:35, 11.88it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  32% 1201/3765 [00:24<00:51, 49.77it/s]\u001b[A\n","Epoch 1:  93% 31658/34216 [44:24<03:35, 11.88it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31664/34216 [44:24<03:34, 11.88it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31670/34216 [44:24<03:34, 11.88it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31676/34216 [44:25<03:33, 11.89it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31682/34216 [44:25<03:33, 11.89it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  33% 1231/3765 [00:25<00:52, 48.45it/s]\u001b[A\n","Epoch 1:  93% 31688/34216 [44:25<03:32, 11.89it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31694/34216 [44:25<03:32, 11.89it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31700/34216 [44:25<03:31, 11.89it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31706/34216 [44:25<03:31, 11.89it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31712/34216 [44:25<03:30, 11.90it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  33% 1261/3765 [00:25<00:51, 48.45it/s]\u001b[A\n","Epoch 1:  93% 31718/34216 [44:25<03:29, 11.90it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31724/34216 [44:26<03:29, 11.90it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31730/34216 [44:26<03:28, 11.90it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31736/34216 [44:26<03:28, 11.90it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31742/34216 [44:26<03:27, 11.90it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  34% 1291/3765 [00:26<00:51, 48.50it/s]\u001b[A\n","Epoch 1:  93% 31748/34216 [44:26<03:27, 11.91it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31754/34216 [44:26<03:26, 11.91it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31760/34216 [44:26<03:26, 11.91it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31766/34216 [44:26<03:25, 11.91it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31772/34216 [44:27<03:25, 11.91it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  35% 1321/3765 [00:27<00:50, 48.49it/s]\u001b[A\n","Epoch 1:  93% 31778/34216 [44:27<03:24, 11.91it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31784/34216 [44:27<03:24, 11.92it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31790/34216 [44:27<03:23, 11.92it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31796/34216 [44:27<03:23, 11.92it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31802/34216 [44:27<03:22, 11.92it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31808/34216 [44:27<03:21, 11.92it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31814/34216 [44:27<03:21, 11.92it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31820/34216 [44:27<03:20, 11.93it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31826/34216 [44:28<03:20, 11.93it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31832/34216 [44:28<03:19, 11.93it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31838/34216 [44:28<03:19, 11.93it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31844/34216 [44:28<03:18, 11.93it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31850/34216 [44:28<03:18, 11.94it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31856/34216 [44:28<03:17, 11.94it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31862/34216 [44:28<03:17, 11.94it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31868/34216 [44:28<03:16, 11.94it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31874/34216 [44:29<03:16, 11.94it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31880/34216 [44:29<03:15, 11.94it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31886/34216 [44:29<03:15, 11.95it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  38% 1435/3765 [00:29<00:46, 49.83it/s]\u001b[A\n","Epoch 1:  93% 31892/34216 [44:29<03:14, 11.95it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31898/34216 [44:29<03:13, 11.95it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31904/34216 [44:29<03:13, 11.95it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31910/34216 [44:29<03:12, 11.95it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31916/34216 [44:29<03:12, 11.95it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31922/34216 [44:30<03:11, 11.96it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  39% 1471/3765 [00:30<00:46, 48.89it/s]\u001b[A\n","Epoch 1:  93% 31928/34216 [44:30<03:11, 11.96it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31934/34216 [44:30<03:10, 11.96it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31940/34216 [44:30<03:10, 11.96it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31946/34216 [44:30<03:09, 11.96it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31952/34216 [44:30<03:09, 11.96it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  40% 1501/3765 [00:30<00:46, 49.16it/s]\u001b[A\n","Epoch 1:  93% 31958/34216 [44:30<03:08, 11.97it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31964/34216 [44:30<03:08, 11.97it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31970/34216 [44:31<03:07, 11.97it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31976/34216 [44:31<03:07, 11.97it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31982/34216 [44:31<03:06, 11.97it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  93% 31988/34216 [44:31<03:06, 11.97it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 31994/34216 [44:31<03:05, 11.98it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32000/34216 [44:31<03:05, 11.98it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32006/34216 [44:31<03:04, 11.98it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32012/34216 [44:31<03:03, 11.98it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  41% 1561/3765 [00:32<00:44, 49.74it/s]\u001b[A\n","Epoch 1:  94% 32018/34216 [44:31<03:03, 11.98it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32024/34216 [44:32<03:02, 11.98it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32030/34216 [44:32<03:02, 11.99it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32036/34216 [44:32<03:01, 11.99it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32042/34216 [44:32<03:01, 11.99it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32048/34216 [44:32<03:00, 11.99it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  42% 1597/3765 [00:32<00:43, 49.52it/s]\u001b[A\n","Epoch 1:  94% 32054/34216 [44:32<03:00, 11.99it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32060/34216 [44:32<02:59, 11.99it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32066/34216 [44:32<02:59, 12.00it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32072/34216 [44:33<02:58, 12.00it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32078/34216 [44:33<02:58, 12.00it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  43% 1627/3765 [00:33<00:43, 48.69it/s]\u001b[A\n","Epoch 1:  94% 32084/34216 [44:33<02:57, 12.00it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32090/34216 [44:33<02:57, 12.00it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32096/34216 [44:33<02:56, 12.00it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32102/34216 [44:33<02:56, 12.01it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32108/34216 [44:33<02:55, 12.01it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  44% 1657/3765 [00:34<00:44, 47.65it/s]\u001b[A\n","Epoch 1:  94% 32114/34216 [44:33<02:55, 12.01it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32120/34216 [44:34<02:54, 12.01it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32126/34216 [44:34<02:53, 12.01it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32132/34216 [44:34<02:53, 12.01it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32138/34216 [44:34<02:52, 12.02it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  45% 1687/3765 [00:34<00:42, 48.76it/s]\u001b[A\n","Epoch 1:  94% 32144/34216 [44:34<02:52, 12.02it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32150/34216 [44:34<02:51, 12.02it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32156/34216 [44:34<02:51, 12.02it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32162/34216 [44:34<02:50, 12.02it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32168/34216 [44:35<02:50, 12.03it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  46% 1717/3765 [00:35<00:41, 49.20it/s]\u001b[A\n","Epoch 1:  94% 32174/34216 [44:35<02:49, 12.03it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32180/34216 [44:35<02:49, 12.03it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32186/34216 [44:35<02:48, 12.03it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32192/34216 [44:35<02:48, 12.03it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32198/34216 [44:35<02:47, 12.03it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  46% 1747/3765 [00:35<00:40, 49.26it/s]\u001b[A\n","Epoch 1:  94% 32204/34216 [44:35<02:47, 12.04it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32210/34216 [44:35<02:46, 12.04it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32216/34216 [44:36<02:46, 12.04it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32222/34216 [44:36<02:45, 12.04it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32228/34216 [44:36<02:45, 12.04it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32234/34216 [44:36<02:44, 12.04it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32240/34216 [44:36<02:44, 12.05it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32246/34216 [44:36<02:43, 12.05it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32252/34216 [44:36<02:43, 12.05it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32258/34216 [44:36<02:42, 12.05it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  48% 1807/3765 [00:37<00:39, 49.16it/s]\u001b[A\n","Epoch 1:  94% 32264/34216 [44:37<02:41, 12.05it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32270/34216 [44:37<02:41, 12.05it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32276/34216 [44:37<02:40, 12.06it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32282/34216 [44:37<02:40, 12.06it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32288/34216 [44:37<02:39, 12.06it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  49% 1837/3765 [00:37<00:39, 49.18it/s]\u001b[A\n","Epoch 1:  94% 32294/34216 [44:37<02:39, 12.06it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32300/34216 [44:37<02:38, 12.06it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32306/34216 [44:37<02:38, 12.06it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32312/34216 [44:38<02:37, 12.07it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32318/34216 [44:38<02:37, 12.07it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  50% 1867/3765 [00:38<00:39, 48.06it/s]\u001b[A\n","Epoch 1:  94% 32324/34216 [44:38<02:36, 12.07it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  94% 32330/34216 [44:38<02:36, 12.07it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32336/34216 [44:38<02:35, 12.07it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32342/34216 [44:38<02:35, 12.07it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32348/34216 [44:38<02:34, 12.08it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  50% 1897/3765 [00:38<00:38, 49.08it/s]\u001b[A\n","Epoch 1:  95% 32354/34216 [44:38<02:34, 12.08it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32360/34216 [44:38<02:33, 12.08it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32366/34216 [44:39<02:33, 12.08it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32372/34216 [44:39<02:32, 12.08it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32378/34216 [44:39<02:32, 12.08it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32384/34216 [44:39<02:31, 12.09it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  51% 1933/3765 [00:39<00:36, 49.53it/s]\u001b[A\n","Epoch 1:  95% 32390/34216 [44:39<02:31, 12.09it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32396/34216 [44:39<02:30, 12.09it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32402/34216 [44:39<02:30, 12.09it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32408/34216 [44:39<02:29, 12.09it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32414/34216 [44:40<02:28, 12.09it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32420/34216 [44:40<02:28, 12.10it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32426/34216 [44:40<02:27, 12.10it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  52% 1975/3765 [00:40<00:35, 49.84it/s]\u001b[A\n","Epoch 1:  95% 32432/34216 [44:40<02:27, 12.10it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32438/34216 [44:40<02:26, 12.10it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32444/34216 [44:40<02:26, 12.10it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32450/34216 [44:40<02:25, 12.10it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32456/34216 [44:40<02:25, 12.11it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32462/34216 [44:41<02:24, 12.11it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  53% 2011/3765 [00:41<00:36, 48.11it/s]\u001b[A\n","Epoch 1:  95% 32468/34216 [44:41<02:24, 12.11it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32474/34216 [44:41<02:23, 12.11it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32480/34216 [44:41<02:23, 12.11it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32486/34216 [44:41<02:22, 12.11it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32492/34216 [44:41<02:22, 12.12it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  54% 2041/3765 [00:41<00:35, 49.21it/s]\u001b[A\n","Epoch 1:  95% 32498/34216 [44:41<02:21, 12.12it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32504/34216 [44:41<02:21, 12.12it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32510/34216 [44:42<02:20, 12.12it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32516/34216 [44:42<02:20, 12.12it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32522/34216 [44:42<02:19, 12.12it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  55% 2071/3765 [00:42<00:34, 49.36it/s]\u001b[A\n","Epoch 1:  95% 32528/34216 [44:42<02:19, 12.13it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32534/34216 [44:42<02:18, 12.13it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32540/34216 [44:42<02:18, 12.13it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32546/34216 [44:42<02:17, 12.13it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32552/34216 [44:42<02:17, 12.13it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  56% 2101/3765 [00:43<00:33, 49.44it/s]\u001b[A\n","Epoch 1:  95% 32558/34216 [44:43<02:16, 12.13it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32564/34216 [44:43<02:16, 12.14it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32570/34216 [44:43<02:15, 12.14it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32576/34216 [44:43<02:15, 12.14it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32582/34216 [44:43<02:14, 12.14it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  57% 2131/3765 [00:43<00:33, 49.40it/s]\u001b[A\n","Epoch 1:  95% 32588/34216 [44:43<02:14, 12.14it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32594/34216 [44:43<02:13, 12.14it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32600/34216 [44:43<02:13, 12.15it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32606/34216 [44:43<02:12, 12.15it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32612/34216 [44:44<02:12, 12.15it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  57% 2161/3765 [00:44<00:33, 48.54it/s]\u001b[A\n","Epoch 1:  95% 32618/34216 [44:44<02:11, 12.15it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32624/34216 [44:44<02:10, 12.15it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32630/34216 [44:44<02:10, 12.15it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32636/34216 [44:44<02:09, 12.16it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32642/34216 [44:44<02:09, 12.16it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32648/34216 [44:44<02:08, 12.16it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32654/34216 [44:44<02:08, 12.16it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32660/34216 [44:45<02:07, 12.16it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  59% 2209/3765 [00:45<00:31, 49.19it/s]\u001b[A\n","Epoch 1:  95% 32666/34216 [44:45<02:07, 12.17it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  95% 32672/34216 [44:45<02:06, 12.17it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32678/34216 [44:45<02:06, 12.17it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32684/34216 [44:45<02:05, 12.17it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32690/34216 [44:45<02:05, 12.17it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32696/34216 [44:45<02:04, 12.17it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32702/34216 [44:45<02:04, 12.18it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  60% 2251/3765 [00:46<00:30, 49.43it/s]\u001b[A\n","Epoch 1:  96% 32708/34216 [44:46<02:03, 12.18it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32714/34216 [44:46<02:03, 12.18it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32720/34216 [44:46<02:02, 12.18it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32726/34216 [44:46<02:02, 12.18it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32732/34216 [44:46<02:01, 12.18it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  61% 2281/3765 [00:46<00:30, 48.84it/s]\u001b[A\n","Epoch 1:  96% 32738/34216 [44:46<02:01, 12.19it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32744/34216 [44:46<02:00, 12.19it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32750/34216 [44:46<02:00, 12.19it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32756/34216 [44:47<01:59, 12.19it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32762/34216 [44:47<01:59, 12.19it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  61% 2311/3765 [00:47<00:29, 48.62it/s]\u001b[A\n","Epoch 1:  96% 32768/34216 [44:47<01:58, 12.19it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32774/34216 [44:47<01:58, 12.20it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32780/34216 [44:47<01:57, 12.20it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32786/34216 [44:47<01:57, 12.20it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32792/34216 [44:47<01:56, 12.20it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  62% 2341/3765 [00:47<00:29, 49.05it/s]\u001b[A\n","Epoch 1:  96% 32798/34216 [44:47<01:56, 12.20it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32804/34216 [44:48<01:55, 12.20it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32810/34216 [44:48<01:55, 12.21it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32816/34216 [44:48<01:54, 12.21it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32822/34216 [44:48<01:54, 12.21it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  63% 2371/3765 [00:48<00:28, 48.92it/s]\u001b[A\n","Epoch 1:  96% 32828/34216 [44:48<01:53, 12.21it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32834/34216 [44:48<01:53, 12.21it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32840/34216 [44:48<01:52, 12.21it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32846/34216 [44:48<01:52, 12.22it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32852/34216 [44:49<01:51, 12.22it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  64% 2401/3765 [00:49<00:27, 48.97it/s]\u001b[A\n","Epoch 1:  96% 32858/34216 [44:49<01:51, 12.22it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32864/34216 [44:49<01:50, 12.22it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32870/34216 [44:49<01:50, 12.22it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32876/34216 [44:49<01:49, 12.22it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32882/34216 [44:49<01:49, 12.23it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32888/34216 [44:49<01:48, 12.23it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  65% 2437/3765 [00:49<00:27, 49.14it/s]\u001b[A\n","Epoch 1:  96% 32894/34216 [44:49<01:48, 12.23it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32900/34216 [44:49<01:47, 12.23it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32906/34216 [44:50<01:47, 12.23it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32912/34216 [44:50<01:46, 12.23it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32918/34216 [44:50<01:46, 12.24it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32924/34216 [44:50<01:45, 12.24it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32930/34216 [44:50<01:45, 12.24it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  66% 2479/3765 [00:50<00:26, 49.41it/s]\u001b[A\n","Epoch 1:  96% 32936/34216 [44:50<01:44, 12.24it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32942/34216 [44:50<01:44, 12.24it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32948/34216 [44:50<01:43, 12.24it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32954/34216 [44:51<01:43, 12.25it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32960/34216 [44:51<01:42, 12.25it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32966/34216 [44:51<01:42, 12.25it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  67% 2515/3765 [00:51<00:25, 49.70it/s]\u001b[A\n","Epoch 1:  96% 32972/34216 [44:51<01:41, 12.25it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32978/34216 [44:51<01:41, 12.25it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32984/34216 [44:51<01:40, 12.25it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32990/34216 [44:51<01:40, 12.26it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 32996/34216 [44:51<01:39, 12.26it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 33002/34216 [44:52<01:39, 12.26it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  96% 33008/34216 [44:52<01:38, 12.26it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  68% 2557/3765 [00:52<00:24, 49.62it/s]\u001b[A\n","Epoch 1:  96% 33014/34216 [44:52<01:38, 12.26it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33020/34216 [44:52<01:37, 12.26it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33026/34216 [44:52<01:37, 12.27it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33032/34216 [44:52<01:36, 12.27it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33038/34216 [44:52<01:36, 12.27it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33044/34216 [44:52<01:35, 12.27it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33050/34216 [44:53<01:35, 12.27it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33056/34216 [44:53<01:34, 12.27it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33062/34216 [44:53<01:34, 12.28it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  69% 2611/3765 [00:53<00:23, 49.24it/s]\u001b[A\n","Epoch 1:  97% 33068/34216 [44:53<01:33, 12.28it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33074/34216 [44:53<01:33, 12.28it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33080/34216 [44:53<01:32, 12.28it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33086/34216 [44:53<01:32, 12.28it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33092/34216 [44:53<01:31, 12.28it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  70% 2641/3765 [00:54<00:23, 48.66it/s]\u001b[A\n","Epoch 1:  97% 33098/34216 [44:54<01:30, 12.29it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33104/34216 [44:54<01:30, 12.29it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33110/34216 [44:54<01:29, 12.29it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33116/34216 [44:54<01:29, 12.29it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33122/34216 [44:54<01:28, 12.29it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  71% 2671/3765 [00:54<00:22, 48.73it/s]\u001b[A\n","Epoch 1:  97% 33128/34216 [44:54<01:28, 12.29it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33134/34216 [44:54<01:27, 12.30it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33140/34216 [44:54<01:27, 12.30it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33146/34216 [44:55<01:26, 12.30it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33152/34216 [44:55<01:26, 12.30it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  72% 2701/3765 [00:55<00:22, 48.20it/s]\u001b[A\n","Epoch 1:  97% 33158/34216 [44:55<01:25, 12.30it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33164/34216 [44:55<01:25, 12.30it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33170/34216 [44:55<01:25, 12.31it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33176/34216 [44:55<01:24, 12.31it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33182/34216 [44:55<01:24, 12.31it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  73% 2731/3765 [00:55<00:21, 48.01it/s]\u001b[A\n","Epoch 1:  97% 33188/34216 [44:55<01:23, 12.31it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33194/34216 [44:56<01:23, 12.31it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33200/34216 [44:56<01:22, 12.31it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33206/34216 [44:56<01:22, 12.32it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33212/34216 [44:56<01:21, 12.32it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  73% 2761/3765 [00:56<00:20, 48.13it/s]\u001b[A\n","Epoch 1:  97% 33218/34216 [44:56<01:21, 12.32it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33224/34216 [44:56<01:20, 12.32it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33230/34216 [44:56<01:20, 12.32it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33236/34216 [44:56<01:19, 12.32it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33242/34216 [44:57<01:19, 12.33it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  74% 2791/3765 [00:57<00:20, 48.06it/s]\u001b[A\n","Epoch 1:  97% 33248/34216 [44:57<01:18, 12.33it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33254/34216 [44:57<01:18, 12.33it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33260/34216 [44:57<01:17, 12.33it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33266/34216 [44:57<01:17, 12.33it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33272/34216 [44:57<01:16, 12.33it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  75% 2821/3765 [00:57<00:19, 47.55it/s]\u001b[A\n","Epoch 1:  97% 33278/34216 [44:57<01:16, 12.34it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33284/34216 [44:57<01:15, 12.34it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33290/34216 [44:57<01:15, 12.34it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33296/34216 [44:58<01:14, 12.34it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33302/34216 [44:58<01:14, 12.34it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33308/34216 [44:58<01:13, 12.34it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  76% 2857/3765 [00:58<00:18, 49.51it/s]\u001b[A\n","Epoch 1:  97% 33314/34216 [44:58<01:13, 12.35it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33320/34216 [44:58<01:12, 12.35it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33326/34216 [44:58<01:12, 12.35it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33332/34216 [44:58<01:11, 12.35it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33338/34216 [44:58<01:11, 12.35it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  77% 2887/3765 [00:59<00:17, 49.23it/s]\u001b[A\n","Epoch 1:  97% 33344/34216 [44:59<01:10, 12.35it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33350/34216 [44:59<01:10, 12.36it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  97% 33356/34216 [44:59<01:09, 12.36it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33362/34216 [44:59<01:09, 12.36it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33368/34216 [44:59<01:08, 12.36it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33374/34216 [44:59<01:08, 12.36it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33380/34216 [44:59<01:07, 12.36it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33386/34216 [44:59<01:07, 12.37it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33392/34216 [45:00<01:06, 12.37it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33398/34216 [45:00<01:06, 12.37it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33404/34216 [45:00<01:05, 12.37it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33410/34216 [45:00<01:05, 12.37it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33416/34216 [45:00<01:04, 12.37it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33422/34216 [45:00<01:04, 12.38it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33428/34216 [45:00<01:03, 12.38it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33434/34216 [45:00<01:03, 12.38it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33440/34216 [45:01<01:02, 12.38it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33446/34216 [45:01<01:02, 12.38it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33452/34216 [45:01<01:01, 12.38it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33458/34216 [45:01<01:01, 12.39it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33464/34216 [45:01<01:00, 12.39it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33470/34216 [45:01<01:00, 12.39it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33476/34216 [45:01<00:59, 12.39it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33482/34216 [45:01<00:59, 12.39it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33488/34216 [45:01<00:58, 12.39it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33494/34216 [45:02<00:58, 12.40it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33500/34216 [45:02<00:57, 12.40it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33506/34216 [45:02<00:57, 12.40it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33512/34216 [45:02<00:56, 12.40it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33518/34216 [45:02<00:56, 12.40it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33524/34216 [45:02<00:55, 12.40it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33530/34216 [45:02<00:55, 12.41it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33536/34216 [45:02<00:54, 12.41it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33542/34216 [45:03<00:54, 12.41it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33548/34216 [45:03<00:53, 12.41it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  82% 3097/3765 [01:03<00:13, 49.52it/s]\u001b[A\n","Epoch 1:  98% 33554/34216 [45:03<00:53, 12.41it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33560/34216 [45:03<00:52, 12.41it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33566/34216 [45:03<00:52, 12.42it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33572/34216 [45:03<00:51, 12.42it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33578/34216 [45:03<00:51, 12.42it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33584/34216 [45:03<00:50, 12.42it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33590/34216 [45:03<00:50, 12.42it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33596/34216 [45:04<00:49, 12.42it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33602/34216 [45:04<00:49, 12.43it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33608/34216 [45:04<00:48, 12.43it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  84% 3157/3765 [01:04<00:12, 49.06it/s]\u001b[A\n","Epoch 1:  98% 33614/34216 [45:04<00:48, 12.43it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33620/34216 [45:04<00:47, 12.43it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33626/34216 [45:04<00:47, 12.43it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33632/34216 [45:04<00:46, 12.43it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33638/34216 [45:04<00:46, 12.44it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33644/34216 [45:05<00:45, 12.44it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33650/34216 [45:05<00:45, 12.44it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33656/34216 [45:05<00:45, 12.44it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33662/34216 [45:05<00:44, 12.44it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33668/34216 [45:05<00:44, 12.44it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  85% 3217/3765 [01:05<00:10, 50.04it/s]\u001b[A\n","Epoch 1:  98% 33674/34216 [45:05<00:43, 12.45it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33680/34216 [45:05<00:43, 12.45it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33686/34216 [45:05<00:42, 12.45it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33692/34216 [45:06<00:42, 12.45it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  98% 33698/34216 [45:06<00:41, 12.45it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  86% 3247/3765 [01:06<00:10, 47.16it/s]\u001b[A\n","Epoch 1:  99% 33704/34216 [45:06<00:41, 12.45it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33710/34216 [45:06<00:40, 12.46it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33716/34216 [45:06<00:40, 12.46it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33722/34216 [45:06<00:39, 12.46it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33728/34216 [45:06<00:39, 12.46it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  87% 3277/3765 [01:07<00:10, 45.78it/s]\u001b[A\n","Epoch 1:  99% 33734/34216 [45:06<00:38, 12.46it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33740/34216 [45:07<00:38, 12.46it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33746/34216 [45:07<00:37, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33752/34216 [45:07<00:37, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33758/34216 [45:07<00:36, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33764/34216 [45:07<00:36, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  88% 3313/3765 [01:07<00:09, 48.12it/s]\u001b[A\n","Epoch 1:  99% 33770/34216 [45:07<00:35, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33776/34216 [45:07<00:35, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33782/34216 [45:07<00:34, 12.47it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33788/34216 [45:08<00:34, 12.48it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33794/34216 [45:08<00:33, 12.48it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33800/34216 [45:08<00:33, 12.48it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33806/34216 [45:08<00:32, 12.48it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33812/34216 [45:08<00:32, 12.48it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33818/34216 [45:08<00:31, 12.48it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33824/34216 [45:08<00:31, 12.49it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33830/34216 [45:08<00:30, 12.49it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33836/34216 [45:09<00:30, 12.49it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33842/34216 [45:09<00:29, 12.49it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33848/34216 [45:09<00:29, 12.49it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33854/34216 [45:09<00:28, 12.49it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  90% 3403/3765 [01:09<00:07, 47.87it/s]\u001b[A\n","Epoch 1:  99% 33860/34216 [45:09<00:28, 12.50it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33866/34216 [45:09<00:28, 12.50it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33872/34216 [45:09<00:27, 12.50it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33878/34216 [45:09<00:27, 12.50it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33884/34216 [45:10<00:26, 12.50it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33890/34216 [45:10<00:26, 12.50it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33896/34216 [45:10<00:25, 12.51it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33902/34216 [45:10<00:25, 12.51it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33908/34216 [45:10<00:24, 12.51it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33914/34216 [45:10<00:24, 12.51it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33920/34216 [45:10<00:23, 12.51it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  92% 3469/3765 [01:10<00:06, 48.76it/s]\u001b[A\n","Epoch 1:  99% 33926/34216 [45:10<00:23, 12.51it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33932/34216 [45:11<00:22, 12.52it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33938/34216 [45:11<00:22, 12.52it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33944/34216 [45:11<00:21, 12.52it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33950/34216 [45:11<00:21, 12.52it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  93% 3499/3765 [01:11<00:05, 49.31it/s]\u001b[A\n","Epoch 1:  99% 33956/34216 [45:11<00:20, 12.52it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33962/34216 [45:11<00:20, 12.52it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33968/34216 [45:11<00:19, 12.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33974/34216 [45:11<00:19, 12.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33980/34216 [45:12<00:18, 12.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33986/34216 [45:12<00:18, 12.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  94% 3535/3765 [01:12<00:04, 49.53it/s]\u001b[A\n","Epoch 1:  99% 33992/34216 [45:12<00:17, 12.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 33998/34216 [45:12<00:17, 12.53it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 34004/34216 [45:12<00:16, 12.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 34010/34216 [45:12<00:16, 12.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 34016/34216 [45:12<00:15, 12.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  95% 3565/3765 [01:12<00:04, 49.17it/s]\u001b[A\n","Epoch 1:  99% 34022/34216 [45:12<00:15, 12.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 34028/34216 [45:12<00:14, 12.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 34034/34216 [45:13<00:14, 12.54it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1:  99% 34040/34216 [45:13<00:14, 12.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34046/34216 [45:13<00:13, 12.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  95% 3595/3765 [01:13<00:03, 49.31it/s]\u001b[A\n","Epoch 1: 100% 34052/34216 [45:13<00:13, 12.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34058/34216 [45:13<00:12, 12.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34064/34216 [45:13<00:12, 12.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34070/34216 [45:13<00:11, 12.55it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34076/34216 [45:13<00:11, 12.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  96% 3625/3765 [01:14<00:02, 48.18it/s]\u001b[A\n","Epoch 1: 100% 34082/34216 [45:14<00:10, 12.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34088/34216 [45:14<00:10, 12.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34094/34216 [45:14<00:09, 12.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34100/34216 [45:14<00:09, 12.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34106/34216 [45:14<00:08, 12.56it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  97% 3655/3765 [01:14<00:02, 46.10it/s]\u001b[A\n","Epoch 1: 100% 34112/34216 [45:14<00:08, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34118/34216 [45:14<00:07, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34124/34216 [45:15<00:07, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34130/34216 [45:15<00:06, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34136/34216 [45:15<00:06, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  98% 3685/3765 [01:15<00:01, 45.90it/s]\u001b[A\n","Epoch 1: 100% 34142/34216 [45:15<00:05, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34148/34216 [45:15<00:05, 12.57it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34154/34216 [45:15<00:04, 12.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34160/34216 [45:15<00:04, 12.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34166/34216 [45:15<00:03, 12.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  99% 3715/3765 [01:16<00:01, 45.33it/s]\u001b[A\n","Epoch 1: 100% 34172/34216 [45:16<00:03, 12.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34178/34216 [45:16<00:03, 12.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34184/34216 [45:16<00:02, 12.58it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34190/34216 [45:16<00:02, 12.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34196/34216 [45:16<00:01, 12.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Validating:  99% 3745/3765 [01:16<00:00, 44.91it/s]\u001b[A\n","Epoch 1: 100% 34202/34216 [45:16<00:01, 12.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34208/34216 [45:16<00:00, 12.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.500]\n","Epoch 1: 100% 34216/34216 [45:17<00:00, 12.59it/s, loss=1.48, v_num=4, train_loss=0.896, val_loss=1.520]\n","                                                   \u001b[AEpoch 1, global step 60901: val_loss reached 1.52009 (best 1.50220), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=01-val_loss=1.520.ckpt\" as top 3\n","Epoch 2:  89% 30451/34216 [44:10<05:27, 11.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  89% 30456/34216 [44:10<05:27, 11.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30462/34216 [44:11<05:26, 11.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30468/34216 [44:11<05:26, 11.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30474/34216 [44:11<05:25, 11.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:   1% 23/3765 [00:00<01:41, 36.69it/s]\u001b[A\n","Epoch 2:  89% 30480/34216 [44:11<05:24, 11.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30486/34216 [44:11<05:24, 11.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30492/34216 [44:11<05:23, 11.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30498/34216 [44:11<05:23, 11.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30504/34216 [44:11<05:22, 11.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30510/34216 [44:11<05:22, 11.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30516/34216 [44:12<05:21, 11.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30522/34216 [44:12<05:20, 11.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30528/34216 [44:12<05:20, 11.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30534/34216 [44:12<05:19, 11.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30540/34216 [44:12<05:19, 11.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30546/34216 [44:12<05:18, 11.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30552/34216 [44:12<05:18, 11.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30558/34216 [44:12<05:17, 11.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30564/34216 [44:13<05:17, 11.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30570/34216 [44:13<05:16, 11.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30576/34216 [44:13<05:15, 11.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30582/34216 [44:13<05:15, 11.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30588/34216 [44:13<05:14, 11.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30594/34216 [44:13<05:14, 11.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30600/34216 [44:13<05:13, 11.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:   4% 149/3765 [00:03<01:18, 46.15it/s]\u001b[A\n","Epoch 2:  89% 30606/34216 [44:13<05:13, 11.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30612/34216 [44:14<05:12, 11.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  89% 30618/34216 [44:14<05:11, 11.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30624/34216 [44:14<05:11, 11.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30630/34216 [44:14<05:10, 11.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30636/34216 [44:14<05:10, 11.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30642/34216 [44:14<05:09, 11.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30648/34216 [44:14<05:09, 11.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30654/34216 [44:14<05:08, 11.55it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30660/34216 [44:15<05:07, 11.55it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:   6% 209/3765 [00:04<01:11, 49.61it/s]\u001b[A\n","Epoch 2:  90% 30666/34216 [44:15<05:07, 11.55it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30672/34216 [44:15<05:06, 11.55it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30678/34216 [44:15<05:06, 11.55it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30684/34216 [44:15<05:05, 11.55it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30690/34216 [44:15<05:05, 11.56it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30696/34216 [44:15<05:04, 11.56it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30702/34216 [44:15<05:03, 11.56it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30708/34216 [44:16<05:03, 11.56it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30714/34216 [44:16<05:02, 11.56it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30720/34216 [44:16<05:02, 11.57it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30726/34216 [44:16<05:01, 11.57it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:   7% 275/3765 [00:06<01:11, 48.65it/s]\u001b[A\n","Epoch 2:  90% 30732/34216 [44:16<05:01, 11.57it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30738/34216 [44:16<05:00, 11.57it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30744/34216 [44:16<05:00, 11.57it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30750/34216 [44:16<04:59, 11.57it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30756/34216 [44:17<04:58, 11.58it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30762/34216 [44:17<04:58, 11.58it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30768/34216 [44:17<04:57, 11.58it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30774/34216 [44:17<04:57, 11.58it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:   9% 323/3765 [00:07<01:10, 48.62it/s]\u001b[A\n","Epoch 2:  90% 30780/34216 [44:17<04:56, 11.58it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30786/34216 [44:17<04:56, 11.58it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30792/34216 [44:17<04:55, 11.59it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30798/34216 [44:17<04:54, 11.59it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30804/34216 [44:18<04:54, 11.59it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:   9% 353/3765 [00:07<01:12, 47.39it/s]\u001b[A\n","Epoch 2:  90% 30810/34216 [44:18<04:53, 11.59it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30816/34216 [44:18<04:53, 11.59it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30822/34216 [44:18<04:52, 11.59it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30828/34216 [44:18<04:52, 11.60it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30834/34216 [44:18<04:51, 11.60it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30840/34216 [44:18<04:51, 11.60it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30846/34216 [44:18<04:50, 11.60it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30852/34216 [44:19<04:49, 11.60it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30858/34216 [44:19<04:49, 11.60it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30864/34216 [44:19<04:48, 11.61it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30870/34216 [44:19<04:48, 11.61it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30876/34216 [44:19<04:47, 11.61it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30882/34216 [44:19<04:47, 11.61it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30888/34216 [44:19<04:46, 11.61it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30894/34216 [44:19<04:46, 11.61it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30900/34216 [44:19<04:45, 11.62it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30906/34216 [44:20<04:44, 11.62it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30912/34216 [44:20<04:44, 11.62it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30918/34216 [44:20<04:43, 11.62it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30924/34216 [44:20<04:43, 11.62it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30930/34216 [44:20<04:42, 11.63it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30936/34216 [44:20<04:42, 11.63it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30942/34216 [44:20<04:41, 11.63it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30948/34216 [44:20<04:40, 11.63it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30954/34216 [44:21<04:40, 11.63it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  90% 30960/34216 [44:21<04:39, 11.63it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 30966/34216 [44:21<04:39, 11.64it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 30972/34216 [44:21<04:38, 11.64it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 30978/34216 [44:21<04:38, 11.64it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 30984/34216 [44:21<04:37, 11.64it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 30990/34216 [44:21<04:37, 11.64it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 30996/34216 [44:21<04:36, 11.64it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31002/34216 [44:22<04:35, 11.65it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31008/34216 [44:22<04:35, 11.65it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31014/34216 [44:22<04:34, 11.65it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31020/34216 [44:22<04:34, 11.65it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31026/34216 [44:22<04:33, 11.65it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31032/34216 [44:22<04:33, 11.65it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31038/34216 [44:22<04:32, 11.66it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31044/34216 [44:22<04:32, 11.66it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31050/34216 [44:22<04:31, 11.66it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31056/34216 [44:23<04:30, 11.66it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31062/34216 [44:23<04:30, 11.66it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31068/34216 [44:23<04:29, 11.67it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31074/34216 [44:23<04:29, 11.67it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31080/34216 [44:23<04:28, 11.67it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31086/34216 [44:23<04:28, 11.67it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31092/34216 [44:23<04:27, 11.67it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  17% 641/3765 [00:13<01:02, 49.86it/s]\u001b[A\n","Epoch 2:  91% 31098/34216 [44:23<04:27, 11.67it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31104/34216 [44:24<04:26, 11.68it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31110/34216 [44:24<04:25, 11.68it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31116/34216 [44:24<04:25, 11.68it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31122/34216 [44:24<04:24, 11.68it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  18% 671/3765 [00:14<01:03, 48.77it/s]\u001b[A\n","Epoch 2:  91% 31128/34216 [44:24<04:24, 11.68it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31134/34216 [44:24<04:23, 11.68it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31140/34216 [44:24<04:23, 11.69it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31146/34216 [44:24<04:22, 11.69it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31152/34216 [44:25<04:22, 11.69it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  19% 701/3765 [00:14<01:08, 44.56it/s]\u001b[A\n","Epoch 2:  91% 31158/34216 [44:25<04:21, 11.69it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31164/34216 [44:25<04:21, 11.69it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31170/34216 [44:25<04:20, 11.69it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31176/34216 [44:25<04:19, 11.70it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31182/34216 [44:25<04:19, 11.70it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  19% 731/3765 [00:15<01:05, 46.48it/s]\u001b[A\n","Epoch 2:  91% 31188/34216 [44:25<04:18, 11.70it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31194/34216 [44:26<04:18, 11.70it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31200/34216 [44:26<04:17, 11.70it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31206/34216 [44:26<04:17, 11.70it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31212/34216 [44:26<04:16, 11.71it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31218/34216 [44:26<04:16, 11.71it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31224/34216 [44:26<04:15, 11.71it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31230/34216 [44:26<04:14, 11.71it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31236/34216 [44:26<04:14, 11.71it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31242/34216 [44:26<04:13, 11.71it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31248/34216 [44:27<04:13, 11.72it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31254/34216 [44:27<04:12, 11.72it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31260/34216 [44:27<04:12, 11.72it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31266/34216 [44:27<04:11, 11.72it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31272/34216 [44:27<04:11, 11.72it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31278/34216 [44:27<04:10, 11.72it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31284/34216 [44:27<04:10, 11.73it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31290/34216 [44:27<04:09, 11.73it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31296/34216 [44:28<04:08, 11.73it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  91% 31302/34216 [44:28<04:08, 11.73it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31308/34216 [44:28<04:07, 11.73it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31314/34216 [44:28<04:07, 11.74it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  23% 863/3765 [00:18<00:58, 49.55it/s]\u001b[A\n","Epoch 2:  92% 31320/34216 [44:28<04:06, 11.74it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31326/34216 [44:28<04:06, 11.74it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31332/34216 [44:28<04:05, 11.74it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31338/34216 [44:28<04:05, 11.74it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31344/34216 [44:29<04:04, 11.74it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31350/34216 [44:29<04:04, 11.75it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31356/34216 [44:29<04:03, 11.75it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31362/34216 [44:29<04:02, 11.75it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31368/34216 [44:29<04:02, 11.75it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31374/34216 [44:29<04:01, 11.75it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31380/34216 [44:29<04:01, 11.75it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31386/34216 [44:29<04:00, 11.76it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31392/34216 [44:29<04:00, 11.76it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31398/34216 [44:30<03:59, 11.76it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31404/34216 [44:30<03:59, 11.76it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  25% 953/3765 [00:19<00:56, 49.64it/s]\u001b[A\n","Epoch 2:  92% 31410/34216 [44:30<03:58, 11.76it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31416/34216 [44:30<03:58, 11.76it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31422/34216 [44:30<03:57, 11.77it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31428/34216 [44:30<03:56, 11.77it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31434/34216 [44:30<03:56, 11.77it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31440/34216 [44:30<03:55, 11.77it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  26% 989/3765 [00:20<00:56, 49.31it/s]\u001b[A\n","Epoch 2:  92% 31446/34216 [44:31<03:55, 11.77it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31452/34216 [44:31<03:54, 11.77it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31458/34216 [44:31<03:54, 11.78it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31464/34216 [44:31<03:53, 11.78it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31470/34216 [44:31<03:53, 11.78it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  27% 1019/3765 [00:21<01:02, 44.21it/s]\u001b[A\n","Epoch 2:  92% 31476/34216 [44:31<03:52, 11.78it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31482/34216 [44:31<03:52, 11.78it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31488/34216 [44:32<03:51, 11.78it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31494/34216 [44:32<03:50, 11.79it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31500/34216 [44:32<03:50, 11.79it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31506/34216 [44:32<03:49, 11.79it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31512/34216 [44:32<03:49, 11.79it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31518/34216 [44:32<03:48, 11.79it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31524/34216 [44:32<03:48, 11.79it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31530/34216 [44:32<03:47, 11.80it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31536/34216 [44:33<03:47, 11.80it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31542/34216 [44:33<03:46, 11.80it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31548/34216 [44:33<03:46, 11.80it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31554/34216 [44:33<03:45, 11.80it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  29% 1103/3765 [00:23<00:54, 48.72it/s]\u001b[A\n","Epoch 2:  92% 31560/34216 [44:33<03:44, 11.80it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31566/34216 [44:33<03:44, 11.81it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31572/34216 [44:33<03:43, 11.81it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31578/34216 [44:33<03:43, 11.81it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31584/34216 [44:33<03:42, 11.81it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  30% 1133/3765 [00:23<00:53, 48.88it/s]\u001b[A\n","Epoch 2:  92% 31590/34216 [44:34<03:42, 11.81it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31596/34216 [44:34<03:41, 11.82it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31602/34216 [44:34<03:41, 11.82it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31608/34216 [44:34<03:40, 11.82it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31614/34216 [44:34<03:40, 11.82it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  31% 1163/3765 [00:24<00:53, 48.55it/s]\u001b[A\n","Epoch 2:  92% 31620/34216 [44:34<03:39, 11.82it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31626/34216 [44:34<03:39, 11.82it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31632/34216 [44:34<03:38, 11.83it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31638/34216 [44:35<03:37, 11.83it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  92% 31644/34216 [44:35<03:37, 11.83it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31650/34216 [44:35<03:36, 11.83it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31656/34216 [44:35<03:36, 11.83it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31662/34216 [44:35<03:35, 11.83it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31668/34216 [44:35<03:35, 11.84it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  32% 1217/3765 [00:25<00:55, 46.28it/s]\u001b[A\n","Epoch 2:  93% 31674/34216 [44:35<03:34, 11.84it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31680/34216 [44:35<03:34, 11.84it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31686/34216 [44:36<03:33, 11.84it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31692/34216 [44:36<03:33, 11.84it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31698/34216 [44:36<03:32, 11.84it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31704/34216 [44:36<03:32, 11.85it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31710/34216 [44:36<03:31, 11.85it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31716/34216 [44:36<03:30, 11.85it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31722/34216 [44:36<03:30, 11.85it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31728/34216 [44:36<03:29, 11.85it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31734/34216 [44:37<03:29, 11.85it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31740/34216 [44:37<03:28, 11.86it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31746/34216 [44:37<03:28, 11.86it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31752/34216 [44:37<03:27, 11.86it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31758/34216 [44:37<03:27, 11.86it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31764/34216 [44:37<03:26, 11.86it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  35% 1313/3765 [00:27<00:52, 46.30it/s]\u001b[A\n","Epoch 2:  93% 31770/34216 [44:37<03:26, 11.86it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31776/34216 [44:37<03:25, 11.87it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31782/34216 [44:38<03:25, 11.87it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31788/34216 [44:38<03:24, 11.87it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31794/34216 [44:38<03:24, 11.87it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31800/34216 [44:38<03:23, 11.87it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31806/34216 [44:38<03:22, 11.87it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31812/34216 [44:38<03:22, 11.88it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31818/34216 [44:38<03:21, 11.88it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31824/34216 [44:38<03:21, 11.88it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31830/34216 [44:39<03:20, 11.88it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  37% 1379/3765 [00:28<00:48, 49.56it/s]\u001b[A\n","Epoch 2:  93% 31836/34216 [44:39<03:20, 11.88it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31842/34216 [44:39<03:19, 11.88it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31848/34216 [44:39<03:19, 11.89it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31854/34216 [44:39<03:18, 11.89it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31860/34216 [44:39<03:18, 11.89it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31866/34216 [44:39<03:17, 11.89it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31872/34216 [44:39<03:17, 11.89it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31878/34216 [44:40<03:16, 11.89it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31884/34216 [44:40<03:16, 11.90it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31890/34216 [44:40<03:15, 11.90it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31896/34216 [44:40<03:14, 11.90it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  38% 1445/3765 [00:30<00:47, 48.59it/s]\u001b[A\n","Epoch 2:  93% 31902/34216 [44:40<03:14, 11.90it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31908/34216 [44:40<03:13, 11.90it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31914/34216 [44:40<03:13, 11.90it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31920/34216 [44:40<03:12, 11.91it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31926/34216 [44:40<03:12, 11.91it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31932/34216 [44:41<03:11, 11.91it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31938/34216 [44:41<03:11, 11.91it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31944/34216 [44:41<03:10, 11.91it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31950/34216 [44:41<03:10, 11.92it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31956/34216 [44:41<03:09, 11.92it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31962/34216 [44:41<03:09, 11.92it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31968/34216 [44:41<03:08, 11.92it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31974/34216 [44:41<03:08, 11.92it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31980/34216 [44:42<03:07, 11.92it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  93% 31986/34216 [44:42<03:06, 11.93it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 31992/34216 [44:42<03:06, 11.93it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 31998/34216 [44:42<03:05, 11.93it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32004/34216 [44:42<03:05, 11.93it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32010/34216 [44:42<03:04, 11.93it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32016/34216 [44:42<03:04, 11.93it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32022/34216 [44:42<03:03, 11.94it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32028/34216 [44:43<03:03, 11.94it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32034/34216 [44:43<03:02, 11.94it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32040/34216 [44:43<03:02, 11.94it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32046/34216 [44:43<03:01, 11.94it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32052/34216 [44:43<03:01, 11.94it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32058/34216 [44:43<03:00, 11.95it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32064/34216 [44:43<03:00, 11.95it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32070/34216 [44:43<02:59, 11.95it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32076/34216 [44:43<02:59, 11.95it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32082/34216 [44:44<02:58, 11.95it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32088/34216 [44:44<02:58, 11.95it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32094/34216 [44:44<02:57, 11.96it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32100/34216 [44:44<02:56, 11.96it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  44% 1649/3765 [00:34<00:42, 49.23it/s]\u001b[A\n","Epoch 2:  94% 32106/34216 [44:44<02:56, 11.96it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32112/34216 [44:44<02:55, 11.96it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32118/34216 [44:44<02:55, 11.96it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32124/34216 [44:44<02:54, 11.96it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32130/34216 [44:45<02:54, 11.97it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32136/34216 [44:45<02:53, 11.97it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32142/34216 [44:45<02:53, 11.97it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32148/34216 [44:45<02:52, 11.97it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  45% 1697/3765 [00:35<00:42, 49.18it/s]\u001b[A\n","Epoch 2:  94% 32154/34216 [44:45<02:52, 11.97it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32160/34216 [44:45<02:51, 11.97it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32166/34216 [44:45<02:51, 11.98it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32172/34216 [44:45<02:50, 11.98it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32178/34216 [44:46<02:50, 11.98it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  46% 1727/3765 [00:35<00:41, 49.39it/s]\u001b[A\n","Epoch 2:  94% 32184/34216 [44:46<02:49, 11.98it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32190/34216 [44:46<02:49, 11.98it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32196/34216 [44:46<02:48, 11.98it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32202/34216 [44:46<02:48, 11.99it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32208/34216 [44:46<02:47, 11.99it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  47% 1757/3765 [00:36<00:47, 42.65it/s]\u001b[A\n","Epoch 2:  94% 32214/34216 [44:46<02:46, 11.99it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32220/34216 [44:47<02:46, 11.99it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32226/34216 [44:47<02:45, 11.99it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32232/34216 [44:47<02:45, 11.99it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32238/34216 [44:47<02:44, 12.00it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  47% 1787/3765 [00:37<00:44, 44.06it/s]\u001b[A\n","Epoch 2:  94% 32244/34216 [44:47<02:44, 12.00it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32250/34216 [44:47<02:43, 12.00it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32256/34216 [44:47<02:43, 12.00it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32262/34216 [44:47<02:42, 12.00it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32268/34216 [44:48<02:42, 12.00it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  48% 1817/3765 [00:37<00:40, 47.84it/s]\u001b[A\n","Epoch 2:  94% 32274/34216 [44:48<02:41, 12.01it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32280/34216 [44:48<02:41, 12.01it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32286/34216 [44:48<02:40, 12.01it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32292/34216 [44:48<02:40, 12.01it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32298/34216 [44:48<02:39, 12.01it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  49% 1847/3765 [00:38<00:39, 48.62it/s]\u001b[A\n","Epoch 2:  94% 32304/34216 [44:48<02:39, 12.01it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32310/34216 [44:48<02:38, 12.02it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32316/34216 [44:49<02:38, 12.02it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32322/34216 [44:49<02:37, 12.02it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  94% 32328/34216 [44:49<02:37, 12.02it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  50% 1877/3765 [00:38<00:38, 49.06it/s]\u001b[A\n","Epoch 2:  94% 32334/34216 [44:49<02:36, 12.02it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32340/34216 [44:49<02:36, 12.02it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32346/34216 [44:49<02:35, 12.03it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32352/34216 [44:49<02:34, 12.03it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32358/34216 [44:49<02:34, 12.03it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  51% 1907/3765 [00:39<00:37, 49.40it/s]\u001b[A\n","Epoch 2:  95% 32364/34216 [44:50<02:33, 12.03it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32370/34216 [44:50<02:33, 12.03it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32376/34216 [44:50<02:32, 12.03it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32382/34216 [44:50<02:32, 12.04it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32388/34216 [44:50<02:31, 12.04it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  51% 1937/3765 [00:40<00:40, 44.64it/s]\u001b[A\n","Epoch 2:  95% 32394/34216 [44:50<02:31, 12.04it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32400/34216 [44:50<02:30, 12.04it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32406/34216 [44:50<02:30, 12.04it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32412/34216 [44:51<02:29, 12.04it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32418/34216 [44:51<02:29, 12.05it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  52% 1967/3765 [00:40<00:41, 42.99it/s]\u001b[A\n","Epoch 2:  95% 32424/34216 [44:51<02:28, 12.05it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32430/34216 [44:51<02:28, 12.05it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32436/34216 [44:51<02:27, 12.05it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32442/34216 [44:51<02:27, 12.05it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32448/34216 [44:51<02:26, 12.05it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32454/34216 [44:51<02:26, 12.06it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32460/34216 [44:52<02:25, 12.06it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32466/34216 [44:52<02:25, 12.06it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32472/34216 [44:52<02:24, 12.06it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32478/34216 [44:52<02:24, 12.06it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32484/34216 [44:52<02:23, 12.06it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  54% 2033/3765 [00:42<00:35, 48.90it/s]\u001b[A\n","Epoch 2:  95% 32490/34216 [44:52<02:23, 12.07it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32496/34216 [44:52<02:22, 12.07it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32502/34216 [44:52<02:22, 12.07it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32508/34216 [44:53<02:21, 12.07it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32514/34216 [44:53<02:20, 12.07it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32520/34216 [44:53<02:20, 12.07it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32526/34216 [44:53<02:19, 12.08it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32532/34216 [44:53<02:19, 12.08it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32538/34216 [44:53<02:18, 12.08it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32544/34216 [44:53<02:18, 12.08it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32550/34216 [44:53<02:17, 12.08it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32556/34216 [44:54<02:17, 12.08it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32562/34216 [44:54<02:16, 12.09it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32568/34216 [44:54<02:16, 12.09it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32574/34216 [44:54<02:15, 12.09it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32580/34216 [44:54<02:15, 12.09it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32586/34216 [44:54<02:14, 12.09it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32592/34216 [44:54<02:14, 12.09it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32598/34216 [44:54<02:13, 12.10it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32604/34216 [44:54<02:13, 12.10it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32610/34216 [44:55<02:12, 12.10it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32616/34216 [44:55<02:12, 12.10it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32622/34216 [44:55<02:11, 12.10it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32628/34216 [44:55<02:11, 12.10it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32634/34216 [44:55<02:10, 12.11it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32640/34216 [44:55<02:10, 12.11it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32646/34216 [44:55<02:09, 12.11it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32652/34216 [44:55<02:09, 12.11it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32658/34216 [44:56<02:08, 12.11it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32664/34216 [44:56<02:08, 12.11it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  95% 32670/34216 [44:56<02:07, 12.12it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  59% 2219/3765 [00:45<00:31, 49.49it/s]\u001b[A\n","Epoch 2:  95% 32676/34216 [44:56<02:07, 12.12it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32682/34216 [44:56<02:06, 12.12it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32688/34216 [44:56<02:06, 12.12it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32694/34216 [44:56<02:05, 12.12it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32700/34216 [44:56<02:05, 12.12it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32706/34216 [44:57<02:04, 12.13it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32712/34216 [44:57<02:04, 12.13it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32718/34216 [44:57<02:03, 12.13it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32724/34216 [44:57<02:02, 12.13it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32730/34216 [44:57<02:02, 12.13it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32736/34216 [44:57<02:01, 12.13it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32742/34216 [44:57<02:01, 12.14it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32748/34216 [44:57<02:00, 12.14it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  61% 2297/3765 [00:47<00:32, 45.31it/s]\u001b[A\n","Epoch 2:  96% 32754/34216 [44:58<02:00, 12.14it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32760/34216 [44:58<01:59, 12.14it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32766/34216 [44:58<01:59, 12.14it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32772/34216 [44:58<01:58, 12.14it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32778/34216 [44:58<01:58, 12.15it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32784/34216 [44:58<01:57, 12.15it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32790/34216 [44:58<01:57, 12.15it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32796/34216 [44:58<01:56, 12.15it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32802/34216 [44:59<01:56, 12.15it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  62% 2351/3765 [00:48<00:28, 49.65it/s]\u001b[A\n","Epoch 2:  96% 32808/34216 [44:59<01:55, 12.15it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32814/34216 [44:59<01:55, 12.16it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32820/34216 [44:59<01:54, 12.16it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32826/34216 [44:59<01:54, 12.16it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32832/34216 [44:59<01:53, 12.16it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32838/34216 [44:59<01:53, 12.16it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32844/34216 [44:59<01:52, 12.16it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32850/34216 [45:00<01:52, 12.17it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32856/34216 [45:00<01:51, 12.17it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  64% 2405/3765 [00:49<00:28, 47.76it/s]\u001b[A\n","Epoch 2:  96% 32862/34216 [45:00<01:51, 12.17it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32868/34216 [45:00<01:50, 12.17it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32874/34216 [45:00<01:50, 12.17it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32880/34216 [45:00<01:49, 12.17it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32886/34216 [45:00<01:49, 12.18it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32892/34216 [45:00<01:48, 12.18it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32898/34216 [45:01<01:48, 12.18it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32904/34216 [45:01<01:47, 12.18it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32910/34216 [45:01<01:47, 12.18it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  65% 2459/3765 [00:50<00:28, 46.39it/s]\u001b[A\n","Epoch 2:  96% 32916/34216 [45:01<01:46, 12.18it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32922/34216 [45:01<01:46, 12.19it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32928/34216 [45:01<01:45, 12.19it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32934/34216 [45:01<01:45, 12.19it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32940/34216 [45:01<01:44, 12.19it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  66% 2489/3765 [00:51<00:28, 45.30it/s]\u001b[A\n","Epoch 2:  96% 32946/34216 [45:02<01:44, 12.19it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32952/34216 [45:02<01:43, 12.19it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32958/34216 [45:02<01:43, 12.20it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32964/34216 [45:02<01:42, 12.20it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32970/34216 [45:02<01:42, 12.20it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32976/34216 [45:02<01:41, 12.20it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32982/34216 [45:02<01:41, 12.20it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32988/34216 [45:02<01:40, 12.20it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 32994/34216 [45:03<01:40, 12.21it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 33000/34216 [45:03<01:39, 12.21it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 33006/34216 [45:03<01:39, 12.21it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 33012/34216 [45:03<01:38, 12.21it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  96% 33018/34216 [45:03<01:38, 12.21it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  68% 2567/3765 [00:53<00:25, 47.74it/s]\u001b[A\n","Epoch 2:  97% 33024/34216 [45:03<01:37, 12.21it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33030/34216 [45:03<01:37, 12.22it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33036/34216 [45:03<01:36, 12.22it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33042/34216 [45:04<01:36, 12.22it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33048/34216 [45:04<01:35, 12.22it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  69% 2597/3765 [00:53<00:23, 49.05it/s]\u001b[A\n","Epoch 2:  97% 33054/34216 [45:04<01:35, 12.22it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33060/34216 [45:04<01:34, 12.22it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33066/34216 [45:04<01:34, 12.23it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33072/34216 [45:04<01:33, 12.23it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33078/34216 [45:04<01:33, 12.23it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33084/34216 [45:04<01:32, 12.23it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33090/34216 [45:05<01:32, 12.23it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  70% 2639/3765 [00:54<00:22, 49.53it/s]\u001b[A\n","Epoch 2:  97% 33096/34216 [45:05<01:31, 12.23it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33102/34216 [45:05<01:31, 12.24it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33108/34216 [45:05<01:30, 12.24it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33114/34216 [45:05<01:30, 12.24it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33120/34216 [45:05<01:29, 12.24it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  71% 2669/3765 [00:55<00:22, 49.07it/s]\u001b[A\n","Epoch 2:  97% 33126/34216 [45:05<01:29, 12.24it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33132/34216 [45:05<01:28, 12.24it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33138/34216 [45:06<01:28, 12.25it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33144/34216 [45:06<01:27, 12.25it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33150/34216 [45:06<01:27, 12.25it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33156/34216 [45:06<01:26, 12.25it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  72% 2705/3765 [00:56<00:21, 49.19it/s]\u001b[A\n","Epoch 2:  97% 33162/34216 [45:06<01:26, 12.25it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33168/34216 [45:06<01:25, 12.25it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33174/34216 [45:06<01:25, 12.26it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33180/34216 [45:06<01:24, 12.26it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33186/34216 [45:07<01:24, 12.26it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  73% 2735/3765 [00:56<00:22, 45.33it/s]\u001b[A\n","Epoch 2:  97% 33192/34216 [45:07<01:23, 12.26it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33198/34216 [45:07<01:23, 12.26it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33204/34216 [45:07<01:22, 12.26it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33210/34216 [45:07<01:22, 12.27it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33216/34216 [45:07<01:21, 12.27it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33222/34216 [45:07<01:21, 12.27it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33228/34216 [45:07<01:20, 12.27it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33234/34216 [45:08<01:20, 12.27it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33240/34216 [45:08<01:19, 12.27it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33246/34216 [45:08<01:19, 12.28it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33252/34216 [45:08<01:18, 12.28it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33258/34216 [45:08<01:18, 12.28it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33264/34216 [45:08<01:17, 12.28it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33270/34216 [45:08<01:17, 12.28it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33276/34216 [45:08<01:16, 12.28it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33282/34216 [45:08<01:16, 12.29it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33288/34216 [45:09<01:15, 12.29it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  75% 2837/3765 [00:58<00:18, 49.15it/s]\u001b[A\n","Epoch 2:  97% 33294/34216 [45:09<01:15, 12.29it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33300/34216 [45:09<01:14, 12.29it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33306/34216 [45:09<01:14, 12.29it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33312/34216 [45:09<01:13, 12.29it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33318/34216 [45:09<01:13, 12.30it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  76% 2867/3765 [00:59<00:19, 46.70it/s]\u001b[A\n","Epoch 2:  97% 33324/34216 [45:09<01:12, 12.30it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33330/34216 [45:10<01:12, 12.30it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33336/34216 [45:10<01:11, 12.30it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33342/34216 [45:10<01:11, 12.30it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33348/34216 [45:10<01:10, 12.30it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  77% 2897/3765 [01:00<00:19, 45.21it/s]\u001b[A\n","Epoch 2:  97% 33354/34216 [45:10<01:10, 12.31it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  97% 33360/34216 [45:10<01:09, 12.31it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33366/34216 [45:10<01:09, 12.31it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33372/34216 [45:10<01:08, 12.31it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33378/34216 [45:11<01:08, 12.31it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  78% 2927/3765 [01:00<00:18, 45.60it/s]\u001b[A\n","Epoch 2:  98% 33384/34216 [45:11<01:07, 12.31it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33390/34216 [45:11<01:07, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33396/34216 [45:11<01:06, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33402/34216 [45:11<01:06, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33408/34216 [45:11<01:05, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  79% 2957/3765 [01:01<00:17, 46.39it/s]\u001b[A\n","Epoch 2:  98% 33414/34216 [45:11<01:05, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33420/34216 [45:11<01:04, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33426/34216 [45:12<01:04, 12.32it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33432/34216 [45:12<01:03, 12.33it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33438/34216 [45:12<01:03, 12.33it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33444/34216 [45:12<01:02, 12.33it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33450/34216 [45:12<01:02, 12.33it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33456/34216 [45:12<01:01, 12.33it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33462/34216 [45:12<01:01, 12.33it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33468/34216 [45:12<01:00, 12.34it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  80% 3017/3765 [01:02<00:15, 49.53it/s]\u001b[A\n","Epoch 2:  98% 33474/34216 [45:13<01:00, 12.34it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33480/34216 [45:13<00:59, 12.34it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33486/34216 [45:13<00:59, 12.34it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33492/34216 [45:13<00:58, 12.34it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33498/34216 [45:13<00:58, 12.34it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33504/34216 [45:13<00:57, 12.35it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33510/34216 [45:13<00:57, 12.35it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  81% 3059/3765 [01:03<00:14, 49.16it/s]\u001b[A\n","Epoch 2:  98% 33516/34216 [45:13<00:56, 12.35it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33522/34216 [45:14<00:56, 12.35it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33528/34216 [45:14<00:55, 12.35it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33534/34216 [45:14<00:55, 12.35it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33540/34216 [45:14<00:54, 12.36it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33546/34216 [45:14<00:54, 12.36it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33552/34216 [45:14<00:53, 12.36it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33558/34216 [45:14<00:53, 12.36it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33564/34216 [45:14<00:52, 12.36it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33570/34216 [45:15<00:52, 12.36it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33576/34216 [45:15<00:51, 12.37it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33582/34216 [45:15<00:51, 12.37it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33588/34216 [45:15<00:50, 12.37it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  83% 3137/3765 [01:05<00:12, 49.58it/s]\u001b[A\n","Epoch 2:  98% 33594/34216 [45:15<00:50, 12.37it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33600/34216 [45:15<00:49, 12.37it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33606/34216 [45:15<00:49, 12.37it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33612/34216 [45:15<00:48, 12.38it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33618/34216 [45:15<00:48, 12.38it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  84% 3167/3765 [01:05<00:12, 48.98it/s]\u001b[A\n","Epoch 2:  98% 33624/34216 [45:16<00:47, 12.38it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33630/34216 [45:16<00:47, 12.38it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33636/34216 [45:16<00:46, 12.38it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33642/34216 [45:16<00:46, 12.38it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33648/34216 [45:16<00:45, 12.39it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33654/34216 [45:16<00:45, 12.39it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  85% 3203/3765 [01:06<00:12, 46.65it/s]\u001b[A\n","Epoch 2:  98% 33660/34216 [45:16<00:44, 12.39it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33666/34216 [45:16<00:44, 12.39it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33672/34216 [45:17<00:43, 12.39it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33678/34216 [45:17<00:43, 12.39it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33684/34216 [45:17<00:42, 12.40it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  86% 3233/3765 [01:07<00:11, 47.49it/s]\u001b[A\n","Epoch 2:  98% 33690/34216 [45:17<00:42, 12.40it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33696/34216 [45:17<00:41, 12.40it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  98% 33702/34216 [45:17<00:41, 12.40it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33708/34216 [45:17<00:40, 12.40it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33714/34216 [45:17<00:40, 12.40it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33720/34216 [45:18<00:39, 12.41it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  87% 3269/3765 [01:07<00:10, 48.71it/s]\u001b[A\n","Epoch 2:  99% 33726/34216 [45:18<00:39, 12.41it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33732/34216 [45:18<00:39, 12.41it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33738/34216 [45:18<00:38, 12.41it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33744/34216 [45:18<00:38, 12.41it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33750/34216 [45:18<00:37, 12.41it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33756/34216 [45:18<00:37, 12.42it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  88% 3305/3765 [01:08<00:09, 49.13it/s]\u001b[A\n","Epoch 2:  99% 33762/34216 [45:18<00:36, 12.42it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33768/34216 [45:19<00:36, 12.42it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33774/34216 [45:19<00:35, 12.42it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33780/34216 [45:19<00:35, 12.42it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33786/34216 [45:19<00:34, 12.42it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33792/34216 [45:19<00:34, 12.43it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33798/34216 [45:19<00:33, 12.43it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33804/34216 [45:19<00:33, 12.43it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33810/34216 [45:19<00:32, 12.43it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33816/34216 [45:20<00:32, 12.43it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33822/34216 [45:20<00:31, 12.43it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33828/34216 [45:20<00:31, 12.44it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33834/34216 [45:20<00:30, 12.44it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33840/34216 [45:20<00:30, 12.44it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33846/34216 [45:20<00:29, 12.44it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33852/34216 [45:20<00:29, 12.44it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33858/34216 [45:20<00:28, 12.44it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33864/34216 [45:21<00:28, 12.45it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33870/34216 [45:21<00:27, 12.45it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33876/34216 [45:21<00:27, 12.45it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33882/34216 [45:21<00:26, 12.45it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33888/34216 [45:21<00:26, 12.45it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33894/34216 [45:21<00:25, 12.45it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33900/34216 [45:21<00:25, 12.46it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  92% 3449/3765 [01:11<00:06, 46.08it/s]\u001b[A\n","Epoch 2:  99% 33906/34216 [45:21<00:24, 12.46it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33912/34216 [45:22<00:24, 12.46it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33918/34216 [45:22<00:23, 12.46it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33924/34216 [45:22<00:23, 12.46it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33930/34216 [45:22<00:22, 12.46it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33936/34216 [45:22<00:22, 12.47it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33942/34216 [45:22<00:21, 12.47it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33948/34216 [45:22<00:21, 12.47it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33954/34216 [45:22<00:21, 12.47it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33960/34216 [45:22<00:20, 12.47it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33966/34216 [45:23<00:20, 12.47it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33972/34216 [45:23<00:19, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33978/34216 [45:23<00:19, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33984/34216 [45:23<00:18, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33990/34216 [45:23<00:18, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 33996/34216 [45:23<00:17, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34002/34216 [45:23<00:17, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34008/34216 [45:23<00:16, 12.48it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34014/34216 [45:24<00:16, 12.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34020/34216 [45:24<00:15, 12.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34026/34216 [45:24<00:15, 12.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  95% 3575/3765 [01:14<00:03, 47.66it/s]\u001b[A\n","Epoch 2:  99% 34032/34216 [45:24<00:14, 12.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34038/34216 [45:24<00:14, 12.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2:  99% 34044/34216 [45:24<00:13, 12.49it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34050/34216 [45:24<00:13, 12.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34056/34216 [45:24<00:12, 12.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34062/34216 [45:25<00:12, 12.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34068/34216 [45:25<00:11, 12.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34074/34216 [45:25<00:11, 12.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34080/34216 [45:25<00:10, 12.50it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34086/34216 [45:25<00:10, 12.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34092/34216 [45:25<00:09, 12.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  97% 3641/3765 [01:15<00:02, 49.04it/s]\u001b[A\n","Epoch 2: 100% 34098/34216 [45:25<00:09, 12.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34104/34216 [45:25<00:08, 12.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34110/34216 [45:26<00:08, 12.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34116/34216 [45:26<00:07, 12.51it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34122/34216 [45:26<00:07, 12.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34128/34216 [45:26<00:07, 12.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34134/34216 [45:26<00:06, 12.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34140/34216 [45:26<00:06, 12.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  98% 3689/3765 [01:16<00:01, 45.64it/s]\u001b[A\n","Epoch 2: 100% 34146/34216 [45:26<00:05, 12.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34152/34216 [45:26<00:05, 12.52it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34158/34216 [45:27<00:04, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34164/34216 [45:27<00:04, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34170/34216 [45:27<00:03, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating:  99% 3719/3765 [01:17<00:01, 44.33it/s]\u001b[A\n","Epoch 2: 100% 34176/34216 [45:27<00:03, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34182/34216 [45:27<00:02, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34188/34216 [45:27<00:02, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34194/34216 [45:27<00:01, 12.53it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34200/34216 [45:28<00:01, 12.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Validating: 100% 3749/3765 [01:17<00:00, 47.91it/s]\u001b[A\n","Epoch 2: 100% 34206/34216 [45:28<00:00, 12.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34212/34216 [45:28<00:00, 12.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.520]\n","Epoch 2: 100% 34216/34216 [45:28<00:00, 12.54it/s, loss=1.41, v_num=4, train_loss=1.410, val_loss=1.490]\n","                                                   \u001b[AEpoch 2, global step 91352: val_loss reached 1.49113 (best 1.49113), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=02-val_loss=1.491.ckpt\" as top 3\n","Epoch 3:  89% 30451/34216 [44:40<05:31, 11.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  89% 30456/34216 [44:41<05:31, 11.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30462/34216 [44:41<05:30, 11.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   0% 11/3765 [00:00<02:59, 20.89it/s]\u001b[A\n","Epoch 3:  89% 30468/34216 [44:41<05:29, 11.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30474/34216 [44:41<05:29, 11.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30480/34216 [44:41<05:28, 11.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30486/34216 [44:42<05:28, 11.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30492/34216 [44:42<05:27, 11.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   1% 41/3765 [00:01<01:28, 41.89it/s]\u001b[A\n","Epoch 3:  89% 30498/34216 [44:42<05:27, 11.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30504/34216 [44:42<05:26, 11.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30510/34216 [44:42<05:25, 11.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30516/34216 [44:42<05:25, 11.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30522/34216 [44:42<05:24, 11.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30528/34216 [44:42<05:24, 11.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30534/34216 [44:43<05:23, 11.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   2% 83/3765 [00:02<01:16, 48.41it/s]\u001b[A\n","Epoch 3:  89% 30540/34216 [44:43<05:22, 11.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30546/34216 [44:43<05:22, 11.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30552/34216 [44:43<05:21, 11.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30558/34216 [44:43<05:21, 11.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30564/34216 [44:43<05:20, 11.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   3% 113/3765 [00:02<01:14, 48.80it/s]\u001b[A\n","Epoch 3:  89% 30570/34216 [44:43<05:20, 11.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30576/34216 [44:43<05:19, 11.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30582/34216 [44:44<05:18, 11.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30588/34216 [44:44<05:18, 11.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30594/34216 [44:44<05:17, 11.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   4% 143/3765 [00:03<01:14, 48.57it/s]\u001b[A\n","Epoch 3:  89% 30600/34216 [44:44<05:17, 11.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30606/34216 [44:44<05:16, 11.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30612/34216 [44:44<05:16, 11.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  89% 30618/34216 [44:44<05:15, 11.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30624/34216 [44:44<05:14, 11.41it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   5% 173/3765 [00:04<01:13, 48.64it/s]\u001b[A\n","Epoch 3:  90% 30630/34216 [44:45<05:14, 11.41it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30636/34216 [44:45<05:13, 11.41it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30642/34216 [44:45<05:13, 11.41it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30648/34216 [44:45<05:12, 11.41it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30654/34216 [44:45<05:12, 11.41it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   5% 203/3765 [00:04<01:13, 48.61it/s]\u001b[A\n","Epoch 3:  90% 30660/34216 [44:45<05:11, 11.42it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30666/34216 [44:45<05:10, 11.42it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30672/34216 [44:45<05:10, 11.42it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30678/34216 [44:46<05:09, 11.42it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30684/34216 [44:46<05:09, 11.42it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   6% 233/3765 [00:05<01:12, 48.59it/s]\u001b[A\n","Epoch 3:  90% 30690/34216 [44:46<05:08, 11.42it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30696/34216 [44:46<05:08, 11.43it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30702/34216 [44:46<05:07, 11.43it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30708/34216 [44:46<05:06, 11.43it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30714/34216 [44:46<05:06, 11.43it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30720/34216 [44:46<05:05, 11.43it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30726/34216 [44:47<05:05, 11.43it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30732/34216 [44:47<05:04, 11.44it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   7% 281/3765 [00:06<01:11, 48.67it/s]\u001b[A\n","Epoch 3:  90% 30738/34216 [44:47<05:04, 11.44it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30744/34216 [44:47<05:03, 11.44it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30750/34216 [44:47<05:02, 11.44it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30756/34216 [44:47<05:02, 11.44it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30762/34216 [44:47<05:01, 11.45it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30768/34216 [44:47<05:01, 11.45it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30774/34216 [44:48<05:00, 11.45it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   9% 323/3765 [00:07<01:09, 49.22it/s]\u001b[A\n","Epoch 3:  90% 30780/34216 [44:48<05:00, 11.45it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30786/34216 [44:48<04:59, 11.45it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30792/34216 [44:48<04:58, 11.45it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30798/34216 [44:48<04:58, 11.46it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30804/34216 [44:48<04:57, 11.46it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:   9% 353/3765 [00:07<01:10, 48.29it/s]\u001b[A\n","Epoch 3:  90% 30810/34216 [44:48<04:57, 11.46it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30816/34216 [44:48<04:56, 11.46it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30822/34216 [44:49<04:56, 11.46it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30828/34216 [44:49<04:55, 11.46it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30834/34216 [44:49<04:54, 11.47it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  10% 383/3765 [00:08<01:08, 49.05it/s]\u001b[A\n","Epoch 3:  90% 30840/34216 [44:49<04:54, 11.47it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30846/34216 [44:49<04:53, 11.47it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30852/34216 [44:49<04:53, 11.47it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30858/34216 [44:49<04:52, 11.47it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30864/34216 [44:49<04:52, 11.47it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  11% 413/3765 [00:08<01:09, 48.47it/s]\u001b[A\n","Epoch 3:  90% 30870/34216 [44:49<04:51, 11.48it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30876/34216 [44:50<04:51, 11.48it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30882/34216 [44:50<04:50, 11.48it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30888/34216 [44:50<04:49, 11.48it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30894/34216 [44:50<04:49, 11.48it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30900/34216 [44:50<04:48, 11.48it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30906/34216 [44:50<04:48, 11.49it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  12% 455/3765 [00:09<01:07, 48.94it/s]\u001b[A\n","Epoch 3:  90% 30912/34216 [44:50<04:47, 11.49it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30918/34216 [44:50<04:47, 11.49it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30924/34216 [44:51<04:46, 11.49it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30930/34216 [44:51<04:45, 11.49it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30936/34216 [44:51<04:45, 11.49it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30942/34216 [44:51<04:44, 11.50it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  13% 491/3765 [00:10<01:07, 48.39it/s]\u001b[A\n","Epoch 3:  90% 30948/34216 [44:51<04:44, 11.50it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30954/34216 [44:51<04:43, 11.50it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  90% 30960/34216 [44:51<04:43, 11.50it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 30966/34216 [44:51<04:42, 11.50it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 30972/34216 [44:52<04:41, 11.50it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  14% 521/3765 [00:11<01:09, 46.89it/s]\u001b[A\n","Epoch 3:  91% 30978/34216 [44:52<04:41, 11.51it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 30984/34216 [44:52<04:40, 11.51it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 30990/34216 [44:52<04:40, 11.51it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 30996/34216 [44:52<04:39, 11.51it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31002/34216 [44:52<04:39, 11.51it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  15% 551/3765 [00:11<01:07, 47.68it/s]\u001b[A\n","Epoch 3:  91% 31008/34216 [44:52<04:38, 11.51it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31014/34216 [44:52<04:38, 11.52it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31020/34216 [44:53<04:37, 11.52it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31026/34216 [44:53<04:36, 11.52it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31032/34216 [44:53<04:36, 11.52it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  15% 581/3765 [00:12<01:05, 48.73it/s]\u001b[A\n","Epoch 3:  91% 31038/34216 [44:53<04:35, 11.52it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31044/34216 [44:53<04:35, 11.53it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31050/34216 [44:53<04:34, 11.53it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31056/34216 [44:53<04:34, 11.53it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31062/34216 [44:53<04:33, 11.53it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  16% 611/3765 [00:13<01:05, 48.50it/s]\u001b[A\n","Epoch 3:  91% 31068/34216 [44:54<04:32, 11.53it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31074/34216 [44:54<04:32, 11.53it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31080/34216 [44:54<04:31, 11.54it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31086/34216 [44:54<04:31, 11.54it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31092/34216 [44:54<04:30, 11.54it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  17% 641/3765 [00:13<01:03, 48.88it/s]\u001b[A\n","Epoch 3:  91% 31098/34216 [44:54<04:30, 11.54it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31104/34216 [44:54<04:29, 11.54it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31110/34216 [44:54<04:29, 11.54it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31116/34216 [44:55<04:28, 11.55it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31122/34216 [44:55<04:27, 11.55it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31128/34216 [44:55<04:27, 11.55it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  18% 677/3765 [00:14<01:03, 48.66it/s]\u001b[A\n","Epoch 3:  91% 31134/34216 [44:55<04:26, 11.55it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31140/34216 [44:55<04:26, 11.55it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31146/34216 [44:55<04:25, 11.55it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31152/34216 [44:55<04:25, 11.56it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31158/34216 [44:55<04:24, 11.56it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31164/34216 [44:56<04:24, 11.56it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31170/34216 [44:56<04:23, 11.56it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31176/34216 [44:56<04:22, 11.56it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31182/34216 [44:56<04:22, 11.56it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  19% 731/3765 [00:15<01:01, 49.51it/s]\u001b[A\n","Epoch 3:  91% 31188/34216 [44:56<04:21, 11.57it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31194/34216 [44:56<04:21, 11.57it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31200/34216 [44:56<04:20, 11.57it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31206/34216 [44:56<04:20, 11.57it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31212/34216 [44:57<04:19, 11.57it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31218/34216 [44:57<04:19, 11.57it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31224/34216 [44:57<04:18, 11.58it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  21% 773/3765 [00:16<01:00, 49.12it/s]\u001b[A\n","Epoch 3:  91% 31230/34216 [44:57<04:17, 11.58it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31236/34216 [44:57<04:17, 11.58it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31242/34216 [44:57<04:16, 11.58it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31248/34216 [44:57<04:16, 11.58it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31254/34216 [44:57<04:15, 11.58it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31260/34216 [44:57<04:15, 11.59it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31266/34216 [44:58<04:14, 11.59it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31272/34216 [44:58<04:14, 11.59it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31278/34216 [44:58<04:13, 11.59it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31284/34216 [44:58<04:12, 11.59it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31290/34216 [44:58<04:12, 11.60it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31296/34216 [44:58<04:11, 11.60it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  91% 31302/34216 [44:58<04:11, 11.60it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31308/34216 [44:58<04:10, 11.60it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  23% 857/3765 [00:18<00:59, 49.20it/s]\u001b[A\n","Epoch 3:  92% 31314/34216 [44:59<04:10, 11.60it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31320/34216 [44:59<04:09, 11.60it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31326/34216 [44:59<04:09, 11.61it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31332/34216 [44:59<04:08, 11.61it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31338/34216 [44:59<04:07, 11.61it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  24% 887/3765 [00:18<01:00, 47.84it/s]\u001b[A\n","Epoch 3:  92% 31344/34216 [44:59<04:07, 11.61it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31350/34216 [44:59<04:06, 11.61it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31356/34216 [44:59<04:06, 11.61it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31362/34216 [45:00<04:05, 11.62it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31368/34216 [45:00<04:05, 11.62it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  24% 917/3765 [00:19<00:58, 48.61it/s]\u001b[A\n","Epoch 3:  92% 31374/34216 [45:00<04:04, 11.62it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31380/34216 [45:00<04:04, 11.62it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31386/34216 [45:00<04:03, 11.62it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31392/34216 [45:00<04:02, 11.62it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31398/34216 [45:00<04:02, 11.63it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  25% 947/3765 [00:19<00:57, 48.64it/s]\u001b[A\n","Epoch 3:  92% 31404/34216 [45:00<04:01, 11.63it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31410/34216 [45:01<04:01, 11.63it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31416/34216 [45:01<04:00, 11.63it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31422/34216 [45:01<04:00, 11.63it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31428/34216 [45:01<03:59, 11.63it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31434/34216 [45:01<03:59, 11.64it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  26% 983/3765 [00:20<00:56, 49.01it/s]\u001b[A\n","Epoch 3:  92% 31440/34216 [45:01<03:58, 11.64it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31446/34216 [45:01<03:57, 11.64it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31452/34216 [45:01<03:57, 11.64it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31458/34216 [45:02<03:56, 11.64it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31464/34216 [45:02<03:56, 11.64it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  27% 1013/3765 [00:21<00:56, 48.65it/s]\u001b[A\n","Epoch 3:  92% 31470/34216 [45:02<03:55, 11.65it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31476/34216 [45:02<03:55, 11.65it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31482/34216 [45:02<03:54, 11.65it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31488/34216 [45:02<03:54, 11.65it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31494/34216 [45:02<03:53, 11.65it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  28% 1043/3765 [00:21<00:56, 48.00it/s]\u001b[A\n","Epoch 3:  92% 31500/34216 [45:02<03:53, 11.65it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31506/34216 [45:03<03:52, 11.66it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31512/34216 [45:03<03:51, 11.66it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31518/34216 [45:03<03:51, 11.66it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31524/34216 [45:03<03:50, 11.66it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  28% 1073/3765 [00:22<00:55, 48.45it/s]\u001b[A\n","Epoch 3:  92% 31530/34216 [45:03<03:50, 11.66it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31536/34216 [45:03<03:49, 11.66it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31542/34216 [45:03<03:49, 11.67it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31548/34216 [45:03<03:48, 11.67it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31554/34216 [45:04<03:48, 11.67it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31560/34216 [45:04<03:47, 11.67it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  29% 1109/3765 [00:23<00:53, 49.78it/s]\u001b[A\n","Epoch 3:  92% 31566/34216 [45:04<03:47, 11.67it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31572/34216 [45:04<03:46, 11.67it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31578/34216 [45:04<03:45, 11.68it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31584/34216 [45:04<03:45, 11.68it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31590/34216 [45:04<03:44, 11.68it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31596/34216 [45:04<03:44, 11.68it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31602/34216 [45:04<03:43, 11.68it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31608/34216 [45:05<03:43, 11.68it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31614/34216 [45:05<03:42, 11.69it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31620/34216 [45:05<03:42, 11.69it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31626/34216 [45:05<03:41, 11.69it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31632/34216 [45:05<03:41, 11.69it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  31% 1181/3765 [00:24<00:52, 49.47it/s]\u001b[A\n","Epoch 3:  92% 31638/34216 [45:05<03:40, 11.69it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  92% 31644/34216 [45:05<03:39, 11.69it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31650/34216 [45:05<03:39, 11.70it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31656/34216 [45:06<03:38, 11.70it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31662/34216 [45:06<03:38, 11.70it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  32% 1211/3765 [00:25<00:51, 49.61it/s]\u001b[A\n","Epoch 3:  93% 31668/34216 [45:06<03:37, 11.70it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31674/34216 [45:06<03:37, 11.70it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31680/34216 [45:06<03:36, 11.70it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31686/34216 [45:06<03:36, 11.71it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31692/34216 [45:06<03:35, 11.71it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31698/34216 [45:06<03:35, 11.71it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31704/34216 [45:07<03:34, 11.71it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31710/34216 [45:07<03:33, 11.71it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31716/34216 [45:07<03:33, 11.72it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31722/34216 [45:07<03:32, 11.72it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31728/34216 [45:07<03:32, 11.72it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31734/34216 [45:07<03:31, 11.72it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31740/34216 [45:07<03:31, 11.72it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31746/34216 [45:07<03:30, 11.72it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31752/34216 [45:08<03:30, 11.73it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31758/34216 [45:08<03:29, 11.73it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31764/34216 [45:08<03:29, 11.73it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31770/34216 [45:08<03:28, 11.73it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31776/34216 [45:08<03:27, 11.73it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31782/34216 [45:08<03:27, 11.73it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31788/34216 [45:08<03:26, 11.74it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31794/34216 [45:08<03:26, 11.74it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31800/34216 [45:08<03:25, 11.74it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31806/34216 [45:09<03:25, 11.74it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31812/34216 [45:09<03:24, 11.74it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31818/34216 [45:09<03:24, 11.74it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31824/34216 [45:09<03:23, 11.75it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31830/34216 [45:09<03:23, 11.75it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31836/34216 [45:09<03:22, 11.75it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31842/34216 [45:09<03:22, 11.75it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  37% 1391/3765 [00:28<00:48, 49.30it/s]\u001b[A\n","Epoch 3:  93% 31848/34216 [45:09<03:21, 11.75it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31854/34216 [45:10<03:20, 11.75it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31860/34216 [45:10<03:20, 11.76it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31866/34216 [45:10<03:19, 11.76it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31872/34216 [45:10<03:19, 11.76it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  38% 1421/3765 [00:29<00:47, 48.98it/s]\u001b[A\n","Epoch 3:  93% 31878/34216 [45:10<03:18, 11.76it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31884/34216 [45:10<03:18, 11.76it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31890/34216 [45:10<03:17, 11.76it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31896/34216 [45:10<03:17, 11.77it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31902/34216 [45:11<03:16, 11.77it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31908/34216 [45:11<03:16, 11.77it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31914/34216 [45:11<03:15, 11.77it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31920/34216 [45:11<03:15, 11.77it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31926/34216 [45:11<03:14, 11.77it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31932/34216 [45:11<03:13, 11.78it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31938/34216 [45:11<03:13, 11.78it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31944/34216 [45:11<03:12, 11.78it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31950/34216 [45:11<03:12, 11.78it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31956/34216 [45:12<03:11, 11.78it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31962/34216 [45:12<03:11, 11.78it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31968/34216 [45:12<03:10, 11.79it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31974/34216 [45:12<03:10, 11.79it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31980/34216 [45:12<03:09, 11.79it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  93% 31986/34216 [45:12<03:09, 11.79it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 31992/34216 [45:12<03:08, 11.79it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 31998/34216 [45:12<03:08, 11.79it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32004/34216 [45:13<03:07, 11.80it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32010/34216 [45:13<03:06, 11.80it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32016/34216 [45:13<03:06, 11.80it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32022/34216 [45:13<03:05, 11.80it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32028/34216 [45:13<03:05, 11.80it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32034/34216 [45:13<03:04, 11.80it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32040/34216 [45:13<03:04, 11.81it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32046/34216 [45:13<03:03, 11.81it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32052/34216 [45:14<03:03, 11.81it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32058/34216 [45:14<03:02, 11.81it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32064/34216 [45:14<03:02, 11.81it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32070/34216 [45:14<03:01, 11.81it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32076/34216 [45:14<03:01, 11.82it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32082/34216 [45:14<03:00, 11.82it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32088/34216 [45:14<03:00, 11.82it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32094/34216 [45:14<02:59, 11.82it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32100/34216 [45:14<02:58, 11.82it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32106/34216 [45:15<02:58, 11.83it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32112/34216 [45:15<02:57, 11.83it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32118/34216 [45:15<02:57, 11.83it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32124/34216 [45:15<02:56, 11.83it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32130/34216 [45:15<02:56, 11.83it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  45% 1679/3765 [00:34<00:42, 49.45it/s]\u001b[A\n","Epoch 3:  94% 32136/34216 [45:15<02:55, 11.83it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32142/34216 [45:15<02:55, 11.84it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32148/34216 [45:15<02:54, 11.84it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32154/34216 [45:16<02:54, 11.84it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32160/34216 [45:16<02:53, 11.84it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32166/34216 [45:16<02:53, 11.84it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32172/34216 [45:16<02:52, 11.84it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32178/34216 [45:16<02:52, 11.85it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32184/34216 [45:16<02:51, 11.85it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32190/34216 [45:16<02:50, 11.85it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32196/34216 [45:16<02:50, 11.85it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32202/34216 [45:17<02:49, 11.85it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32208/34216 [45:17<02:49, 11.85it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  47% 1757/3765 [00:36<00:40, 49.62it/s]\u001b[A\n","Epoch 3:  94% 32214/34216 [45:17<02:48, 11.86it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32220/34216 [45:17<02:48, 11.86it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32226/34216 [45:17<02:47, 11.86it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32232/34216 [45:17<02:47, 11.86it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32238/34216 [45:17<02:46, 11.86it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32244/34216 [45:17<02:46, 11.86it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32250/34216 [45:18<02:45, 11.87it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  48% 1799/3765 [00:37<00:40, 48.43it/s]\u001b[A\n","Epoch 3:  94% 32256/34216 [45:18<02:45, 11.87it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32262/34216 [45:18<02:44, 11.87it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32268/34216 [45:18<02:44, 11.87it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32274/34216 [45:18<02:43, 11.87it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32280/34216 [45:18<02:43, 11.87it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32286/34216 [45:18<02:42, 11.88it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32292/34216 [45:18<02:41, 11.88it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32298/34216 [45:18<02:41, 11.88it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32304/34216 [45:19<02:40, 11.88it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32310/34216 [45:19<02:40, 11.88it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  49% 1859/3765 [00:38<00:39, 48.80it/s]\u001b[A\n","Epoch 3:  94% 32316/34216 [45:19<02:39, 11.88it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32322/34216 [45:19<02:39, 11.89it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32328/34216 [45:19<02:38, 11.89it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  94% 32334/34216 [45:19<02:38, 11.89it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32340/34216 [45:19<02:37, 11.89it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  50% 1889/3765 [00:38<00:38, 48.97it/s]\u001b[A\n","Epoch 3:  95% 32346/34216 [45:19<02:37, 11.89it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32352/34216 [45:20<02:36, 11.89it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32358/34216 [45:20<02:36, 11.90it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32364/34216 [45:20<02:35, 11.90it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32370/34216 [45:20<02:35, 11.90it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32376/34216 [45:20<02:34, 11.90it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32382/34216 [45:20<02:34, 11.90it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  51% 1931/3765 [00:39<00:36, 49.78it/s]\u001b[A\n","Epoch 3:  95% 32388/34216 [45:20<02:33, 11.90it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32394/34216 [45:20<02:33, 11.91it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32400/34216 [45:21<02:32, 11.91it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32406/34216 [45:21<02:31, 11.91it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32412/34216 [45:21<02:31, 11.91it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  52% 1961/3765 [00:40<00:36, 49.10it/s]\u001b[A\n","Epoch 3:  95% 32418/34216 [45:21<02:30, 11.91it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32424/34216 [45:21<02:30, 11.91it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32430/34216 [45:21<02:29, 11.92it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32436/34216 [45:21<02:29, 11.92it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32442/34216 [45:21<02:28, 11.92it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  53% 1991/3765 [00:41<00:36, 47.98it/s]\u001b[A\n","Epoch 3:  95% 32448/34216 [45:22<02:28, 11.92it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32454/34216 [45:22<02:27, 11.92it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32460/34216 [45:22<02:27, 11.92it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32466/34216 [45:22<02:26, 11.93it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32472/34216 [45:22<02:26, 11.93it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  54% 2021/3765 [00:41<00:35, 49.20it/s]\u001b[A\n","Epoch 3:  95% 32478/34216 [45:22<02:25, 11.93it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32484/34216 [45:22<02:25, 11.93it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32490/34216 [45:22<02:24, 11.93it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32496/34216 [45:23<02:24, 11.93it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32502/34216 [45:23<02:23, 11.94it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  54% 2051/3765 [00:42<00:34, 49.63it/s]\u001b[A\n","Epoch 3:  95% 32508/34216 [45:23<02:23, 11.94it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32514/34216 [45:23<02:22, 11.94it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32520/34216 [45:23<02:22, 11.94it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32526/34216 [45:23<02:21, 11.94it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32532/34216 [45:23<02:20, 11.94it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32538/34216 [45:23<02:20, 11.95it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32544/34216 [45:23<02:19, 11.95it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  56% 2093/3765 [00:43<00:34, 48.59it/s]\u001b[A\n","Epoch 3:  95% 32550/34216 [45:24<02:19, 11.95it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32556/34216 [45:24<02:18, 11.95it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32562/34216 [45:24<02:18, 11.95it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32568/34216 [45:24<02:17, 11.95it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32574/34216 [45:24<02:17, 11.96it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  56% 2123/3765 [00:43<00:33, 49.01it/s]\u001b[A\n","Epoch 3:  95% 32580/34216 [45:24<02:16, 11.96it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32586/34216 [45:24<02:16, 11.96it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32592/34216 [45:24<02:15, 11.96it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32598/34216 [45:25<02:15, 11.96it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32604/34216 [45:25<02:14, 11.96it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32610/34216 [45:25<02:14, 11.97it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32616/34216 [45:25<02:13, 11.97it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  58% 2165/3765 [00:44<00:32, 49.07it/s]\u001b[A\n","Epoch 3:  95% 32622/34216 [45:25<02:13, 11.97it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32628/34216 [45:25<02:12, 11.97it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32634/34216 [45:25<02:12, 11.97it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32640/34216 [45:25<02:11, 11.97it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32646/34216 [45:26<02:11, 11.98it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  58% 2195/3765 [00:45<00:32, 49.05it/s]\u001b[A\n","Epoch 3:  95% 32652/34216 [45:26<02:10, 11.98it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32658/34216 [45:26<02:10, 11.98it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32664/34216 [45:26<02:09, 11.98it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32670/34216 [45:26<02:09, 11.98it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  95% 32676/34216 [45:26<02:08, 11.98it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  59% 2225/3765 [00:45<00:32, 47.39it/s]\u001b[A\n","Epoch 3:  96% 32682/34216 [45:26<02:07, 11.99it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32688/34216 [45:26<02:07, 11.99it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32694/34216 [45:27<02:06, 11.99it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32700/34216 [45:27<02:06, 11.99it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32706/34216 [45:27<02:05, 11.99it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32712/34216 [45:27<02:05, 11.99it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  60% 2261/3765 [00:46<00:30, 49.20it/s]\u001b[A\n","Epoch 3:  96% 32718/34216 [45:27<02:04, 12.00it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32724/34216 [45:27<02:04, 12.00it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32730/34216 [45:27<02:03, 12.00it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32736/34216 [45:27<02:03, 12.00it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32742/34216 [45:28<02:02, 12.00it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  61% 2291/3765 [00:47<00:30, 48.13it/s]\u001b[A\n","Epoch 3:  96% 32748/34216 [45:28<02:02, 12.00it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32754/34216 [45:28<02:01, 12.01it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32760/34216 [45:28<02:01, 12.01it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32766/34216 [45:28<02:00, 12.01it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32772/34216 [45:28<02:00, 12.01it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  62% 2321/3765 [00:47<00:30, 48.02it/s]\u001b[A\n","Epoch 3:  96% 32778/34216 [45:28<01:59, 12.01it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32784/34216 [45:28<01:59, 12.01it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32790/34216 [45:29<01:58, 12.02it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32796/34216 [45:29<01:58, 12.02it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32802/34216 [45:29<01:57, 12.02it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  62% 2351/3765 [00:48<00:28, 48.96it/s]\u001b[A\n","Epoch 3:  96% 32808/34216 [45:29<01:57, 12.02it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32814/34216 [45:29<01:56, 12.02it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32820/34216 [45:29<01:56, 12.02it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32826/34216 [45:29<01:55, 12.03it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32832/34216 [45:29<01:55, 12.03it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32838/34216 [45:30<01:54, 12.03it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  63% 2387/3765 [00:49<00:27, 49.26it/s]\u001b[A\n","Epoch 3:  96% 32844/34216 [45:30<01:54, 12.03it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32850/34216 [45:30<01:53, 12.03it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32856/34216 [45:30<01:53, 12.03it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32862/34216 [45:30<01:52, 12.04it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32868/34216 [45:30<01:51, 12.04it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  64% 2417/3765 [00:49<00:27, 49.21it/s]\u001b[A\n","Epoch 3:  96% 32874/34216 [45:30<01:51, 12.04it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32880/34216 [45:30<01:50, 12.04it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32886/34216 [45:30<01:50, 12.04it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32892/34216 [45:31<01:49, 12.04it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32898/34216 [45:31<01:49, 12.05it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32904/34216 [45:31<01:48, 12.05it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32910/34216 [45:31<01:48, 12.05it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32916/34216 [45:31<01:47, 12.05it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32922/34216 [45:31<01:47, 12.05it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32928/34216 [45:31<01:46, 12.05it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32934/34216 [45:31<01:46, 12.06it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32940/34216 [45:32<01:45, 12.06it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32946/34216 [45:32<01:45, 12.06it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32952/34216 [45:32<01:44, 12.06it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32958/34216 [45:32<01:44, 12.06it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32964/34216 [45:32<01:43, 12.06it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  67% 2513/3765 [00:51<00:25, 48.60it/s]\u001b[A\n","Epoch 3:  96% 32970/34216 [45:32<01:43, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32976/34216 [45:32<01:42, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32982/34216 [45:32<01:42, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32988/34216 [45:33<01:41, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 32994/34216 [45:33<01:41, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  68% 2543/3765 [00:52<00:25, 47.84it/s]\u001b[A\n","Epoch 3:  96% 33000/34216 [45:33<01:40, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 33006/34216 [45:33<01:40, 12.07it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 33012/34216 [45:33<01:39, 12.08it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  96% 33018/34216 [45:33<01:39, 12.08it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33024/34216 [45:33<01:38, 12.08it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  68% 2573/3765 [00:52<00:24, 48.55it/s]\u001b[A\n","Epoch 3:  97% 33030/34216 [45:33<01:38, 12.08it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33036/34216 [45:34<01:37, 12.08it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33042/34216 [45:34<01:37, 12.08it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33048/34216 [45:34<01:36, 12.09it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33054/34216 [45:34<01:36, 12.09it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  69% 2603/3765 [00:53<00:25, 46.38it/s]\u001b[A\n","Epoch 3:  97% 33060/34216 [45:34<01:35, 12.09it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33066/34216 [45:34<01:35, 12.09it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33072/34216 [45:34<01:34, 12.09it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33078/34216 [45:34<01:34, 12.09it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33084/34216 [45:35<01:33, 12.10it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  70% 2633/3765 [00:54<00:24, 46.50it/s]\u001b[A\n","Epoch 3:  97% 33090/34216 [45:35<01:33, 12.10it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33096/34216 [45:35<01:32, 12.10it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33102/34216 [45:35<01:32, 12.10it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33108/34216 [45:35<01:31, 12.10it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33114/34216 [45:35<01:31, 12.10it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  71% 2663/3765 [00:54<00:22, 48.05it/s]\u001b[A\n","Epoch 3:  97% 33120/34216 [45:35<01:30, 12.11it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33126/34216 [45:35<01:30, 12.11it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33132/34216 [45:36<01:29, 12.11it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33138/34216 [45:36<01:29, 12.11it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33144/34216 [45:36<01:28, 12.11it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33150/34216 [45:36<01:27, 12.11it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33156/34216 [45:36<01:27, 12.12it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33162/34216 [45:36<01:26, 12.12it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33168/34216 [45:36<01:26, 12.12it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  72% 2717/3765 [00:55<00:21, 48.65it/s]\u001b[A\n","Epoch 3:  97% 33174/34216 [45:36<01:25, 12.12it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33180/34216 [45:37<01:25, 12.12it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33186/34216 [45:37<01:24, 12.12it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33192/34216 [45:37<01:24, 12.13it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33198/34216 [45:37<01:23, 12.13it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  73% 2747/3765 [00:56<00:21, 47.57it/s]\u001b[A\n","Epoch 3:  97% 33204/34216 [45:37<01:23, 12.13it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33210/34216 [45:37<01:22, 12.13it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33216/34216 [45:37<01:22, 12.13it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33222/34216 [45:37<01:21, 12.13it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33228/34216 [45:38<01:21, 12.14it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  74% 2777/3765 [00:57<00:21, 46.70it/s]\u001b[A\n","Epoch 3:  97% 33234/34216 [45:38<01:20, 12.14it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33240/34216 [45:38<01:20, 12.14it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33246/34216 [45:38<01:19, 12.14it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33252/34216 [45:38<01:19, 12.14it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33258/34216 [45:38<01:18, 12.14it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  75% 2807/3765 [00:57<00:20, 47.51it/s]\u001b[A\n","Epoch 3:  97% 33264/34216 [45:38<01:18, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33270/34216 [45:38<01:17, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33276/34216 [45:39<01:17, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33282/34216 [45:39<01:16, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33288/34216 [45:39<01:16, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  75% 2837/3765 [00:58<00:19, 48.63it/s]\u001b[A\n","Epoch 3:  97% 33294/34216 [45:39<01:15, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33300/34216 [45:39<01:15, 12.15it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33306/34216 [45:39<01:14, 12.16it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33312/34216 [45:39<01:14, 12.16it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33318/34216 [45:39<01:13, 12.16it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  76% 2867/3765 [00:59<00:18, 47.80it/s]\u001b[A\n","Epoch 3:  97% 33324/34216 [45:40<01:13, 12.16it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33330/34216 [45:40<01:12, 12.16it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33336/34216 [45:40<01:12, 12.16it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33342/34216 [45:40<01:11, 12.17it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33348/34216 [45:40<01:11, 12.17it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  77% 2897/3765 [00:59<00:18, 47.78it/s]\u001b[A\n","Epoch 3:  97% 33354/34216 [45:40<01:10, 12.17it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  97% 33360/34216 [45:40<01:10, 12.17it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33366/34216 [45:40<01:09, 12.17it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33372/34216 [45:41<01:09, 12.17it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33378/34216 [45:41<01:08, 12.18it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  78% 2927/3765 [01:00<00:17, 48.05it/s]\u001b[A\n","Epoch 3:  98% 33384/34216 [45:41<01:08, 12.18it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33390/34216 [45:41<01:07, 12.18it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33396/34216 [45:41<01:07, 12.18it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33402/34216 [45:41<01:06, 12.18it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33408/34216 [45:41<01:06, 12.18it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33414/34216 [45:42<01:05, 12.19it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  79% 2963/3765 [01:01<00:18, 42.76it/s]\u001b[A\n","Epoch 3:  98% 33420/34216 [45:42<01:05, 12.19it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33426/34216 [45:42<01:04, 12.19it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33432/34216 [45:42<01:04, 12.19it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33438/34216 [45:42<01:03, 12.19it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33444/34216 [45:42<01:03, 12.19it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33450/34216 [45:42<01:02, 12.20it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  80% 2999/3765 [01:01<00:16, 46.78it/s]\u001b[A\n","Epoch 3:  98% 33456/34216 [45:42<01:02, 12.20it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33462/34216 [45:43<01:01, 12.20it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33468/34216 [45:43<01:01, 12.20it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33474/34216 [45:43<01:00, 12.20it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33480/34216 [45:43<01:00, 12.20it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33486/34216 [45:43<00:59, 12.21it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  81% 3035/3765 [01:02<00:15, 48.53it/s]\u001b[A\n","Epoch 3:  98% 33492/34216 [45:43<00:59, 12.21it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33498/34216 [45:43<00:58, 12.21it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33504/34216 [45:43<00:58, 12.21it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33510/34216 [45:44<00:57, 12.21it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33516/34216 [45:44<00:57, 12.21it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  81% 3065/3765 [01:03<00:14, 49.17it/s]\u001b[A\n","Epoch 3:  98% 33522/34216 [45:44<00:56, 12.22it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33528/34216 [45:44<00:56, 12.22it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33534/34216 [45:44<00:55, 12.22it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33540/34216 [45:44<00:55, 12.22it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33546/34216 [45:44<00:54, 12.22it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33552/34216 [45:44<00:54, 12.22it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33558/34216 [45:45<00:53, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33564/34216 [45:45<00:53, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  83% 3113/3765 [01:04<00:13, 49.61it/s]\u001b[A\n","Epoch 3:  98% 33570/34216 [45:45<00:52, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33576/34216 [45:45<00:52, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33582/34216 [45:45<00:51, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33588/34216 [45:45<00:51, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33594/34216 [45:45<00:50, 12.23it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  83% 3143/3765 [01:04<00:12, 48.31it/s]\u001b[A\n","Epoch 3:  98% 33600/34216 [45:45<00:50, 12.24it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33606/34216 [45:45<00:49, 12.24it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33612/34216 [45:46<00:49, 12.24it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33618/34216 [45:46<00:48, 12.24it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33624/34216 [45:46<00:48, 12.24it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  84% 3173/3765 [01:05<00:13, 45.19it/s]\u001b[A\n","Epoch 3:  98% 33630/34216 [45:46<00:47, 12.24it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33636/34216 [45:46<00:47, 12.25it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33642/34216 [45:46<00:46, 12.25it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33648/34216 [45:46<00:46, 12.25it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33654/34216 [45:47<00:45, 12.25it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  85% 3203/3765 [01:06<00:11, 47.53it/s]\u001b[A\n","Epoch 3:  98% 33660/34216 [45:47<00:45, 12.25it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33666/34216 [45:47<00:44, 12.25it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33672/34216 [45:47<00:44, 12.26it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33678/34216 [45:47<00:43, 12.26it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33684/34216 [45:47<00:43, 12.26it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  86% 3233/3765 [01:06<00:11, 45.58it/s]\u001b[A\n","Epoch 3:  98% 33690/34216 [45:47<00:42, 12.26it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33696/34216 [45:47<00:42, 12.26it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  98% 33702/34216 [45:48<00:41, 12.26it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33708/34216 [45:48<00:41, 12.27it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33714/34216 [45:48<00:40, 12.27it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  87% 3263/3765 [01:07<00:11, 44.92it/s]\u001b[A\n","Epoch 3:  99% 33720/34216 [45:48<00:40, 12.27it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33726/34216 [45:48<00:39, 12.27it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33732/34216 [45:48<00:39, 12.27it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33738/34216 [45:48<00:38, 12.27it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33744/34216 [45:48<00:38, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  87% 3293/3765 [01:08<00:09, 47.63it/s]\u001b[A\n","Epoch 3:  99% 33750/34216 [45:49<00:37, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33756/34216 [45:49<00:37, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33762/34216 [45:49<00:36, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33768/34216 [45:49<00:36, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33774/34216 [45:49<00:35, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  88% 3323/3765 [01:08<00:09, 47.89it/s]\u001b[A\n","Epoch 3:  99% 33780/34216 [45:49<00:35, 12.28it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33786/34216 [45:49<00:34, 12.29it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33792/34216 [45:49<00:34, 12.29it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33798/34216 [45:50<00:34, 12.29it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33804/34216 [45:50<00:33, 12.29it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  89% 3353/3765 [01:09<00:08, 48.40it/s]\u001b[A\n","Epoch 3:  99% 33810/34216 [45:50<00:33, 12.29it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33816/34216 [45:50<00:32, 12.29it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33822/34216 [45:50<00:32, 12.30it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33828/34216 [45:50<00:31, 12.30it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33834/34216 [45:50<00:31, 12.30it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  90% 3383/3765 [01:09<00:07, 47.90it/s]\u001b[A\n","Epoch 3:  99% 33840/34216 [45:50<00:30, 12.30it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33846/34216 [45:51<00:30, 12.30it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33852/34216 [45:51<00:29, 12.30it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33858/34216 [45:51<00:29, 12.31it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33864/34216 [45:51<00:28, 12.31it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  91% 3413/3765 [01:10<00:07, 48.68it/s]\u001b[A\n","Epoch 3:  99% 33870/34216 [45:51<00:28, 12.31it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33876/34216 [45:51<00:27, 12.31it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33882/34216 [45:51<00:27, 12.31it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33888/34216 [45:51<00:26, 12.31it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33894/34216 [45:52<00:26, 12.32it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  91% 3443/3765 [01:11<00:06, 48.44it/s]\u001b[A\n","Epoch 3:  99% 33900/34216 [45:52<00:25, 12.32it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33906/34216 [45:52<00:25, 12.32it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33912/34216 [45:52<00:24, 12.32it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33918/34216 [45:52<00:24, 12.32it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33924/34216 [45:52<00:23, 12.32it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  92% 3473/3765 [01:11<00:06, 47.76it/s]\u001b[A\n","Epoch 3:  99% 33930/34216 [45:52<00:23, 12.33it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33936/34216 [45:52<00:22, 12.33it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33942/34216 [45:53<00:22, 12.33it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33948/34216 [45:53<00:21, 12.33it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33954/34216 [45:53<00:21, 12.33it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  93% 3503/3765 [01:12<00:05, 48.61it/s]\u001b[A\n","Epoch 3:  99% 33960/34216 [45:53<00:20, 12.33it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33966/34216 [45:53<00:20, 12.34it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33972/34216 [45:53<00:19, 12.34it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33978/34216 [45:53<00:19, 12.34it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33984/34216 [45:53<00:18, 12.34it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  94% 3533/3765 [01:13<00:04, 48.63it/s]\u001b[A\n","Epoch 3:  99% 33990/34216 [45:54<00:18, 12.34it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 33996/34216 [45:54<00:17, 12.34it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34002/34216 [45:54<00:17, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34008/34216 [45:54<00:16, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34014/34216 [45:54<00:16, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  95% 3563/3765 [01:13<00:04, 49.20it/s]\u001b[A\n","Epoch 3:  99% 34020/34216 [45:54<00:15, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34026/34216 [45:54<00:15, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34032/34216 [45:54<00:14, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34038/34216 [45:55<00:14, 12.35it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3:  99% 34044/34216 [45:55<00:13, 12.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  95% 3593/3765 [01:14<00:03, 48.33it/s]\u001b[A\n","Epoch 3: 100% 34050/34216 [45:55<00:13, 12.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34056/34216 [45:55<00:12, 12.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34062/34216 [45:55<00:12, 12.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34068/34216 [45:55<00:11, 12.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34074/34216 [45:55<00:11, 12.36it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  96% 3623/3765 [01:14<00:02, 48.19it/s]\u001b[A\n","Epoch 3: 100% 34080/34216 [45:55<00:10, 12.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34086/34216 [45:56<00:10, 12.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34092/34216 [45:56<00:10, 12.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34098/34216 [45:56<00:09, 12.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34104/34216 [45:56<00:09, 12.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  97% 3653/3765 [01:15<00:02, 48.55it/s]\u001b[A\n","Epoch 3: 100% 34110/34216 [45:56<00:08, 12.37it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34116/34216 [45:56<00:08, 12.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34122/34216 [45:56<00:07, 12.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34128/34216 [45:56<00:07, 12.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34134/34216 [45:57<00:06, 12.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  98% 3683/3765 [01:16<00:01, 48.31it/s]\u001b[A\n","Epoch 3: 100% 34140/34216 [45:57<00:06, 12.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34146/34216 [45:57<00:05, 12.38it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34152/34216 [45:57<00:05, 12.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34158/34216 [45:57<00:04, 12.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34164/34216 [45:57<00:04, 12.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  99% 3713/3765 [01:16<00:01, 48.44it/s]\u001b[A\n","Epoch 3: 100% 34170/34216 [45:57<00:03, 12.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34176/34216 [45:57<00:03, 12.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34182/34216 [45:58<00:02, 12.39it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34188/34216 [45:58<00:02, 12.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34194/34216 [45:58<00:01, 12.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Validating:  99% 3743/3765 [01:17<00:00, 48.73it/s]\u001b[A\n","Epoch 3: 100% 34200/34216 [45:58<00:01, 12.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34206/34216 [45:58<00:00, 12.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34212/34216 [45:58<00:00, 12.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.490]\n","Epoch 3: 100% 34216/34216 [45:58<00:00, 12.40it/s, loss=1.33, v_num=4, train_loss=1.580, val_loss=1.520]\n","                                                   \u001b[AEpoch 3, global step 121803: val_loss was not in top 3\n","Epoch 4:  89% 30451/34216 [44:35<05:30, 11.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  89% 30456/34216 [44:36<05:30, 11.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30462/34216 [44:36<05:29, 11.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30468/34216 [44:36<05:29, 11.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30474/34216 [44:36<05:28, 11.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30480/34216 [44:36<05:28, 11.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   1% 29/3765 [00:01<01:32, 40.52it/s]\u001b[A\n","Epoch 4:  89% 30486/34216 [44:37<05:27, 11.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30492/34216 [44:37<05:26, 11.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30498/34216 [44:37<05:26, 11.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30504/34216 [44:37<05:25, 11.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30510/34216 [44:37<05:25, 11.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30516/34216 [44:37<05:24, 11.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30522/34216 [44:37<05:24, 11.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30528/34216 [44:37<05:23, 11.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30534/34216 [44:38<05:22, 11.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   2% 83/3765 [00:02<01:15, 48.69it/s]\u001b[A\n","Epoch 4:  89% 30540/34216 [44:38<05:22, 11.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30546/34216 [44:38<05:21, 11.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30552/34216 [44:38<05:21, 11.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30558/34216 [44:38<05:20, 11.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30564/34216 [44:38<05:20, 11.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   3% 113/3765 [00:02<01:13, 49.36it/s]\u001b[A\n","Epoch 4:  89% 30570/34216 [44:38<05:19, 11.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30576/34216 [44:38<05:18, 11.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30582/34216 [44:39<05:18, 11.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30588/34216 [44:39<05:17, 11.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30594/34216 [44:39<05:17, 11.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   4% 143/3765 [00:03<01:13, 49.39it/s]\u001b[A\n","Epoch 4:  89% 30600/34216 [44:39<05:16, 11.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30606/34216 [44:39<05:16, 11.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30612/34216 [44:39<05:15, 11.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  89% 30618/34216 [44:39<05:14, 11.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30624/34216 [44:39<05:14, 11.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30630/34216 [44:40<05:13, 11.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   5% 179/3765 [00:04<01:14, 48.33it/s]\u001b[A\n","Epoch 4:  90% 30636/34216 [44:40<05:13, 11.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30642/34216 [44:40<05:12, 11.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30648/34216 [44:40<05:12, 11.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30654/34216 [44:40<05:11, 11.44it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30660/34216 [44:40<05:10, 11.44it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30666/34216 [44:40<05:10, 11.44it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30672/34216 [44:40<05:09, 11.44it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30678/34216 [44:40<05:09, 11.44it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30684/34216 [44:41<05:08, 11.44it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30690/34216 [44:41<05:08, 11.45it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30696/34216 [44:41<05:07, 11.45it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30702/34216 [44:41<05:06, 11.45it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30708/34216 [44:41<05:06, 11.45it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   7% 257/3765 [00:05<01:11, 49.06it/s]\u001b[A\n","Epoch 4:  90% 30714/34216 [44:41<05:05, 11.45it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30720/34216 [44:41<05:05, 11.45it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30726/34216 [44:41<05:04, 11.46it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30732/34216 [44:42<05:04, 11.46it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30738/34216 [44:42<05:03, 11.46it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30744/34216 [44:42<05:02, 11.46it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30750/34216 [44:42<05:02, 11.46it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30756/34216 [44:42<05:01, 11.47it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30762/34216 [44:42<05:01, 11.47it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30768/34216 [44:42<05:00, 11.47it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30774/34216 [44:42<05:00, 11.47it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30780/34216 [44:43<04:59, 11.47it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30786/34216 [44:43<04:58, 11.47it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30792/34216 [44:43<04:58, 11.48it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30798/34216 [44:43<04:57, 11.48it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30804/34216 [44:43<04:57, 11.48it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:   9% 353/3765 [00:07<01:08, 49.65it/s]\u001b[A\n","Epoch 4:  90% 30810/34216 [44:43<04:56, 11.48it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30816/34216 [44:43<04:56, 11.48it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30822/34216 [44:43<04:55, 11.48it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30828/34216 [44:44<04:54, 11.49it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30834/34216 [44:44<04:54, 11.49it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  10% 383/3765 [00:08<01:13, 46.25it/s]\u001b[A\n","Epoch 4:  90% 30840/34216 [44:44<04:53, 11.49it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30846/34216 [44:44<04:53, 11.49it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30852/34216 [44:44<04:52, 11.49it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30858/34216 [44:44<04:52, 11.49it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30864/34216 [44:44<04:51, 11.50it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  11% 413/3765 [00:08<01:13, 45.82it/s]\u001b[A\n","Epoch 4:  90% 30870/34216 [44:44<04:51, 11.50it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30876/34216 [44:45<04:50, 11.50it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30882/34216 [44:45<04:49, 11.50it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30888/34216 [44:45<04:49, 11.50it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30894/34216 [44:45<04:48, 11.50it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  12% 443/3765 [00:09<01:11, 46.40it/s]\u001b[A\n","Epoch 4:  90% 30900/34216 [44:45<04:48, 11.51it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30906/34216 [44:45<04:47, 11.51it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30912/34216 [44:45<04:47, 11.51it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30918/34216 [44:45<04:46, 11.51it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30924/34216 [44:46<04:45, 11.51it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  13% 473/3765 [00:10<01:12, 45.48it/s]\u001b[A\n","Epoch 4:  90% 30930/34216 [44:46<04:45, 11.51it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30936/34216 [44:46<04:44, 11.52it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30942/34216 [44:46<04:44, 11.52it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30948/34216 [44:46<04:43, 11.52it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  90% 30954/34216 [44:46<04:43, 11.52it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  13% 503/3765 [00:10<01:10, 46.12it/s]\u001b[A\n","Epoch 4:  90% 30960/34216 [44:46<04:42, 11.52it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 30966/34216 [44:47<04:42, 11.52it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 30972/34216 [44:47<04:41, 11.53it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 30978/34216 [44:47<04:40, 11.53it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 30984/34216 [44:47<04:40, 11.53it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  14% 533/3765 [00:11<01:10, 46.07it/s]\u001b[A\n","Epoch 4:  91% 30990/34216 [44:47<04:39, 11.53it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 30996/34216 [44:47<04:39, 11.53it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31002/34216 [44:47<04:38, 11.53it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31008/34216 [44:47<04:38, 11.54it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31014/34216 [44:48<04:37, 11.54it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31020/34216 [44:48<04:36, 11.54it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31026/34216 [44:48<04:36, 11.54it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31032/34216 [44:48<04:35, 11.54it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31038/34216 [44:48<04:35, 11.54it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31044/34216 [44:48<04:34, 11.55it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31050/34216 [44:48<04:34, 11.55it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31056/34216 [44:48<04:33, 11.55it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31062/34216 [44:48<04:33, 11.55it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31068/34216 [44:49<04:32, 11.55it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31074/34216 [44:49<04:31, 11.55it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31080/34216 [44:49<04:31, 11.56it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31086/34216 [44:49<04:30, 11.56it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31092/34216 [44:49<04:30, 11.56it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31098/34216 [44:49<04:29, 11.56it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31104/34216 [44:49<04:29, 11.56it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31110/34216 [44:49<04:28, 11.57it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31116/34216 [44:50<04:28, 11.57it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31122/34216 [44:50<04:27, 11.57it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31128/34216 [44:50<04:26, 11.57it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31134/34216 [44:50<04:26, 11.57it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31140/34216 [44:50<04:25, 11.57it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31146/34216 [44:50<04:25, 11.58it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31152/34216 [44:50<04:24, 11.58it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31158/34216 [44:50<04:24, 11.58it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31164/34216 [44:51<04:23, 11.58it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31170/34216 [44:51<04:22, 11.58it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31176/34216 [44:51<04:22, 11.58it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31182/34216 [44:51<04:21, 11.59it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31188/34216 [44:51<04:21, 11.59it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31194/34216 [44:51<04:20, 11.59it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31200/34216 [44:51<04:20, 11.59it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  20% 749/3765 [00:15<01:01, 48.81it/s]\u001b[A\n","Epoch 4:  91% 31206/34216 [44:51<04:19, 11.59it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31212/34216 [44:51<04:19, 11.59it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31218/34216 [44:52<04:18, 11.60it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31224/34216 [44:52<04:17, 11.60it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31230/34216 [44:52<04:17, 11.60it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  21% 779/3765 [00:16<01:01, 48.36it/s]\u001b[A\n","Epoch 4:  91% 31236/34216 [44:52<04:16, 11.60it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31242/34216 [44:52<04:16, 11.60it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31248/34216 [44:52<04:15, 11.60it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31254/34216 [44:52<04:15, 11.61it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31260/34216 [44:52<04:14, 11.61it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  21% 809/3765 [00:17<01:00, 48.49it/s]\u001b[A\n","Epoch 4:  91% 31266/34216 [44:53<04:14, 11.61it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31272/34216 [44:53<04:13, 11.61it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31278/34216 [44:53<04:12, 11.61it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31284/34216 [44:53<04:12, 11.61it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31290/34216 [44:53<04:11, 11.62it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  22% 839/3765 [00:17<01:00, 48.47it/s]\u001b[A\n","Epoch 4:  91% 31296/34216 [44:53<04:11, 11.62it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  91% 31302/34216 [44:53<04:10, 11.62it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31308/34216 [44:53<04:10, 11.62it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31314/34216 [44:54<04:09, 11.62it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31320/34216 [44:54<04:09, 11.62it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  23% 869/3765 [00:18<01:00, 48.21it/s]\u001b[A\n","Epoch 4:  92% 31326/34216 [44:54<04:08, 11.63it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31332/34216 [44:54<04:08, 11.63it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31338/34216 [44:54<04:07, 11.63it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31344/34216 [44:54<04:06, 11.63it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31350/34216 [44:54<04:06, 11.63it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  24% 899/3765 [00:18<00:59, 48.30it/s]\u001b[A\n","Epoch 4:  92% 31356/34216 [44:54<04:05, 11.63it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31362/34216 [44:55<04:05, 11.64it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31368/34216 [44:55<04:04, 11.64it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31374/34216 [44:55<04:04, 11.64it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31380/34216 [44:55<04:03, 11.64it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  25% 929/3765 [00:19<00:57, 49.03it/s]\u001b[A\n","Epoch 4:  92% 31386/34216 [44:55<04:03, 11.64it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31392/34216 [44:55<04:02, 11.65it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31398/34216 [44:55<04:01, 11.65it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31404/34216 [44:55<04:01, 11.65it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31410/34216 [44:56<04:00, 11.65it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  25% 959/3765 [00:20<00:57, 48.99it/s]\u001b[A\n","Epoch 4:  92% 31416/34216 [44:56<04:00, 11.65it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31422/34216 [44:56<03:59, 11.65it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31428/34216 [44:56<03:59, 11.66it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31434/34216 [44:56<03:58, 11.66it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31440/34216 [44:56<03:58, 11.66it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  26% 989/3765 [00:20<00:57, 48.10it/s]\u001b[A\n","Epoch 4:  92% 31446/34216 [44:56<03:57, 11.66it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31452/34216 [44:56<03:57, 11.66it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31458/34216 [44:57<03:56, 11.66it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31464/34216 [44:57<03:55, 11.67it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31470/34216 [44:57<03:55, 11.67it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  27% 1019/3765 [00:21<00:56, 48.38it/s]\u001b[A\n","Epoch 4:  92% 31476/34216 [44:57<03:54, 11.67it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31482/34216 [44:57<03:54, 11.67it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31488/34216 [44:57<03:53, 11.67it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31494/34216 [44:57<03:53, 11.67it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31500/34216 [44:57<03:52, 11.68it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  28% 1049/3765 [00:22<00:56, 48.36it/s]\u001b[A\n","Epoch 4:  92% 31506/34216 [44:58<03:52, 11.68it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31512/34216 [44:58<03:51, 11.68it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31518/34216 [44:58<03:50, 11.68it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31524/34216 [44:58<03:50, 11.68it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31530/34216 [44:58<03:49, 11.68it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  29% 1079/3765 [00:22<00:55, 48.83it/s]\u001b[A\n","Epoch 4:  92% 31536/34216 [44:58<03:49, 11.69it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31542/34216 [44:58<03:48, 11.69it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31548/34216 [44:58<03:48, 11.69it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31554/34216 [44:59<03:47, 11.69it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31560/34216 [44:59<03:47, 11.69it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31566/34216 [44:59<03:46, 11.69it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  30% 1115/3765 [00:23<00:57, 45.86it/s]\u001b[A\n","Epoch 4:  92% 31572/34216 [44:59<03:46, 11.70it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31578/34216 [44:59<03:45, 11.70it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31584/34216 [44:59<03:44, 11.70it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31590/34216 [44:59<03:44, 11.70it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31596/34216 [45:00<03:43, 11.70it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  30% 1145/3765 [00:24<00:57, 45.82it/s]\u001b[A\n","Epoch 4:  92% 31602/34216 [45:00<03:43, 11.70it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31608/34216 [45:00<03:42, 11.71it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31614/34216 [45:00<03:42, 11.71it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31620/34216 [45:00<03:41, 11.71it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31626/34216 [45:00<03:41, 11.71it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  31% 1175/3765 [00:24<00:57, 44.86it/s]\u001b[A\n","Epoch 4:  92% 31632/34216 [45:00<03:40, 11.71it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31638/34216 [45:00<03:40, 11.71it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  92% 31644/34216 [45:01<03:39, 11.72it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31650/34216 [45:01<03:38, 11.72it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31656/34216 [45:01<03:38, 11.72it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  32% 1205/3765 [00:25<00:52, 48.59it/s]\u001b[A\n","Epoch 4:  93% 31662/34216 [45:01<03:37, 11.72it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31668/34216 [45:01<03:37, 11.72it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31674/34216 [45:01<03:36, 11.72it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31680/34216 [45:01<03:36, 11.73it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31686/34216 [45:01<03:35, 11.73it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31692/34216 [45:02<03:35, 11.73it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31698/34216 [45:02<03:34, 11.73it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31704/34216 [45:02<03:34, 11.73it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  33% 1253/3765 [00:26<00:50, 49.82it/s]\u001b[A\n","Epoch 4:  93% 31710/34216 [45:02<03:33, 11.73it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31716/34216 [45:02<03:33, 11.74it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31722/34216 [45:02<03:32, 11.74it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31728/34216 [45:02<03:31, 11.74it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31734/34216 [45:02<03:31, 11.74it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31740/34216 [45:03<03:30, 11.74it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31746/34216 [45:03<03:30, 11.74it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  34% 1295/3765 [00:27<00:49, 49.49it/s]\u001b[A\n","Epoch 4:  93% 31752/34216 [45:03<03:29, 11.75it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31758/34216 [45:03<03:29, 11.75it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31764/34216 [45:03<03:28, 11.75it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31770/34216 [45:03<03:28, 11.75it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31776/34216 [45:03<03:27, 11.75it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  35% 1325/3765 [00:27<00:49, 49.23it/s]\u001b[A\n","Epoch 4:  93% 31782/34216 [45:03<03:27, 11.75it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31788/34216 [45:03<03:26, 11.76it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31794/34216 [45:04<03:25, 11.76it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31800/34216 [45:04<03:25, 11.76it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31806/34216 [45:04<03:24, 11.76it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31812/34216 [45:04<03:24, 11.76it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  36% 1361/3765 [00:28<00:48, 49.43it/s]\u001b[A\n","Epoch 4:  93% 31818/34216 [45:04<03:23, 11.76it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31824/34216 [45:04<03:23, 11.77it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31830/34216 [45:04<03:22, 11.77it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31836/34216 [45:04<03:22, 11.77it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31842/34216 [45:05<03:21, 11.77it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31848/34216 [45:05<03:21, 11.77it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31854/34216 [45:05<03:20, 11.77it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  37% 1403/3765 [00:29<00:47, 49.82it/s]\u001b[A\n","Epoch 4:  93% 31860/34216 [45:05<03:20, 11.78it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31866/34216 [45:05<03:19, 11.78it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31872/34216 [45:05<03:18, 11.78it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31878/34216 [45:05<03:18, 11.78it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31884/34216 [45:05<03:17, 11.78it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  38% 1433/3765 [00:30<00:46, 49.68it/s]\u001b[A\n","Epoch 4:  93% 31890/34216 [45:06<03:17, 11.78it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31896/34216 [45:06<03:16, 11.79it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31902/34216 [45:06<03:16, 11.79it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31908/34216 [45:06<03:15, 11.79it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31914/34216 [45:06<03:15, 11.79it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31920/34216 [45:06<03:14, 11.79it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31926/34216 [45:06<03:14, 11.79it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31932/34216 [45:06<03:13, 11.80it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31938/34216 [45:06<03:13, 11.80it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31944/34216 [45:07<03:12, 11.80it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31950/34216 [45:07<03:12, 11.80it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  40% 1499/3765 [00:31<00:45, 49.47it/s]\u001b[A\n","Epoch 4:  93% 31956/34216 [45:07<03:11, 11.80it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31962/34216 [45:07<03:10, 11.81it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31968/34216 [45:07<03:10, 11.81it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31974/34216 [45:07<03:09, 11.81it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31980/34216 [45:07<03:09, 11.81it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  93% 31986/34216 [45:07<03:08, 11.81it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 31992/34216 [45:08<03:08, 11.81it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 31998/34216 [45:08<03:07, 11.82it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32004/34216 [45:08<03:07, 11.82it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  41% 1553/3765 [00:32<00:44, 49.82it/s]\u001b[A\n","Epoch 4:  94% 32010/34216 [45:08<03:06, 11.82it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32016/34216 [45:08<03:06, 11.82it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32022/34216 [45:08<03:05, 11.82it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32028/34216 [45:08<03:05, 11.82it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32034/34216 [45:08<03:04, 11.83it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32040/34216 [45:09<03:03, 11.83it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32046/34216 [45:09<03:03, 11.83it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32052/34216 [45:09<03:02, 11.83it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32058/34216 [45:09<03:02, 11.83it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32064/34216 [45:09<03:01, 11.83it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32070/34216 [45:09<03:01, 11.84it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32076/34216 [45:09<03:00, 11.84it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32082/34216 [45:09<03:00, 11.84it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  43% 1631/3765 [00:33<00:42, 49.72it/s]\u001b[A\n","Epoch 4:  94% 32088/34216 [45:10<02:59, 11.84it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32094/34216 [45:10<02:59, 11.84it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32100/34216 [45:10<02:58, 11.84it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32106/34216 [45:10<02:58, 11.85it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32112/34216 [45:10<02:57, 11.85it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32118/34216 [45:10<02:57, 11.85it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  44% 1667/3765 [00:34<00:42, 49.33it/s]\u001b[A\n","Epoch 4:  94% 32124/34216 [45:10<02:56, 11.85it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32130/34216 [45:10<02:55, 11.85it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32136/34216 [45:10<02:55, 11.85it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32142/34216 [45:11<02:54, 11.86it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32148/34216 [45:11<02:54, 11.86it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32154/34216 [45:11<02:53, 11.86it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32160/34216 [45:11<02:53, 11.86it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32166/34216 [45:11<02:52, 11.86it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32172/34216 [45:11<02:52, 11.86it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  46% 1721/3765 [00:35<00:44, 46.05it/s]\u001b[A\n","Epoch 4:  94% 32178/34216 [45:11<02:51, 11.87it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32184/34216 [45:12<02:51, 11.87it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32190/34216 [45:12<02:50, 11.87it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32196/34216 [45:12<02:50, 11.87it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32202/34216 [45:12<02:49, 11.87it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  47% 1751/3765 [00:36<00:43, 46.07it/s]\u001b[A\n","Epoch 4:  94% 32208/34216 [45:12<02:49, 11.87it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32214/34216 [45:12<02:48, 11.88it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32220/34216 [45:12<02:48, 11.88it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32226/34216 [45:12<02:47, 11.88it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32232/34216 [45:13<02:46, 11.88it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32238/34216 [45:13<02:46, 11.88it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  47% 1787/3765 [00:37<00:42, 47.07it/s]\u001b[A\n","Epoch 4:  94% 32244/34216 [45:13<02:45, 11.88it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32250/34216 [45:13<02:45, 11.89it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32256/34216 [45:13<02:44, 11.89it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32262/34216 [45:13<02:44, 11.89it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32268/34216 [45:13<02:43, 11.89it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  48% 1817/3765 [00:37<00:40, 48.30it/s]\u001b[A\n","Epoch 4:  94% 32274/34216 [45:13<02:43, 11.89it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32280/34216 [45:14<02:42, 11.89it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32286/34216 [45:14<02:42, 11.90it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32292/34216 [45:14<02:41, 11.90it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32298/34216 [45:14<02:41, 11.90it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32304/34216 [45:14<02:40, 11.90it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  49% 1853/3765 [00:38<00:38, 49.54it/s]\u001b[A\n","Epoch 4:  94% 32310/34216 [45:14<02:40, 11.90it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32316/34216 [45:14<02:39, 11.90it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32322/34216 [45:14<02:39, 11.91it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32328/34216 [45:15<02:38, 11.91it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  94% 32334/34216 [45:15<02:38, 11.91it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32340/34216 [45:15<02:37, 11.91it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  50% 1889/3765 [00:39<00:38, 48.80it/s]\u001b[A\n","Epoch 4:  95% 32346/34216 [45:15<02:36, 11.91it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32352/34216 [45:15<02:36, 11.91it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32358/34216 [45:15<02:35, 11.92it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32364/34216 [45:15<02:35, 11.92it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32370/34216 [45:15<02:34, 11.92it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32376/34216 [45:15<02:34, 11.92it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32382/34216 [45:16<02:33, 11.92it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32388/34216 [45:16<02:33, 11.92it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32394/34216 [45:16<02:32, 11.93it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32400/34216 [45:16<02:32, 11.93it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32406/34216 [45:16<02:31, 11.93it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32412/34216 [45:16<02:31, 11.93it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32418/34216 [45:16<02:30, 11.93it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32424/34216 [45:16<02:30, 11.93it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32430/34216 [45:17<02:29, 11.94it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32436/34216 [45:17<02:29, 11.94it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32442/34216 [45:17<02:28, 11.94it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32448/34216 [45:17<02:28, 11.94it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32454/34216 [45:17<02:27, 11.94it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32460/34216 [45:17<02:27, 11.94it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32466/34216 [45:17<02:26, 11.95it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32472/34216 [45:17<02:25, 11.95it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32478/34216 [45:18<02:25, 11.95it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32484/34216 [45:18<02:24, 11.95it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32490/34216 [45:18<02:24, 11.95it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32496/34216 [45:18<02:23, 11.95it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32502/34216 [45:18<02:23, 11.96it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32508/34216 [45:18<02:22, 11.96it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32514/34216 [45:18<02:22, 11.96it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32520/34216 [45:18<02:21, 11.96it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32526/34216 [45:18<02:21, 11.96it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  55% 2075/3765 [00:43<00:34, 49.13it/s]\u001b[A\n","Epoch 4:  95% 32532/34216 [45:19<02:20, 11.96it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32538/34216 [45:19<02:20, 11.97it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32544/34216 [45:19<02:19, 11.97it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32550/34216 [45:19<02:19, 11.97it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32556/34216 [45:19<02:18, 11.97it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32562/34216 [45:19<02:18, 11.97it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32568/34216 [45:19<02:17, 11.97it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  56% 2117/3765 [00:43<00:33, 49.51it/s]\u001b[A\n","Epoch 4:  95% 32574/34216 [45:19<02:17, 11.98it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32580/34216 [45:20<02:16, 11.98it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32586/34216 [45:20<02:16, 11.98it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32592/34216 [45:20<02:15, 11.98it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32598/34216 [45:20<02:15, 11.98it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32604/34216 [45:20<02:14, 11.98it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  57% 2153/3765 [00:44<00:32, 49.78it/s]\u001b[A\n","Epoch 4:  95% 32610/34216 [45:20<02:13, 11.99it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32616/34216 [45:20<02:13, 11.99it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32622/34216 [45:20<02:12, 11.99it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32628/34216 [45:21<02:12, 11.99it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32634/34216 [45:21<02:11, 11.99it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32640/34216 [45:21<02:11, 11.99it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32646/34216 [45:21<02:10, 12.00it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32652/34216 [45:21<02:10, 12.00it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32658/34216 [45:21<02:09, 12.00it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  59% 2207/3765 [00:45<00:32, 48.14it/s]\u001b[A\n","Epoch 4:  95% 32664/34216 [45:21<02:09, 12.00it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32670/34216 [45:21<02:08, 12.00it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  95% 32676/34216 [45:22<02:08, 12.00it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32682/34216 [45:22<02:07, 12.01it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32688/34216 [45:22<02:07, 12.01it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32694/34216 [45:22<02:06, 12.01it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32700/34216 [45:22<02:06, 12.01it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32706/34216 [45:22<02:05, 12.01it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32712/34216 [45:22<02:05, 12.01it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32718/34216 [45:22<02:04, 12.02it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32724/34216 [45:22<02:04, 12.02it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32730/34216 [45:23<02:03, 12.02it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32736/34216 [45:23<02:03, 12.02it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32742/34216 [45:23<02:02, 12.02it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  61% 2291/3765 [00:47<00:29, 49.28it/s]\u001b[A\n","Epoch 4:  96% 32748/34216 [45:23<02:02, 12.02it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32754/34216 [45:23<02:01, 12.03it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32760/34216 [45:23<02:01, 12.03it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32766/34216 [45:23<02:00, 12.03it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32772/34216 [45:23<02:00, 12.03it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32778/34216 [45:24<01:59, 12.03it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32784/34216 [45:24<01:58, 12.03it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32790/34216 [45:24<01:58, 12.04it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32796/34216 [45:24<01:57, 12.04it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32802/34216 [45:24<01:57, 12.04it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32808/34216 [45:24<01:56, 12.04it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32814/34216 [45:24<01:56, 12.04it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32820/34216 [45:24<01:55, 12.04it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32826/34216 [45:25<01:55, 12.05it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32832/34216 [45:25<01:54, 12.05it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32838/34216 [45:25<01:54, 12.05it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32844/34216 [45:25<01:53, 12.05it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32850/34216 [45:25<01:53, 12.05it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32856/34216 [45:25<01:52, 12.05it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  64% 2405/3765 [00:49<00:27, 49.93it/s]\u001b[A\n","Epoch 4:  96% 32862/34216 [45:25<01:52, 12.06it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32868/34216 [45:25<01:51, 12.06it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32874/34216 [45:25<01:51, 12.06it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32880/34216 [45:26<01:50, 12.06it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32886/34216 [45:26<01:50, 12.06it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32892/34216 [45:26<01:49, 12.06it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32898/34216 [45:26<01:49, 12.07it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32904/34216 [45:26<01:48, 12.07it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32910/34216 [45:26<01:48, 12.07it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32916/34216 [45:26<01:47, 12.07it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32922/34216 [45:26<01:47, 12.07it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  66% 2471/3765 [00:51<00:26, 49.74it/s]\u001b[A\n","Epoch 4:  96% 32928/34216 [45:27<01:46, 12.07it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32934/34216 [45:27<01:46, 12.08it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32940/34216 [45:27<01:45, 12.08it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32946/34216 [45:27<01:45, 12.08it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32952/34216 [45:27<01:44, 12.08it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32958/34216 [45:27<01:44, 12.08it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32964/34216 [45:27<01:43, 12.08it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  67% 2513/3765 [00:51<00:25, 49.62it/s]\u001b[A\n","Epoch 4:  96% 32970/34216 [45:27<01:43, 12.09it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32976/34216 [45:28<01:42, 12.09it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32982/34216 [45:28<01:42, 12.09it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32988/34216 [45:28<01:41, 12.09it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 32994/34216 [45:28<01:41, 12.09it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  68% 2543/3765 [00:52<00:24, 49.53it/s]\u001b[A\n","Epoch 4:  96% 33000/34216 [45:28<01:40, 12.09it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 33006/34216 [45:28<01:40, 12.10it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 33012/34216 [45:28<01:39, 12.10it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  96% 33018/34216 [45:28<01:39, 12.10it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33024/34216 [45:29<01:38, 12.10it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33030/34216 [45:29<01:37, 12.10it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  68% 2579/3765 [00:53<00:24, 48.53it/s]\u001b[A\n","Epoch 4:  97% 33036/34216 [45:29<01:37, 12.10it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33042/34216 [45:29<01:36, 12.11it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33048/34216 [45:29<01:36, 12.11it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33054/34216 [45:29<01:35, 12.11it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33060/34216 [45:29<01:35, 12.11it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  69% 2609/3765 [00:53<00:25, 45.55it/s]\u001b[A\n","Epoch 4:  97% 33066/34216 [45:29<01:34, 12.11it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33072/34216 [45:30<01:34, 12.11it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33078/34216 [45:30<01:33, 12.12it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33084/34216 [45:30<01:33, 12.12it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33090/34216 [45:30<01:32, 12.12it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33096/34216 [45:30<01:32, 12.12it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33102/34216 [45:30<01:31, 12.12it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33108/34216 [45:30<01:31, 12.12it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33114/34216 [45:30<01:30, 12.13it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33120/34216 [45:30<01:30, 12.13it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33126/34216 [45:31<01:29, 12.13it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  71% 2675/3765 [00:55<00:22, 49.50it/s]\u001b[A\n","Epoch 4:  97% 33132/34216 [45:31<01:29, 12.13it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33138/34216 [45:31<01:28, 12.13it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33144/34216 [45:31<01:28, 12.13it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33150/34216 [45:31<01:27, 12.14it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33156/34216 [45:31<01:27, 12.14it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33162/34216 [45:31<01:26, 12.14it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33168/34216 [45:31<01:26, 12.14it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33174/34216 [45:32<01:25, 12.14it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33180/34216 [45:32<01:25, 12.14it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33186/34216 [45:32<01:24, 12.15it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33192/34216 [45:32<01:24, 12.15it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33198/34216 [45:32<01:23, 12.15it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33204/34216 [45:32<01:23, 12.15it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33210/34216 [45:32<01:22, 12.15it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33216/34216 [45:32<01:22, 12.15it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33222/34216 [45:33<01:21, 12.16it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33228/34216 [45:33<01:21, 12.16it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33234/34216 [45:33<01:20, 12.16it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33240/34216 [45:33<01:20, 12.16it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33246/34216 [45:33<01:19, 12.16it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33252/34216 [45:33<01:19, 12.16it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33258/34216 [45:33<01:18, 12.17it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33264/34216 [45:33<01:18, 12.17it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33270/34216 [45:34<01:17, 12.17it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33276/34216 [45:34<01:17, 12.17it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  75% 2825/3765 [00:58<00:18, 49.93it/s]\u001b[A\n","Epoch 4:  97% 33282/34216 [45:34<01:16, 12.17it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33288/34216 [45:34<01:16, 12.17it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33294/34216 [45:34<01:15, 12.18it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33300/34216 [45:34<01:15, 12.18it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33306/34216 [45:34<01:14, 12.18it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33312/34216 [45:34<01:14, 12.18it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33318/34216 [45:34<01:13, 12.18it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33324/34216 [45:35<01:13, 12.18it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33330/34216 [45:35<01:12, 12.19it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33336/34216 [45:35<01:12, 12.19it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33342/34216 [45:35<01:11, 12.19it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33348/34216 [45:35<01:11, 12.19it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33354/34216 [45:35<01:10, 12.19it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  97% 33360/34216 [45:35<01:10, 12.19it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33366/34216 [45:35<01:09, 12.20it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33372/34216 [45:36<01:09, 12.20it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33378/34216 [45:36<01:08, 12.20it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33384/34216 [45:36<01:08, 12.20it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33390/34216 [45:36<01:07, 12.20it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33396/34216 [45:36<01:07, 12.20it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33402/34216 [45:36<01:06, 12.21it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33408/34216 [45:36<01:06, 12.21it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33414/34216 [45:36<01:05, 12.21it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33420/34216 [45:37<01:05, 12.21it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  79% 2969/3765 [01:01<00:16, 49.24it/s]\u001b[A\n","Epoch 4:  98% 33426/34216 [45:37<01:04, 12.21it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33432/34216 [45:37<01:04, 12.21it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33438/34216 [45:37<01:03, 12.22it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33444/34216 [45:37<01:03, 12.22it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33450/34216 [45:37<01:02, 12.22it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  80% 2999/3765 [01:01<00:15, 49.50it/s]\u001b[A\n","Epoch 4:  98% 33456/34216 [45:37<01:02, 12.22it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33462/34216 [45:37<01:01, 12.22it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33468/34216 [45:37<01:01, 12.22it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33474/34216 [45:38<01:00, 12.23it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33480/34216 [45:38<01:00, 12.23it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33486/34216 [45:38<00:59, 12.23it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33492/34216 [45:38<00:59, 12.23it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33498/34216 [45:38<00:58, 12.23it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33504/34216 [45:38<00:58, 12.23it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33510/34216 [45:38<00:57, 12.24it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33516/34216 [45:38<00:57, 12.24it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33522/34216 [45:39<00:56, 12.24it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33528/34216 [45:39<00:56, 12.24it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  82% 3077/3765 [01:03<00:13, 49.50it/s]\u001b[A\n","Epoch 4:  98% 33534/34216 [45:39<00:55, 12.24it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33540/34216 [45:39<00:55, 12.24it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33546/34216 [45:39<00:54, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33552/34216 [45:39<00:54, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33558/34216 [45:39<00:53, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33564/34216 [45:39<00:53, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33570/34216 [45:40<00:52, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33576/34216 [45:40<00:52, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33582/34216 [45:40<00:51, 12.25it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33588/34216 [45:40<00:51, 12.26it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33594/34216 [45:40<00:50, 12.26it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33600/34216 [45:40<00:50, 12.26it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33606/34216 [45:40<00:49, 12.26it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33612/34216 [45:40<00:49, 12.26it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33618/34216 [45:40<00:48, 12.26it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33624/34216 [45:41<00:48, 12.27it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33630/34216 [45:41<00:47, 12.27it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33636/34216 [45:41<00:47, 12.27it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33642/34216 [45:41<00:46, 12.27it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33648/34216 [45:41<00:46, 12.27it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33654/34216 [45:41<00:45, 12.27it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33660/34216 [45:41<00:45, 12.28it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33666/34216 [45:41<00:44, 12.28it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33672/34216 [45:42<00:44, 12.28it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33678/34216 [45:42<00:43, 12.28it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  86% 3227/3765 [01:06<00:10, 49.37it/s]\u001b[A\n","Epoch 4:  98% 33684/34216 [45:42<00:43, 12.28it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33690/34216 [45:42<00:42, 12.28it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33696/34216 [45:42<00:42, 12.29it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  98% 33702/34216 [45:42<00:41, 12.29it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33708/34216 [45:42<00:41, 12.29it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  87% 3257/3765 [01:06<00:10, 49.31it/s]\u001b[A\n","Epoch 4:  99% 33714/34216 [45:42<00:40, 12.29it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33720/34216 [45:43<00:40, 12.29it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33726/34216 [45:43<00:39, 12.29it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33732/34216 [45:43<00:39, 12.30it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33738/34216 [45:43<00:38, 12.30it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33744/34216 [45:43<00:38, 12.30it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  87% 3293/3765 [01:07<00:09, 48.54it/s]\u001b[A\n","Epoch 4:  99% 33750/34216 [45:43<00:37, 12.30it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33756/34216 [45:43<00:37, 12.30it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33762/34216 [45:43<00:36, 12.30it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33768/34216 [45:44<00:36, 12.31it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33774/34216 [45:44<00:35, 12.31it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  88% 3323/3765 [01:08<00:08, 49.42it/s]\u001b[A\n","Epoch 4:  99% 33780/34216 [45:44<00:35, 12.31it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33786/34216 [45:44<00:34, 12.31it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33792/34216 [45:44<00:34, 12.31it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33798/34216 [45:44<00:33, 12.31it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33804/34216 [45:44<00:33, 12.32it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33810/34216 [45:44<00:32, 12.32it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33816/34216 [45:44<00:32, 12.32it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  89% 3365/3765 [01:09<00:07, 50.02it/s]\u001b[A\n","Epoch 4:  99% 33822/34216 [45:45<00:31, 12.32it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33828/34216 [45:45<00:31, 12.32it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33834/34216 [45:45<00:30, 12.32it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33840/34216 [45:45<00:30, 12.33it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33846/34216 [45:45<00:30, 12.33it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33852/34216 [45:45<00:29, 12.33it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33858/34216 [45:45<00:29, 12.33it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33864/34216 [45:45<00:28, 12.33it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33870/34216 [45:46<00:28, 12.33it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  91% 3419/3765 [01:10<00:07, 49.19it/s]\u001b[A\n","Epoch 4:  99% 33876/34216 [45:46<00:27, 12.34it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33882/34216 [45:46<00:27, 12.34it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33888/34216 [45:46<00:26, 12.34it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33894/34216 [45:46<00:26, 12.34it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33900/34216 [45:46<00:25, 12.34it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33906/34216 [45:46<00:25, 12.34it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  92% 3455/3765 [01:10<00:06, 49.16it/s]\u001b[A\n","Epoch 4:  99% 33912/34216 [45:46<00:24, 12.35it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33918/34216 [45:47<00:24, 12.35it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33924/34216 [45:47<00:23, 12.35it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33930/34216 [45:47<00:23, 12.35it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33936/34216 [45:47<00:22, 12.35it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33942/34216 [45:47<00:22, 12.35it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33948/34216 [45:47<00:21, 12.36it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33954/34216 [45:47<00:21, 12.36it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33960/34216 [45:47<00:20, 12.36it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33966/34216 [45:48<00:20, 12.36it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  93% 3515/3765 [01:12<00:05, 49.91it/s]\u001b[A\n","Epoch 4:  99% 33972/34216 [45:48<00:19, 12.36it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33978/34216 [45:48<00:19, 12.36it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33984/34216 [45:48<00:18, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33990/34216 [45:48<00:18, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 33996/34216 [45:48<00:17, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34002/34216 [45:48<00:17, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34008/34216 [45:48<00:16, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34014/34216 [45:49<00:16, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34020/34216 [45:49<00:15, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34026/34216 [45:49<00:15, 12.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  95% 3575/3765 [01:13<00:03, 49.59it/s]\u001b[A\n","Epoch 4:  99% 34032/34216 [45:49<00:14, 12.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34038/34216 [45:49<00:14, 12.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4:  99% 34044/34216 [45:49<00:13, 12.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34050/34216 [45:49<00:13, 12.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34056/34216 [45:49<00:12, 12.38it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34062/34216 [45:49<00:12, 12.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34068/34216 [45:50<00:11, 12.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34074/34216 [45:50<00:11, 12.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34080/34216 [45:50<00:10, 12.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34086/34216 [45:50<00:10, 12.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34092/34216 [45:50<00:10, 12.39it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34098/34216 [45:50<00:09, 12.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34104/34216 [45:50<00:09, 12.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34110/34216 [45:50<00:08, 12.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34116/34216 [45:51<00:08, 12.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34122/34216 [45:51<00:07, 12.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34128/34216 [45:51<00:07, 12.40it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34134/34216 [45:51<00:06, 12.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34140/34216 [45:51<00:06, 12.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34146/34216 [45:51<00:05, 12.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34152/34216 [45:51<00:05, 12.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34158/34216 [45:51<00:04, 12.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34164/34216 [45:52<00:04, 12.41it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34170/34216 [45:52<00:03, 12.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34176/34216 [45:52<00:03, 12.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Validating:  99% 3725/3765 [01:16<00:00, 49.95it/s]\u001b[A\n","Epoch 4: 100% 34182/34216 [45:52<00:02, 12.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34188/34216 [45:52<00:02, 12.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34194/34216 [45:52<00:01, 12.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34200/34216 [45:52<00:01, 12.42it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34206/34216 [45:52<00:00, 12.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34212/34216 [45:52<00:00, 12.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Epoch 4: 100% 34216/34216 [45:53<00:00, 12.43it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","                                                   \u001b[AEpoch 4, global step 152254: val_loss reached 1.51556 (best 1.49113), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=04-val_loss=1.516.ckpt\" as top 3\n","Epoch 4: 100% 34216/34216 [46:06<00:00, 12.37it/s, loss=1.27, v_num=4, train_loss=1.140, val_loss=1.520]\n","Saving latest checkpoint...\n"]}]},{"cell_type":"code","source":["!python train.py --gradient_clip_val 1.0 --max_epochs 5 --default_root_dir logs --gpus 1 --batch_size 8 --num_workers 4 --lr 3e-3 --max_len 256\n","'''\n","Epoch 0, global step 30450 : epoch=00-val_loss = 9.098\n","Epoch 1, global step 60901 : epoch=01-val_loss = 8.924\n","Epoch 2, global step 91352 : epoch=02-val_loss = 8.829\n","Epoch 3, global step 121803 : epoch=03-val_loss = 8.714\n","Epoch 4, global step 152254 : epoch=04-val_loss = 8.683\n","'''"],"metadata":{"id":"0WYRrbg48j5_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673935966018,"user_tz":-540,"elapsed":188986,"user":{"displayName":"Pollux Castor","userId":"08864791763715881407"}},"outputId":"f94e7559-b6d3-455f-cbb4-c8cdf8636303"},"id":"0WYRrbg48j5_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-17 02:19:09.427227: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Downloading: 100% 4.00/4.00 [00:00<00:00, 4.33kB/s]\n","Downloading: 100% 111/111 [00:00<00:00, 108kB/s]\n","Downloading: 100% 682k/682k [00:00<00:00, 4.67MB/s]\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=8, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=None, checkpoint_path=None, default_root_dir='logs', detect_anomaly=False, deterministic=False, devices=None, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, flush_logs_every_n_steps=None, gpus=1, gradient_clip_algorithm=None, gradient_clip_val=1.0, ipus=None, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=0.003, max_epochs=5, max_len=256, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, model_path=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=4, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=None, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, stochastic_weight_avg=False, strategy=None, sync_batchnorm=False, terminate_on_nan=None, test_file='data/test.tsv', tpu_cores=None, track_grad_norm=-1, train_file='data/train.tsv', val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Downloading: 100% 1.36k/1.36k [00:00<00:00, 1.17MB/s]\n","Downloading: 100% 496M/496M [00:12<00:00, 38.9MB/s]\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:root:number of workers 4, data length 30451\n","INFO:root:num_train_steps : 4757\n","INFO:root:num_warmup_steps : 475\n","\n","  | Name  | Type                         | Params\n","-------------------------------------------------------\n","0 | model | BartForConditionalGeneration | 123 M \n","-------------------------------------------------------\n","123 M     Trainable params\n","0         Non-trainable params\n","123 M     Total params\n","495.440   Total estimated model params size (MB)\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","Epoch 0:  89% 30451/34216 [43:57<05:26, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  89% 30453/34216 [43:57<05:25, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30458/34216 [43:57<05:25, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30463/34216 [43:57<05:24, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30468/34216 [43:57<05:24, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30473/34216 [43:58<05:24, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30478/34216 [43:58<05:23, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30483/34216 [43:58<05:23, 11.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30488/34216 [43:58<05:22, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30493/34216 [43:58<05:22, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30498/34216 [43:58<05:21, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30503/34216 [43:58<05:21, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30508/34216 [43:58<05:20, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30513/34216 [43:58<05:20, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30518/34216 [43:59<05:19, 11.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30523/34216 [43:59<05:19, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30528/34216 [43:59<05:18, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30533/34216 [43:59<05:18, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30538/34216 [43:59<05:17, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30543/34216 [43:59<05:17, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30548/34216 [43:59<05:16, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30553/34216 [43:59<05:16, 11.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30558/34216 [43:59<05:16, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30563/34216 [43:59<05:15, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30568/34216 [44:00<05:15, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30573/34216 [44:00<05:14, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30578/34216 [44:00<05:14, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30583/34216 [44:00<05:13, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30588/34216 [44:00<05:13, 11.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30593/34216 [44:00<05:12, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30598/34216 [44:00<05:12, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30603/34216 [44:00<05:11, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30608/34216 [44:00<05:11, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30613/34216 [44:01<05:10, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30618/34216 [44:01<05:10, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  89% 30623/34216 [44:01<05:09, 11.59it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30628/34216 [44:01<05:09, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30633/34216 [44:01<05:08, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30638/34216 [44:01<05:08, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30643/34216 [44:01<05:08, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30648/34216 [44:01<05:07, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30653/34216 [44:01<05:07, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30658/34216 [44:01<05:06, 11.60it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30663/34216 [44:02<05:06, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30668/34216 [44:02<05:05, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30673/34216 [44:02<05:05, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30678/34216 [44:02<05:04, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30683/34216 [44:02<05:04, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30688/34216 [44:02<05:03, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30693/34216 [44:02<05:03, 11.61it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30698/34216 [44:02<05:02, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30703/34216 [44:02<05:02, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30708/34216 [44:03<05:01, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30713/34216 [44:03<05:01, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30718/34216 [44:03<05:01, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30723/34216 [44:03<05:00, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30728/34216 [44:03<05:00, 11.62it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30733/34216 [44:03<04:59, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30738/34216 [44:03<04:59, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30743/34216 [44:03<04:58, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30748/34216 [44:04<04:58, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30753/34216 [44:04<04:57, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30758/34216 [44:04<04:57, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30763/34216 [44:04<04:56, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30768/34216 [44:04<04:56, 11.63it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30773/34216 [44:04<04:55, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30778/34216 [44:04<04:55, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30783/34216 [44:04<04:54, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30788/34216 [44:04<04:54, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30793/34216 [44:05<04:54, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30798/34216 [44:05<04:53, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30803/34216 [44:05<04:53, 11.64it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30808/34216 [44:05<04:52, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30813/34216 [44:05<04:52, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30818/34216 [44:05<04:51, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30823/34216 [44:05<04:51, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30828/34216 [44:05<04:50, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30833/34216 [44:05<04:50, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30838/34216 [44:05<04:49, 11.65it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30843/34216 [44:06<04:49, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30848/34216 [44:06<04:48, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30853/34216 [44:06<04:48, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30858/34216 [44:06<04:47, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30863/34216 [44:06<04:47, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30868/34216 [44:06<04:47, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30873/34216 [44:06<04:46, 11.66it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30878/34216 [44:06<04:46, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30883/34216 [44:06<04:45, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30888/34216 [44:07<04:45, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30893/34216 [44:07<04:44, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30898/34216 [44:07<04:44, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30903/34216 [44:07<04:43, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30908/34216 [44:07<04:43, 11.67it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30913/34216 [44:07<04:42, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30918/34216 [44:07<04:42, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30923/34216 [44:07<04:41, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30928/34216 [44:07<04:41, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30933/34216 [44:08<04:41, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30938/34216 [44:08<04:40, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30943/34216 [44:08<04:40, 11.68it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30948/34216 [44:08<04:39, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30953/34216 [44:08<04:39, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30958/34216 [44:08<04:38, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  90% 30963/34216 [44:08<04:38, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30968/34216 [44:08<04:37, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30973/34216 [44:08<04:37, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30978/34216 [44:09<04:36, 11.69it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30983/34216 [44:09<04:36, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30988/34216 [44:09<04:35, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30993/34216 [44:09<04:35, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 30998/34216 [44:09<04:35, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31003/34216 [44:09<04:34, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31008/34216 [44:09<04:34, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31013/34216 [44:09<04:33, 11.70it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31018/34216 [44:09<04:33, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31023/34216 [44:10<04:32, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31028/34216 [44:10<04:32, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31033/34216 [44:10<04:31, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31038/34216 [44:10<04:31, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31043/34216 [44:10<04:30, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31048/34216 [44:10<04:30, 11.71it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31053/34216 [44:10<04:29, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31058/34216 [44:10<04:29, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31063/34216 [44:10<04:29, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31068/34216 [44:11<04:28, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31073/34216 [44:11<04:28, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31078/34216 [44:11<04:27, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31083/34216 [44:11<04:27, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31088/34216 [44:11<04:26, 11.72it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31093/34216 [44:11<04:26, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31098/34216 [44:11<04:25, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31103/34216 [44:11<04:25, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31108/34216 [44:11<04:24, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31113/34216 [44:12<04:24, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31118/34216 [44:12<04:24, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31123/34216 [44:12<04:23, 11.73it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31128/34216 [44:12<04:23, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31133/34216 [44:12<04:22, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31138/34216 [44:12<04:22, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31143/34216 [44:12<04:21, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31148/34216 [44:12<04:21, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31153/34216 [44:12<04:20, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31158/34216 [44:13<04:20, 11.74it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31163/34216 [44:13<04:19, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31168/34216 [44:13<04:19, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31173/34216 [44:13<04:19, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31178/34216 [44:13<04:18, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31183/34216 [44:13<04:18, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31188/34216 [44:13<04:17, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31193/34216 [44:13<04:17, 11.75it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31198/34216 [44:13<04:16, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31203/34216 [44:13<04:16, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31208/34216 [44:14<04:15, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31213/34216 [44:14<04:15, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31218/34216 [44:14<04:14, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31223/34216 [44:14<04:14, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31228/34216 [44:14<04:13, 11.76it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31233/34216 [44:14<04:13, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31238/34216 [44:14<04:13, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31243/34216 [44:14<04:12, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31248/34216 [44:14<04:12, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31253/34216 [44:15<04:11, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31258/34216 [44:15<04:11, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31263/34216 [44:15<04:10, 11.77it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31268/34216 [44:15<04:10, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31273/34216 [44:15<04:09, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31278/34216 [44:15<04:09, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31283/34216 [44:15<04:08, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31288/34216 [44:15<04:08, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31293/34216 [44:15<04:08, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31298/34216 [44:15<04:07, 11.78it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  91% 31303/34216 [44:16<04:07, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31308/34216 [44:16<04:06, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31313/34216 [44:16<04:06, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31318/34216 [44:16<04:05, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31323/34216 [44:16<04:05, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31328/34216 [44:16<04:04, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31333/34216 [44:16<04:04, 11.79it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31338/34216 [44:16<04:03, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31343/34216 [44:16<04:03, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31348/34216 [44:16<04:03, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31353/34216 [44:17<04:02, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31358/34216 [44:17<04:02, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31363/34216 [44:17<04:01, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31368/34216 [44:17<04:01, 11.80it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31373/34216 [44:17<04:00, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31378/34216 [44:17<04:00, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31383/34216 [44:17<03:59, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31388/34216 [44:17<03:59, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31393/34216 [44:17<03:59, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31398/34216 [44:18<03:58, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31403/34216 [44:18<03:58, 11.81it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31408/34216 [44:18<03:57, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31413/34216 [44:18<03:57, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31418/34216 [44:18<03:56, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31423/34216 [44:18<03:56, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31428/34216 [44:18<03:55, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31433/34216 [44:18<03:55, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31438/34216 [44:18<03:54, 11.82it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31443/34216 [44:18<03:54, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31448/34216 [44:19<03:54, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31453/34216 [44:19<03:53, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31458/34216 [44:19<03:53, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31463/34216 [44:19<03:52, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31468/34216 [44:19<03:52, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31473/34216 [44:19<03:51, 11.83it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31478/34216 [44:19<03:51, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31483/34216 [44:19<03:50, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31488/34216 [44:19<03:50, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31493/34216 [44:20<03:49, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31498/34216 [44:20<03:49, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31503/34216 [44:20<03:49, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31508/34216 [44:20<03:48, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31513/34216 [44:20<03:48, 11.84it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31518/34216 [44:20<03:47, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31523/34216 [44:20<03:47, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31528/34216 [44:20<03:46, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31533/34216 [44:20<03:46, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31538/34216 [44:20<03:45, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31543/34216 [44:21<03:45, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31548/34216 [44:21<03:45, 11.85it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31553/34216 [44:21<03:44, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31558/34216 [44:21<03:44, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31563/34216 [44:21<03:43, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31568/34216 [44:21<03:43, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31573/34216 [44:21<03:42, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31578/34216 [44:21<03:42, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31583/34216 [44:21<03:41, 11.86it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31588/34216 [44:22<03:41, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31593/34216 [44:22<03:41, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31598/34216 [44:22<03:40, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31603/34216 [44:22<03:40, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31608/34216 [44:22<03:39, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31613/34216 [44:22<03:39, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31618/34216 [44:22<03:38, 11.87it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31623/34216 [44:22<03:38, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31628/34216 [44:22<03:37, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31633/34216 [44:23<03:37, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31638/34216 [44:23<03:37, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31643/34216 [44:23<03:36, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  92% 31648/34216 [44:23<03:36, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31653/34216 [44:23<03:35, 11.88it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31658/34216 [44:23<03:35, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31663/34216 [44:23<03:34, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31668/34216 [44:23<03:34, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31673/34216 [44:23<03:33, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31678/34216 [44:24<03:33, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31683/34216 [44:24<03:32, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31688/34216 [44:24<03:32, 11.89it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31693/34216 [44:24<03:32, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31698/34216 [44:24<03:31, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31703/34216 [44:24<03:31, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31708/34216 [44:24<03:30, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31713/34216 [44:24<03:30, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31718/34216 [44:24<03:29, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31723/34216 [44:24<03:29, 11.90it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31728/34216 [44:25<03:28, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31733/34216 [44:25<03:28, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31738/34216 [44:25<03:28, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31743/34216 [44:25<03:27, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31748/34216 [44:25<03:27, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31753/34216 [44:25<03:26, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31758/34216 [44:25<03:26, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31763/34216 [44:25<03:25, 11.91it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31768/34216 [44:25<03:25, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31773/34216 [44:26<03:24, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31778/34216 [44:26<03:24, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31783/34216 [44:26<03:24, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31788/34216 [44:26<03:23, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31793/34216 [44:26<03:23, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31798/34216 [44:26<03:22, 11.92it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31803/34216 [44:26<03:22, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31808/34216 [44:26<03:21, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31813/34216 [44:26<03:21, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31818/34216 [44:27<03:21, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31823/34216 [44:27<03:20, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31828/34216 [44:27<03:20, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31833/34216 [44:27<03:19, 11.93it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31838/34216 [44:27<03:19, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31843/34216 [44:27<03:18, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31848/34216 [44:27<03:18, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31853/34216 [44:27<03:17, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31858/34216 [44:27<03:17, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31863/34216 [44:27<03:17, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31868/34216 [44:28<03:16, 11.94it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31873/34216 [44:28<03:16, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31878/34216 [44:28<03:15, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31883/34216 [44:28<03:15, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31888/34216 [44:28<03:14, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31893/34216 [44:28<03:14, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31898/34216 [44:28<03:13, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31903/34216 [44:28<03:13, 11.95it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31908/34216 [44:28<03:13, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31913/34216 [44:29<03:12, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31918/34216 [44:29<03:12, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31923/34216 [44:29<03:11, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31928/34216 [44:29<03:11, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31933/34216 [44:29<03:10, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31938/34216 [44:29<03:10, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31943/34216 [44:29<03:09, 11.96it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31948/34216 [44:29<03:09, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31953/34216 [44:29<03:09, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31958/34216 [44:30<03:08, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31963/34216 [44:30<03:08, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31968/34216 [44:30<03:07, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31973/34216 [44:30<03:07, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31978/34216 [44:30<03:06, 11.97it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31983/34216 [44:30<03:06, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  93% 31988/34216 [44:30<03:06, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 31993/34216 [44:30<03:05, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 31998/34216 [44:30<03:05, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32003/34216 [44:31<03:04, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32008/34216 [44:31<03:04, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32013/34216 [44:31<03:03, 11.98it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32018/34216 [44:31<03:03, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32023/34216 [44:31<03:02, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32028/34216 [44:31<03:02, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32033/34216 [44:31<03:02, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32038/34216 [44:31<03:01, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32043/34216 [44:32<03:01, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32048/34216 [44:32<03:00, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32053/34216 [44:32<03:00, 11.99it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32058/34216 [44:32<02:59, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32063/34216 [44:32<02:59, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32068/34216 [44:32<02:59, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32073/34216 [44:32<02:58, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32078/34216 [44:32<02:58, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32083/34216 [44:32<02:57, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32088/34216 [44:32<02:57, 12.00it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32093/34216 [44:33<02:56, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32098/34216 [44:33<02:56, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32103/34216 [44:33<02:55, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32108/34216 [44:33<02:55, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32113/34216 [44:33<02:55, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32118/34216 [44:33<02:54, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32123/34216 [44:33<02:54, 12.01it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32128/34216 [44:33<02:53, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32133/34216 [44:33<02:53, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32138/34216 [44:34<02:52, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32143/34216 [44:34<02:52, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32148/34216 [44:34<02:52, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32153/34216 [44:34<02:51, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32158/34216 [44:34<02:51, 12.02it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32163/34216 [44:34<02:50, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32168/34216 [44:34<02:50, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32173/34216 [44:34<02:49, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32178/34216 [44:34<02:49, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32183/34216 [44:34<02:48, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32188/34216 [44:35<02:48, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32193/34216 [44:35<02:48, 12.03it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32198/34216 [44:35<02:47, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32203/34216 [44:35<02:47, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32208/34216 [44:35<02:46, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32213/34216 [44:35<02:46, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32218/34216 [44:35<02:45, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32223/34216 [44:35<02:45, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32228/34216 [44:36<02:45, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32233/34216 [44:36<02:44, 12.04it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32238/34216 [44:36<02:44, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32243/34216 [44:36<02:43, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32248/34216 [44:36<02:43, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32253/34216 [44:36<02:42, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32258/34216 [44:36<02:42, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32263/34216 [44:36<02:42, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32268/34216 [44:36<02:41, 12.05it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32273/34216 [44:37<02:41, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32278/34216 [44:37<02:40, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32283/34216 [44:37<02:40, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32288/34216 [44:37<02:39, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32293/34216 [44:37<02:39, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32298/34216 [44:37<02:39, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32303/34216 [44:37<02:38, 12.06it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32308/34216 [44:37<02:38, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32313/34216 [44:37<02:37, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32318/34216 [44:38<02:37, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32323/34216 [44:38<02:36, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32328/34216 [44:38<02:36, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  94% 32333/34216 [44:38<02:35, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32338/34216 [44:38<02:35, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32343/34216 [44:38<02:35, 12.07it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32348/34216 [44:38<02:34, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32353/34216 [44:38<02:34, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32358/34216 [44:38<02:33, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32363/34216 [44:39<02:33, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32368/34216 [44:39<02:32, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32373/34216 [44:39<02:32, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32378/34216 [44:39<02:32, 12.08it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32383/34216 [44:39<02:31, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32388/34216 [44:39<02:31, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32393/34216 [44:39<02:30, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32398/34216 [44:39<02:30, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32403/34216 [44:39<02:29, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32408/34216 [44:40<02:29, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32413/34216 [44:40<02:29, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32418/34216 [44:40<02:28, 12.09it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32423/34216 [44:40<02:28, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32428/34216 [44:40<02:27, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32433/34216 [44:40<02:27, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32438/34216 [44:40<02:26, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32443/34216 [44:40<02:26, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32448/34216 [44:40<02:26, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32453/34216 [44:41<02:25, 12.10it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32458/34216 [44:41<02:25, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32463/34216 [44:41<02:24, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32468/34216 [44:41<02:24, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32473/34216 [44:41<02:23, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32478/34216 [44:41<02:23, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32483/34216 [44:41<02:23, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32488/34216 [44:41<02:22, 12.11it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32493/34216 [44:41<02:22, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32498/34216 [44:41<02:21, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32503/34216 [44:42<02:21, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32508/34216 [44:42<02:20, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32513/34216 [44:42<02:20, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32518/34216 [44:42<02:20, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32523/34216 [44:42<02:19, 12.12it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32528/34216 [44:42<02:19, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32533/34216 [44:42<02:18, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32538/34216 [44:42<02:18, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32543/34216 [44:42<02:17, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32548/34216 [44:43<02:17, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32553/34216 [44:43<02:17, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32558/34216 [44:43<02:16, 12.13it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32563/34216 [44:43<02:16, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32568/34216 [44:43<02:15, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32573/34216 [44:43<02:15, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32578/34216 [44:43<02:14, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32583/34216 [44:43<02:14, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32588/34216 [44:43<02:14, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32593/34216 [44:44<02:13, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32598/34216 [44:44<02:13, 12.14it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32603/34216 [44:44<02:12, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32608/34216 [44:44<02:12, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32613/34216 [44:44<02:11, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32618/34216 [44:44<02:11, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32623/34216 [44:44<02:11, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32628/34216 [44:44<02:10, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32633/34216 [44:44<02:10, 12.15it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32638/34216 [44:44<02:09, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32643/34216 [44:45<02:09, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32648/34216 [44:45<02:08, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32653/34216 [44:45<02:08, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32658/34216 [44:45<02:08, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32663/34216 [44:45<02:07, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32668/34216 [44:45<02:07, 12.16it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  95% 32673/34216 [44:45<02:06, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32678/34216 [44:45<02:06, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32683/34216 [44:46<02:05, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32688/34216 [44:46<02:05, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32693/34216 [44:46<02:05, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32698/34216 [44:46<02:04, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32703/34216 [44:46<02:04, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32708/34216 [44:46<02:03, 12.17it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32713/34216 [44:46<02:03, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32718/34216 [44:46<02:03, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32723/34216 [44:46<02:02, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32728/34216 [44:46<02:02, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32733/34216 [44:47<02:01, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32738/34216 [44:47<02:01, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32743/34216 [44:47<02:00, 12.18it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32748/34216 [44:47<02:00, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32753/34216 [44:47<02:00, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32758/34216 [44:47<01:59, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32763/34216 [44:47<01:59, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32768/34216 [44:47<01:58, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32773/34216 [44:47<01:58, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32778/34216 [44:48<01:57, 12.19it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32783/34216 [44:48<01:57, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32788/34216 [44:48<01:57, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32793/34216 [44:48<01:56, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32798/34216 [44:48<01:56, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32803/34216 [44:48<01:55, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32808/34216 [44:48<01:55, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32813/34216 [44:48<01:54, 12.20it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32818/34216 [44:48<01:54, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32823/34216 [44:48<01:54, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32828/34216 [44:49<01:53, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32833/34216 [44:49<01:53, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32838/34216 [44:49<01:52, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32843/34216 [44:49<01:52, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32848/34216 [44:49<01:52, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32853/34216 [44:49<01:51, 12.21it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32858/34216 [44:49<01:51, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32863/34216 [44:49<01:50, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32868/34216 [44:49<01:50, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32873/34216 [44:50<01:49, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32878/34216 [44:50<01:49, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32883/34216 [44:50<01:49, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32888/34216 [44:50<01:48, 12.22it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32893/34216 [44:50<01:48, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32898/34216 [44:50<01:47, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32903/34216 [44:50<01:47, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32908/34216 [44:50<01:46, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32913/34216 [44:50<01:46, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32918/34216 [44:50<01:46, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32923/34216 [44:51<01:45, 12.23it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32928/34216 [44:51<01:45, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32933/34216 [44:51<01:44, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32938/34216 [44:51<01:44, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32943/34216 [44:51<01:44, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32948/34216 [44:51<01:43, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32953/34216 [44:51<01:43, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32958/34216 [44:51<01:42, 12.24it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32963/34216 [44:51<01:42, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32968/34216 [44:51<01:41, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32973/34216 [44:52<01:41, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32978/34216 [44:52<01:41, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32983/34216 [44:52<01:40, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32988/34216 [44:52<01:40, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32993/34216 [44:52<01:39, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 32998/34216 [44:52<01:39, 12.25it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 33003/34216 [44:52<01:38, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 33008/34216 [44:52<01:38, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 33013/34216 [44:52<01:38, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  96% 33018/34216 [44:53<01:37, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33023/34216 [44:53<01:37, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33028/34216 [44:53<01:36, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33033/34216 [44:53<01:36, 12.26it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33038/34216 [44:53<01:36, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33043/34216 [44:53<01:35, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33048/34216 [44:53<01:35, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33053/34216 [44:53<01:34, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33058/34216 [44:53<01:34, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33063/34216 [44:53<01:33, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33068/34216 [44:54<01:33, 12.27it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33073/34216 [44:54<01:33, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33078/34216 [44:54<01:32, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33083/34216 [44:54<01:32, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33088/34216 [44:54<01:31, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33093/34216 [44:54<01:31, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33098/34216 [44:54<01:31, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33103/34216 [44:54<01:30, 12.28it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33108/34216 [44:54<01:30, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33113/34216 [44:55<01:29, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33118/34216 [44:55<01:29, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33123/34216 [44:55<01:28, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33128/34216 [44:55<01:28, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33133/34216 [44:55<01:28, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33138/34216 [44:55<01:27, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33143/34216 [44:55<01:27, 12.29it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33148/34216 [44:55<01:26, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33153/34216 [44:55<01:26, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33158/34216 [44:56<01:26, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33163/34216 [44:56<01:25, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33168/34216 [44:56<01:25, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33173/34216 [44:56<01:24, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33178/34216 [44:56<01:24, 12.30it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33183/34216 [44:56<01:23, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33188/34216 [44:56<01:23, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33193/34216 [44:56<01:23, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33198/34216 [44:56<01:22, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33203/34216 [44:57<01:22, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33208/34216 [44:57<01:21, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33213/34216 [44:57<01:21, 12.31it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33218/34216 [44:57<01:21, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33223/34216 [44:57<01:20, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33228/34216 [44:57<01:20, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33233/34216 [44:57<01:19, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33238/34216 [44:57<01:19, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33243/34216 [44:57<01:18, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33248/34216 [44:57<01:18, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33253/34216 [44:58<01:18, 12.32it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33258/34216 [44:58<01:17, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33263/34216 [44:58<01:17, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33268/34216 [44:58<01:16, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33273/34216 [44:58<01:16, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33278/34216 [44:58<01:16, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33283/34216 [44:58<01:15, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33288/34216 [44:58<01:15, 12.33it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33293/34216 [44:58<01:14, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33298/34216 [44:59<01:14, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33303/34216 [44:59<01:13, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33308/34216 [44:59<01:13, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33313/34216 [44:59<01:13, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33318/34216 [44:59<01:12, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33323/34216 [44:59<01:12, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33328/34216 [44:59<01:11, 12.34it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33333/34216 [44:59<01:11, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33338/34216 [44:59<01:11, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33343/34216 [45:00<01:10, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33348/34216 [45:00<01:10, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33353/34216 [45:00<01:09, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  97% 33358/34216 [45:00<01:09, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33363/34216 [45:00<01:09, 12.35it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33368/34216 [45:00<01:08, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33373/34216 [45:00<01:08, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33378/34216 [45:00<01:07, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33383/34216 [45:00<01:07, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33388/34216 [45:01<01:06, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33393/34216 [45:01<01:06, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33398/34216 [45:01<01:06, 12.36it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33403/34216 [45:01<01:05, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33408/34216 [45:01<01:05, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33413/34216 [45:01<01:04, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33418/34216 [45:01<01:04, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33423/34216 [45:01<01:04, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33428/34216 [45:01<01:03, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33433/34216 [45:01<01:03, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33438/34216 [45:02<01:02, 12.37it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33443/34216 [45:02<01:02, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33448/34216 [45:02<01:02, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33453/34216 [45:02<01:01, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33458/34216 [45:02<01:01, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33463/34216 [45:02<01:00, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33468/34216 [45:02<01:00, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33473/34216 [45:02<00:59, 12.38it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33478/34216 [45:02<00:59, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33483/34216 [45:03<00:59, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33488/34216 [45:03<00:58, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33493/34216 [45:03<00:58, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33498/34216 [45:03<00:57, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33503/34216 [45:03<00:57, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33508/34216 [45:03<00:57, 12.39it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33513/34216 [45:03<00:56, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33518/34216 [45:03<00:56, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33523/34216 [45:03<00:55, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33528/34216 [45:03<00:55, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33533/34216 [45:04<00:55, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33538/34216 [45:04<00:54, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33543/34216 [45:04<00:54, 12.40it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33548/34216 [45:04<00:53, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33553/34216 [45:04<00:53, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33558/34216 [45:04<00:53, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33563/34216 [45:04<00:52, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33568/34216 [45:04<00:52, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33573/34216 [45:04<00:51, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33578/34216 [45:05<00:51, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33583/34216 [45:05<00:50, 12.41it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33588/34216 [45:05<00:50, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33593/34216 [45:05<00:50, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33598/34216 [45:05<00:49, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33603/34216 [45:05<00:49, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33608/34216 [45:05<00:48, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33613/34216 [45:05<00:48, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33618/34216 [45:05<00:48, 12.42it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33623/34216 [45:05<00:47, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33628/34216 [45:06<00:47, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33633/34216 [45:06<00:46, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33638/34216 [45:06<00:46, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33643/34216 [45:06<00:46, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33648/34216 [45:06<00:45, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33653/34216 [45:06<00:45, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33658/34216 [45:06<00:44, 12.43it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33663/34216 [45:06<00:44, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33668/34216 [45:06<00:44, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33673/34216 [45:07<00:43, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33678/34216 [45:07<00:43, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33683/34216 [45:07<00:42, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33688/34216 [45:07<00:42, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33693/34216 [45:07<00:42, 12.44it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  98% 33698/34216 [45:07<00:41, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33703/34216 [45:07<00:41, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33708/34216 [45:07<00:40, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33713/34216 [45:07<00:40, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33718/34216 [45:08<00:39, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33723/34216 [45:08<00:39, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33728/34216 [45:08<00:39, 12.45it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33733/34216 [45:08<00:38, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33738/34216 [45:08<00:38, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33743/34216 [45:08<00:37, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33748/34216 [45:08<00:37, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33753/34216 [45:08<00:37, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33758/34216 [45:08<00:36, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33763/34216 [45:08<00:36, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33768/34216 [45:09<00:35, 12.46it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33773/34216 [45:09<00:35, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33778/34216 [45:09<00:35, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33783/34216 [45:09<00:34, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33788/34216 [45:09<00:34, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33793/34216 [45:09<00:33, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33798/34216 [45:09<00:33, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33803/34216 [45:09<00:33, 12.47it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33808/34216 [45:09<00:32, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33813/34216 [45:10<00:32, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33818/34216 [45:10<00:31, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33823/34216 [45:10<00:31, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33828/34216 [45:10<00:31, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33833/34216 [45:10<00:30, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33838/34216 [45:10<00:30, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33843/34216 [45:10<00:29, 12.48it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33848/34216 [45:10<00:29, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33853/34216 [45:10<00:29, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33858/34216 [45:11<00:28, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33863/34216 [45:11<00:28, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33868/34216 [45:11<00:27, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33873/34216 [45:11<00:27, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33878/34216 [45:11<00:27, 12.49it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33883/34216 [45:11<00:26, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33888/34216 [45:11<00:26, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33893/34216 [45:11<00:25, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33898/34216 [45:11<00:25, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33903/34216 [45:12<00:25, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33908/34216 [45:12<00:24, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33913/34216 [45:12<00:24, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33918/34216 [45:12<00:23, 12.50it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33923/34216 [45:12<00:23, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33928/34216 [45:12<00:23, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33933/34216 [45:12<00:22, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33938/34216 [45:12<00:22, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33943/34216 [45:12<00:21, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33948/34216 [45:13<00:21, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33953/34216 [45:13<00:21, 12.51it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33958/34216 [45:13<00:20, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33963/34216 [45:13<00:20, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33968/34216 [45:13<00:19, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33973/34216 [45:13<00:19, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33978/34216 [45:13<00:19, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33983/34216 [45:13<00:18, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33988/34216 [45:13<00:18, 12.52it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33993/34216 [45:13<00:17, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 33998/34216 [45:14<00:17, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34003/34216 [45:14<00:17, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34008/34216 [45:14<00:16, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34013/34216 [45:14<00:16, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34018/34216 [45:14<00:15, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34023/34216 [45:14<00:15, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34028/34216 [45:14<00:14, 12.53it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34033/34216 [45:14<00:14, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34038/34216 [45:14<00:14, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0:  99% 34043/34216 [45:15<00:13, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34048/34216 [45:15<00:13, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34053/34216 [45:15<00:12, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34058/34216 [45:15<00:12, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34063/34216 [45:15<00:12, 12.54it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34068/34216 [45:15<00:11, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34073/34216 [45:15<00:11, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34078/34216 [45:15<00:10, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34083/34216 [45:15<00:10, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34088/34216 [45:16<00:10, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34093/34216 [45:16<00:09, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34098/34216 [45:16<00:09, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34103/34216 [45:16<00:09, 12.55it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34108/34216 [45:16<00:08, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34113/34216 [45:16<00:08, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34118/34216 [45:16<00:07, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34123/34216 [45:16<00:07, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34128/34216 [45:16<00:07, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34133/34216 [45:16<00:06, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34138/34216 [45:17<00:06, 12.56it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34143/34216 [45:17<00:05, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34148/34216 [45:17<00:05, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34153/34216 [45:17<00:05, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34158/34216 [45:17<00:04, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34163/34216 [45:17<00:04, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34168/34216 [45:17<00:03, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34173/34216 [45:17<00:03, 12.57it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34178/34216 [45:17<00:03, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34183/34216 [45:18<00:02, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34188/34216 [45:18<00:02, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34193/34216 [45:18<00:01, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34198/34216 [45:18<00:01, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34203/34216 [45:18<00:01, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34208/34216 [45:18<00:00, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580]\n","Epoch 0: 100% 34216/34216 [45:18<00:00, 12.58it/s, loss=8.27, v_num=5, train_loss=8.580, val_loss=9.100]\n","                                                   \u001b[AEpoch 0, global step 30450: val_loss reached 9.09846 (best 9.09846), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=00-val_loss=9.098.ckpt\" as top 3\n","tcmalloc: large alloc 1321271296 bytes == 0x7fe7e93f0000 @  0x7fec0a05c615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7febdf4a7734 0x7febdf512389 0x7feb6dbb3665 0x7feb6dbafbca 0x7feb6dbb4079 0x7febdf512922 0x7febdf158cae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 1651589120 bytes == 0x14059c000 @  0x7fec0a05c615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7febdf4a7734 0x7febdf512389 0x7feb6dbb3665 0x7feb6dbafbca 0x7feb6dbb4079 0x7febdf512922 0x7febdf158cae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 2064490496 bytes == 0x7fe76e316000 @  0x7fec0a05c615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7febdf4a7734 0x7febdf512389 0x7feb6dbb3665 0x7feb6dbafbca 0x7feb6dbb4079 0x7febdf512922 0x7febdf158cae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 1651589120 bytes == 0x7fe7bcf26000 @  0x7fec0a05c615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7febdf4a7734 0x7febdf512389 0x7feb6dbb3665 0x7feb6dbafbca 0x7feb6dbb4079 0x7febdf512922 0x7febdf158cae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","tcmalloc: large alloc 2064490496 bytes == 0x14059c000 @  0x7fec0a05c615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7febdf4a7734 0x7febdf512389 0x7feb6dbb3665 0x7feb6dbafbca 0x7feb6dbb4079 0x7febdf512922 0x7febdf158cae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","Epoch 1:  89% 30451/34216 [44:41<05:31, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  89% 30453/34216 [44:41<05:31, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30458/34216 [44:41<05:30, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30463/34216 [44:42<05:30, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30468/34216 [44:42<05:29, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30473/34216 [44:42<05:29, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30478/34216 [44:42<05:28, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30483/34216 [44:42<05:28, 11.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30488/34216 [44:42<05:28, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30493/34216 [44:42<05:27, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30498/34216 [44:42<05:27, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30503/34216 [44:42<05:26, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30508/34216 [44:43<05:26, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30513/34216 [44:43<05:25, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30518/34216 [44:43<05:25, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30523/34216 [44:43<05:24, 11.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30528/34216 [44:43<05:24, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30533/34216 [44:43<05:23, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30538/34216 [44:43<05:23, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30543/34216 [44:43<05:22, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30548/34216 [44:43<05:22, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30553/34216 [44:44<05:21, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30558/34216 [44:44<05:21, 11.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30563/34216 [44:44<05:20, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30568/34216 [44:44<05:20, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30573/34216 [44:44<05:19, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30578/34216 [44:44<05:19, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30583/34216 [44:44<05:18, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30588/34216 [44:44<05:18, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30593/34216 [44:44<05:17, 11.39it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30598/34216 [44:44<05:17, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30603/34216 [44:45<05:17, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30608/34216 [44:45<05:16, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30613/34216 [44:45<05:16, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30618/34216 [44:45<05:15, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  89% 30623/34216 [44:45<05:15, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30628/34216 [44:45<05:14, 11.40it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30633/34216 [44:45<05:14, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30638/34216 [44:45<05:13, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30643/34216 [44:45<05:13, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30648/34216 [44:46<05:12, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30653/34216 [44:46<05:12, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30658/34216 [44:46<05:11, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30663/34216 [44:46<05:11, 11.41it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30668/34216 [44:46<05:10, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30673/34216 [44:46<05:10, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30678/34216 [44:46<05:09, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30683/34216 [44:46<05:09, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30688/34216 [44:46<05:08, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30693/34216 [44:47<05:08, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30698/34216 [44:47<05:07, 11.42it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30703/34216 [44:47<05:07, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30708/34216 [44:47<05:07, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30713/34216 [44:47<05:06, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30718/34216 [44:47<05:06, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30723/34216 [44:47<05:05, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30728/34216 [44:47<05:05, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30733/34216 [44:47<05:04, 11.43it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30738/34216 [44:48<05:04, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30743/34216 [44:48<05:03, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30748/34216 [44:48<05:03, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30753/34216 [44:48<05:02, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30758/34216 [44:48<05:02, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30763/34216 [44:48<05:01, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30768/34216 [44:48<05:01, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30773/34216 [44:48<05:00, 11.44it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30778/34216 [44:48<05:00, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30783/34216 [44:49<04:59, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30788/34216 [44:49<04:59, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30793/34216 [44:49<04:58, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30798/34216 [44:49<04:58, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30803/34216 [44:49<04:57, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30808/34216 [44:49<04:57, 11.45it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30813/34216 [44:49<04:57, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30818/34216 [44:49<04:56, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30823/34216 [44:49<04:56, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30828/34216 [44:49<04:55, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30833/34216 [44:50<04:55, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30838/34216 [44:50<04:54, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30843/34216 [44:50<04:54, 11.46it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30848/34216 [44:50<04:53, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30853/34216 [44:50<04:53, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30858/34216 [44:50<04:52, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30863/34216 [44:50<04:52, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30868/34216 [44:50<04:51, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30873/34216 [44:50<04:51, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30878/34216 [44:51<04:50, 11.47it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30883/34216 [44:51<04:50, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30888/34216 [44:51<04:49, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30893/34216 [44:51<04:49, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30898/34216 [44:51<04:49, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30903/34216 [44:51<04:48, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30908/34216 [44:51<04:48, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30913/34216 [44:51<04:47, 11.48it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30918/34216 [44:51<04:47, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30923/34216 [44:52<04:46, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30928/34216 [44:52<04:46, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30933/34216 [44:52<04:45, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30938/34216 [44:52<04:45, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30943/34216 [44:52<04:44, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30948/34216 [44:52<04:44, 11.49it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30953/34216 [44:52<04:43, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30958/34216 [44:52<04:43, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  90% 30963/34216 [44:52<04:42, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30968/34216 [44:53<04:42, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30973/34216 [44:53<04:41, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30978/34216 [44:53<04:41, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30983/34216 [44:53<04:41, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30988/34216 [44:53<04:40, 11.50it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30993/34216 [44:53<04:40, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 30998/34216 [44:53<04:39, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31003/34216 [44:53<04:39, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31008/34216 [44:53<04:38, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31013/34216 [44:53<04:38, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31018/34216 [44:54<04:37, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31023/34216 [44:54<04:37, 11.51it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31028/34216 [44:54<04:36, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31033/34216 [44:54<04:36, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31038/34216 [44:54<04:35, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31043/34216 [44:54<04:35, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31048/34216 [44:54<04:34, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31053/34216 [44:54<04:34, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31058/34216 [44:54<04:34, 11.52it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31063/34216 [44:55<04:33, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31068/34216 [44:55<04:33, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31073/34216 [44:55<04:32, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31078/34216 [44:55<04:32, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31083/34216 [44:55<04:31, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31088/34216 [44:55<04:31, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31093/34216 [44:55<04:30, 11.53it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31098/34216 [44:55<04:30, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31103/34216 [44:55<04:29, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31108/34216 [44:56<04:29, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31113/34216 [44:56<04:28, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31118/34216 [44:56<04:28, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31123/34216 [44:56<04:27, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31128/34216 [44:56<04:27, 11.54it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31133/34216 [44:56<04:27, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31138/34216 [44:56<04:26, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31143/34216 [44:56<04:26, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31148/34216 [44:56<04:25, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31153/34216 [44:57<04:25, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31158/34216 [44:57<04:24, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31163/34216 [44:57<04:24, 11.55it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31168/34216 [44:57<04:23, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31173/34216 [44:57<04:23, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31178/34216 [44:57<04:22, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31183/34216 [44:57<04:22, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31188/34216 [44:57<04:21, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31193/34216 [44:57<04:21, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31198/34216 [44:58<04:20, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31203/34216 [44:58<04:20, 11.56it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31208/34216 [44:58<04:20, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31213/34216 [44:58<04:19, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31218/34216 [44:58<04:19, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31223/34216 [44:58<04:18, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31228/34216 [44:58<04:18, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31233/34216 [44:58<04:17, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31238/34216 [44:58<04:17, 11.57it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31243/34216 [44:58<04:16, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31248/34216 [44:59<04:16, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31253/34216 [44:59<04:15, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31258/34216 [44:59<04:15, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31263/34216 [44:59<04:14, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31268/34216 [44:59<04:14, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31273/34216 [44:59<04:14, 11.58it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31278/34216 [44:59<04:13, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31283/34216 [44:59<04:13, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31288/34216 [45:00<04:12, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31293/34216 [45:00<04:12, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31298/34216 [45:00<04:11, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  91% 31303/34216 [45:00<04:11, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31308/34216 [45:00<04:10, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31313/34216 [45:00<04:10, 11.59it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31318/34216 [45:00<04:09, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31323/34216 [45:00<04:09, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31328/34216 [45:00<04:08, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31333/34216 [45:01<04:08, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31338/34216 [45:01<04:08, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31343/34216 [45:01<04:07, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31348/34216 [45:01<04:07, 11.60it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31353/34216 [45:01<04:06, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31358/34216 [45:01<04:06, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31363/34216 [45:01<04:05, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31368/34216 [45:01<04:05, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31373/34216 [45:01<04:04, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31378/34216 [45:02<04:04, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31383/34216 [45:02<04:03, 11.61it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31388/34216 [45:02<04:03, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31393/34216 [45:02<04:03, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31398/34216 [45:02<04:02, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31403/34216 [45:02<04:02, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31408/34216 [45:02<04:01, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31413/34216 [45:02<04:01, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31418/34216 [45:02<04:00, 11.62it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31423/34216 [45:03<04:00, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31428/34216 [45:03<03:59, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31433/34216 [45:03<03:59, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31438/34216 [45:03<03:58, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31443/34216 [45:03<03:58, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31448/34216 [45:03<03:57, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31453/34216 [45:03<03:57, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31458/34216 [45:03<03:57, 11.63it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31463/34216 [45:03<03:56, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31468/34216 [45:03<03:56, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31473/34216 [45:04<03:55, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31478/34216 [45:04<03:55, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31483/34216 [45:04<03:54, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31488/34216 [45:04<03:54, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31493/34216 [45:04<03:53, 11.64it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31498/34216 [45:04<03:53, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31503/34216 [45:04<03:52, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31508/34216 [45:04<03:52, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31513/34216 [45:04<03:52, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31518/34216 [45:05<03:51, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31523/34216 [45:05<03:51, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31528/34216 [45:05<03:50, 11.65it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31533/34216 [45:05<03:50, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31538/34216 [45:05<03:49, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31543/34216 [45:05<03:49, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31548/34216 [45:05<03:48, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31553/34216 [45:05<03:48, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31558/34216 [45:05<03:47, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31563/34216 [45:06<03:47, 11.66it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31568/34216 [45:06<03:46, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31573/34216 [45:06<03:46, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31578/34216 [45:06<03:46, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31583/34216 [45:06<03:45, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31588/34216 [45:06<03:45, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31593/34216 [45:06<03:44, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31598/34216 [45:06<03:44, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31603/34216 [45:06<03:43, 11.67it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31608/34216 [45:07<03:43, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31613/34216 [45:07<03:42, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31618/34216 [45:07<03:42, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31623/34216 [45:07<03:41, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31628/34216 [45:07<03:41, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31633/34216 [45:07<03:41, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31638/34216 [45:07<03:40, 11.68it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31643/34216 [45:07<03:40, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  92% 31648/34216 [45:07<03:39, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31653/34216 [45:07<03:39, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31658/34216 [45:08<03:38, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31663/34216 [45:08<03:38, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31668/34216 [45:08<03:37, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31673/34216 [45:08<03:37, 11.69it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31678/34216 [45:08<03:37, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31683/34216 [45:08<03:36, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31688/34216 [45:08<03:36, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31693/34216 [45:08<03:35, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31698/34216 [45:08<03:35, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31703/34216 [45:09<03:34, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31708/34216 [45:09<03:34, 11.70it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31713/34216 [45:09<03:33, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31718/34216 [45:09<03:33, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31723/34216 [45:09<03:32, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31728/34216 [45:09<03:32, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31733/34216 [45:09<03:32, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31738/34216 [45:09<03:31, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31743/34216 [45:09<03:31, 11.71it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31748/34216 [45:10<03:30, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31753/34216 [45:10<03:30, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31758/34216 [45:10<03:29, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31763/34216 [45:10<03:29, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31768/34216 [45:10<03:28, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31773/34216 [45:10<03:28, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31778/34216 [45:10<03:27, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31783/34216 [45:10<03:27, 11.72it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31788/34216 [45:10<03:27, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31793/34216 [45:11<03:26, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31798/34216 [45:11<03:26, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31803/34216 [45:11<03:25, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31808/34216 [45:11<03:25, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31813/34216 [45:11<03:24, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31818/34216 [45:11<03:24, 11.73it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31823/34216 [45:11<03:23, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31828/34216 [45:11<03:23, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31833/34216 [45:11<03:23, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31838/34216 [45:12<03:22, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31843/34216 [45:12<03:22, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31848/34216 [45:12<03:21, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31853/34216 [45:12<03:21, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31858/34216 [45:12<03:20, 11.74it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31863/34216 [45:12<03:20, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31868/34216 [45:12<03:19, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31873/34216 [45:12<03:19, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31878/34216 [45:12<03:18, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31883/34216 [45:13<03:18, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31888/34216 [45:13<03:18, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31893/34216 [45:13<03:17, 11.75it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31898/34216 [45:13<03:17, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31903/34216 [45:13<03:16, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31908/34216 [45:13<03:16, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31913/34216 [45:13<03:15, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31918/34216 [45:13<03:15, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31923/34216 [45:13<03:14, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31928/34216 [45:14<03:14, 11.76it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31933/34216 [45:14<03:14, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31938/34216 [45:14<03:13, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31943/34216 [45:14<03:13, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31948/34216 [45:14<03:12, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31953/34216 [45:14<03:12, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31958/34216 [45:14<03:11, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31963/34216 [45:14<03:11, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31968/34216 [45:14<03:10, 11.77it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31973/34216 [45:15<03:10, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31978/34216 [45:15<03:10, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31983/34216 [45:15<03:09, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  93% 31988/34216 [45:15<03:09, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 31993/34216 [45:15<03:08, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 31998/34216 [45:15<03:08, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32003/34216 [45:15<03:07, 11.78it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32008/34216 [45:15<03:07, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32013/34216 [45:15<03:06, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32018/34216 [45:16<03:06, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32023/34216 [45:16<03:06, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32028/34216 [45:16<03:05, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32033/34216 [45:16<03:05, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32038/34216 [45:16<03:04, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32043/34216 [45:16<03:04, 11.79it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32048/34216 [45:16<03:03, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32053/34216 [45:16<03:03, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32058/34216 [45:17<03:02, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32063/34216 [45:17<03:02, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32068/34216 [45:17<03:02, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32073/34216 [45:17<03:01, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32078/34216 [45:17<03:01, 11.80it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32083/34216 [45:17<03:00, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32088/34216 [45:17<03:00, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32093/34216 [45:17<02:59, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32098/34216 [45:17<02:59, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32103/34216 [45:18<02:58, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32108/34216 [45:18<02:58, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32113/34216 [45:18<02:58, 11.81it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32118/34216 [45:18<02:57, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32123/34216 [45:18<02:57, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32128/34216 [45:18<02:56, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32133/34216 [45:18<02:56, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32138/34216 [45:18<02:55, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32143/34216 [45:18<02:55, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32148/34216 [45:19<02:54, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32153/34216 [45:19<02:54, 11.82it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32158/34216 [45:19<02:54, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32163/34216 [45:19<02:53, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32168/34216 [45:19<02:53, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32173/34216 [45:19<02:52, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32178/34216 [45:19<02:52, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32183/34216 [45:19<02:51, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32188/34216 [45:19<02:51, 11.83it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32193/34216 [45:19<02:50, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32198/34216 [45:20<02:50, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32203/34216 [45:20<02:50, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32208/34216 [45:20<02:49, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32213/34216 [45:20<02:49, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32218/34216 [45:20<02:48, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32223/34216 [45:20<02:48, 11.84it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32228/34216 [45:20<02:47, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32233/34216 [45:20<02:47, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32238/34216 [45:20<02:46, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32243/34216 [45:21<02:46, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32248/34216 [45:21<02:46, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32253/34216 [45:21<02:45, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32258/34216 [45:21<02:45, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32263/34216 [45:21<02:44, 11.85it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32268/34216 [45:21<02:44, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32273/34216 [45:21<02:43, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32278/34216 [45:21<02:43, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32283/34216 [45:21<02:42, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32288/34216 [45:22<02:42, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32293/34216 [45:22<02:42, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32298/34216 [45:22<02:41, 11.86it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32303/34216 [45:22<02:41, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32308/34216 [45:22<02:40, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32313/34216 [45:22<02:40, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32318/34216 [45:22<02:39, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32323/34216 [45:22<02:39, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32328/34216 [45:22<02:39, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  94% 32333/34216 [45:22<02:38, 11.87it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32338/34216 [45:23<02:38, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32343/34216 [45:23<02:37, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32348/34216 [45:23<02:37, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32353/34216 [45:23<02:36, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32358/34216 [45:23<02:36, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32363/34216 [45:23<02:35, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32368/34216 [45:23<02:35, 11.88it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32373/34216 [45:23<02:35, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32378/34216 [45:23<02:34, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32383/34216 [45:24<02:34, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32388/34216 [45:24<02:33, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32393/34216 [45:24<02:33, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32398/34216 [45:24<02:32, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32403/34216 [45:24<02:32, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32408/34216 [45:24<02:32, 11.89it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32413/34216 [45:24<02:31, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32418/34216 [45:24<02:31, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32423/34216 [45:24<02:30, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32428/34216 [45:25<02:30, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32433/34216 [45:25<02:29, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32438/34216 [45:25<02:29, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32443/34216 [45:25<02:28, 11.90it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32448/34216 [45:25<02:28, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32453/34216 [45:25<02:28, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32458/34216 [45:25<02:27, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32463/34216 [45:25<02:27, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32468/34216 [45:25<02:26, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32473/34216 [45:26<02:26, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32478/34216 [45:26<02:25, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32483/34216 [45:26<02:25, 11.91it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32488/34216 [45:26<02:25, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32493/34216 [45:26<02:24, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32498/34216 [45:26<02:24, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32503/34216 [45:26<02:23, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32508/34216 [45:26<02:23, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32513/34216 [45:26<02:22, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32518/34216 [45:27<02:22, 11.92it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32523/34216 [45:27<02:21, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32528/34216 [45:27<02:21, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32533/34216 [45:27<02:21, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32538/34216 [45:27<02:20, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32543/34216 [45:27<02:20, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32548/34216 [45:27<02:19, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32553/34216 [45:27<02:19, 11.93it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32558/34216 [45:27<02:18, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32563/34216 [45:28<02:18, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32568/34216 [45:28<02:18, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32573/34216 [45:28<02:17, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32578/34216 [45:28<02:17, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32583/34216 [45:28<02:16, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32588/34216 [45:28<02:16, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32593/34216 [45:28<02:15, 11.94it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32598/34216 [45:28<02:15, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32603/34216 [45:28<02:15, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32608/34216 [45:29<02:14, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32613/34216 [45:29<02:14, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32618/34216 [45:29<02:13, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32623/34216 [45:29<02:13, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32628/34216 [45:29<02:12, 11.95it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32633/34216 [45:29<02:12, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32638/34216 [45:29<02:11, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32643/34216 [45:29<02:11, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32648/34216 [45:29<02:11, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32653/34216 [45:30<02:10, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32658/34216 [45:30<02:10, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32663/34216 [45:30<02:09, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32668/34216 [45:30<02:09, 11.96it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  95% 32673/34216 [45:30<02:08, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32678/34216 [45:30<02:08, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32683/34216 [45:30<02:08, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32688/34216 [45:30<02:07, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32693/34216 [45:30<02:07, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32698/34216 [45:31<02:06, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32703/34216 [45:31<02:06, 11.97it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32708/34216 [45:31<02:05, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32713/34216 [45:31<02:05, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32718/34216 [45:31<02:05, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32723/34216 [45:31<02:04, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32728/34216 [45:31<02:04, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32733/34216 [45:31<02:03, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32738/34216 [45:31<02:03, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32743/34216 [45:32<02:02, 11.98it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32748/34216 [45:32<02:02, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32753/34216 [45:32<02:02, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32758/34216 [45:32<02:01, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32763/34216 [45:32<02:01, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32768/34216 [45:32<02:00, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32773/34216 [45:32<02:00, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32778/34216 [45:32<01:59, 11.99it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32783/34216 [45:32<01:59, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32788/34216 [45:33<01:59, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32793/34216 [45:33<01:58, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32798/34216 [45:33<01:58, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32803/34216 [45:33<01:57, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32808/34216 [45:33<01:57, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32813/34216 [45:33<01:56, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32818/34216 [45:33<01:56, 12.00it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32823/34216 [45:33<01:56, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32828/34216 [45:33<01:55, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32833/34216 [45:34<01:55, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32838/34216 [45:34<01:54, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32843/34216 [45:34<01:54, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32848/34216 [45:34<01:53, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32853/34216 [45:34<01:53, 12.01it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32858/34216 [45:34<01:53, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32863/34216 [45:34<01:52, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32868/34216 [45:34<01:52, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32873/34216 [45:34<01:51, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32878/34216 [45:34<01:51, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32883/34216 [45:35<01:50, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32888/34216 [45:35<01:50, 12.02it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32893/34216 [45:35<01:50, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32898/34216 [45:35<01:49, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32903/34216 [45:35<01:49, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32908/34216 [45:35<01:48, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32913/34216 [45:35<01:48, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32918/34216 [45:35<01:47, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32923/34216 [45:35<01:47, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32928/34216 [45:36<01:47, 12.03it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32933/34216 [45:36<01:46, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32938/34216 [45:36<01:46, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32943/34216 [45:36<01:45, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32948/34216 [45:36<01:45, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32953/34216 [45:36<01:44, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32958/34216 [45:36<01:44, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32963/34216 [45:36<01:44, 12.04it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32968/34216 [45:36<01:43, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32973/34216 [45:37<01:43, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32978/34216 [45:37<01:42, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32983/34216 [45:37<01:42, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32988/34216 [45:37<01:41, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32993/34216 [45:37<01:41, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 32998/34216 [45:37<01:41, 12.05it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 33003/34216 [45:37<01:40, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 33008/34216 [45:37<01:40, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 33013/34216 [45:37<01:39, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  96% 33018/34216 [45:37<01:39, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33023/34216 [45:38<01:38, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33028/34216 [45:38<01:38, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33033/34216 [45:38<01:38, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33038/34216 [45:38<01:37, 12.06it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33043/34216 [45:38<01:37, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33048/34216 [45:38<01:36, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33053/34216 [45:38<01:36, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33058/34216 [45:38<01:35, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33063/34216 [45:38<01:35, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33068/34216 [45:39<01:35, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33073/34216 [45:39<01:34, 12.07it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33078/34216 [45:39<01:34, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33083/34216 [45:39<01:33, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33088/34216 [45:39<01:33, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33093/34216 [45:39<01:32, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33098/34216 [45:39<01:32, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33103/34216 [45:39<01:32, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33108/34216 [45:39<01:31, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33113/34216 [45:40<01:31, 12.08it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33118/34216 [45:40<01:30, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33123/34216 [45:40<01:30, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33128/34216 [45:40<01:30, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33133/34216 [45:40<01:29, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33138/34216 [45:40<01:29, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33143/34216 [45:40<01:28, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33148/34216 [45:40<01:28, 12.09it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33153/34216 [45:40<01:27, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33158/34216 [45:41<01:27, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33163/34216 [45:41<01:27, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33168/34216 [45:41<01:26, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33173/34216 [45:41<01:26, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33178/34216 [45:41<01:25, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33183/34216 [45:41<01:25, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33188/34216 [45:41<01:24, 12.10it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33193/34216 [45:41<01:24, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33198/34216 [45:41<01:24, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33203/34216 [45:42<01:23, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33208/34216 [45:42<01:23, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33213/34216 [45:42<01:22, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33218/34216 [45:42<01:22, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33223/34216 [45:42<01:21, 12.11it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33228/34216 [45:42<01:21, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33233/34216 [45:42<01:21, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33238/34216 [45:42<01:20, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33243/34216 [45:42<01:20, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33248/34216 [45:43<01:19, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33253/34216 [45:43<01:19, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33258/34216 [45:43<01:19, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33263/34216 [45:43<01:18, 12.12it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33268/34216 [45:43<01:18, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33273/34216 [45:43<01:17, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33278/34216 [45:43<01:17, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33283/34216 [45:43<01:16, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33288/34216 [45:43<01:16, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33293/34216 [45:44<01:16, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33298/34216 [45:44<01:15, 12.13it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33303/34216 [45:44<01:15, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33308/34216 [45:44<01:14, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33313/34216 [45:44<01:14, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33318/34216 [45:44<01:13, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33323/34216 [45:44<01:13, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33328/34216 [45:44<01:13, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33333/34216 [45:44<01:12, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33338/34216 [45:45<01:12, 12.14it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33343/34216 [45:45<01:11, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33348/34216 [45:45<01:11, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33353/34216 [45:45<01:11, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  97% 33358/34216 [45:45<01:10, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33363/34216 [45:45<01:10, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33368/34216 [45:45<01:09, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33373/34216 [45:45<01:09, 12.15it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33378/34216 [45:45<01:08, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33383/34216 [45:46<01:08, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33388/34216 [45:46<01:08, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33393/34216 [45:46<01:07, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33398/34216 [45:46<01:07, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33403/34216 [45:46<01:06, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33408/34216 [45:46<01:06, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33413/34216 [45:46<01:06, 12.16it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33418/34216 [45:46<01:05, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33423/34216 [45:46<01:05, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33428/34216 [45:47<01:04, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33433/34216 [45:47<01:04, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33438/34216 [45:47<01:03, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33443/34216 [45:47<01:03, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33448/34216 [45:47<01:03, 12.17it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33453/34216 [45:47<01:02, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33458/34216 [45:47<01:02, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33463/34216 [45:47<01:01, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33468/34216 [45:47<01:01, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33473/34216 [45:48<01:00, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33478/34216 [45:48<01:00, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33483/34216 [45:48<01:00, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33488/34216 [45:48<00:59, 12.18it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33493/34216 [45:48<00:59, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33498/34216 [45:48<00:58, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33503/34216 [45:48<00:58, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33508/34216 [45:48<00:58, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33513/34216 [45:48<00:57, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33518/34216 [45:49<00:57, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33523/34216 [45:49<00:56, 12.19it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33528/34216 [45:49<00:56, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33533/34216 [45:49<00:55, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33538/34216 [45:49<00:55, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33543/34216 [45:49<00:55, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33548/34216 [45:49<00:54, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33553/34216 [45:49<00:54, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33558/34216 [45:49<00:53, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33563/34216 [45:50<00:53, 12.20it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33568/34216 [45:50<00:53, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33573/34216 [45:50<00:52, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33578/34216 [45:50<00:52, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33583/34216 [45:50<00:51, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33588/34216 [45:50<00:51, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33593/34216 [45:50<00:51, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33598/34216 [45:50<00:50, 12.21it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33603/34216 [45:50<00:50, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33608/34216 [45:51<00:49, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33613/34216 [45:51<00:49, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33618/34216 [45:51<00:48, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33623/34216 [45:51<00:48, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33628/34216 [45:51<00:48, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33633/34216 [45:51<00:47, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33638/34216 [45:51<00:47, 12.22it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33643/34216 [45:51<00:46, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33648/34216 [45:51<00:46, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33653/34216 [45:51<00:46, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33658/34216 [45:52<00:45, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33663/34216 [45:52<00:45, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33668/34216 [45:52<00:44, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33673/34216 [45:52<00:44, 12.23it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33678/34216 [45:52<00:43, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33683/34216 [45:52<00:43, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33688/34216 [45:52<00:43, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33693/34216 [45:52<00:42, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  98% 33698/34216 [45:52<00:42, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33703/34216 [45:53<00:41, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33708/34216 [45:53<00:41, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33713/34216 [45:53<00:41, 12.24it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33718/34216 [45:53<00:40, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33723/34216 [45:53<00:40, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33728/34216 [45:53<00:39, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33733/34216 [45:53<00:39, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33738/34216 [45:53<00:39, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33743/34216 [45:53<00:38, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33748/34216 [45:54<00:38, 12.25it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33753/34216 [45:54<00:37, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33758/34216 [45:54<00:37, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33763/34216 [45:54<00:36, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33768/34216 [45:54<00:36, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33773/34216 [45:54<00:36, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33778/34216 [45:54<00:35, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33783/34216 [45:54<00:35, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33788/34216 [45:54<00:34, 12.26it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33793/34216 [45:55<00:34, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33798/34216 [45:55<00:34, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33803/34216 [45:55<00:33, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33808/34216 [45:55<00:33, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33813/34216 [45:55<00:32, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33818/34216 [45:55<00:32, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33823/34216 [45:55<00:32, 12.27it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33828/34216 [45:55<00:31, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33833/34216 [45:55<00:31, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33838/34216 [45:55<00:30, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33843/34216 [45:56<00:30, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33848/34216 [45:56<00:29, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33853/34216 [45:56<00:29, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33858/34216 [45:56<00:29, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33863/34216 [45:56<00:28, 12.28it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33868/34216 [45:56<00:28, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33873/34216 [45:56<00:27, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33878/34216 [45:56<00:27, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33883/34216 [45:56<00:27, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33888/34216 [45:57<00:26, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33893/34216 [45:57<00:26, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33898/34216 [45:57<00:25, 12.29it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33903/34216 [45:57<00:25, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33908/34216 [45:57<00:25, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33913/34216 [45:57<00:24, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33918/34216 [45:57<00:24, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33923/34216 [45:57<00:23, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33928/34216 [45:57<00:23, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33933/34216 [45:58<00:23, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33938/34216 [45:58<00:22, 12.30it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33943/34216 [45:58<00:22, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33948/34216 [45:58<00:21, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33953/34216 [45:58<00:21, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33958/34216 [45:58<00:20, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33963/34216 [45:58<00:20, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33968/34216 [45:58<00:20, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33973/34216 [45:58<00:19, 12.31it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33978/34216 [45:59<00:19, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33983/34216 [45:59<00:18, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33988/34216 [45:59<00:18, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33993/34216 [45:59<00:18, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 33998/34216 [45:59<00:17, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34003/34216 [45:59<00:17, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34008/34216 [45:59<00:16, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34013/34216 [45:59<00:16, 12.32it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34018/34216 [45:59<00:16, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34023/34216 [45:59<00:15, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34028/34216 [46:00<00:15, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34033/34216 [46:00<00:14, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34038/34216 [46:00<00:14, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1:  99% 34043/34216 [46:00<00:14, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34048/34216 [46:00<00:13, 12.33it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34053/34216 [46:00<00:13, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34058/34216 [46:00<00:12, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34063/34216 [46:00<00:12, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34068/34216 [46:00<00:11, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34073/34216 [46:01<00:11, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34078/34216 [46:01<00:11, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34083/34216 [46:01<00:10, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34088/34216 [46:01<00:10, 12.34it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34093/34216 [46:01<00:09, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34098/34216 [46:01<00:09, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34103/34216 [46:01<00:09, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34108/34216 [46:01<00:08, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34113/34216 [46:01<00:08, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34118/34216 [46:02<00:07, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34123/34216 [46:02<00:07, 12.35it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34128/34216 [46:02<00:07, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34133/34216 [46:02<00:06, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34138/34216 [46:02<00:06, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34143/34216 [46:02<00:05, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34148/34216 [46:02<00:05, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34153/34216 [46:02<00:05, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34158/34216 [46:02<00:04, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34163/34216 [46:02<00:04, 12.36it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34168/34216 [46:03<00:03, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34173/34216 [46:03<00:03, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34178/34216 [46:03<00:03, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34183/34216 [46:03<00:02, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34188/34216 [46:03<00:02, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34193/34216 [46:03<00:01, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34198/34216 [46:03<00:01, 12.37it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34203/34216 [46:03<00:01, 12.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34208/34216 [46:03<00:00, 12.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=9.100]\n","Epoch 1: 100% 34216/34216 [46:04<00:00, 12.38it/s, loss=8.18, v_num=5, train_loss=8.070, val_loss=8.920]\n","                                                   \u001b[AEpoch 1, global step 60901: val_loss reached 8.92419 (best 8.92419), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=01-val_loss=8.924.ckpt\" as top 3\n","tcmalloc: large alloc 2064490496 bytes == 0x14059c000 @  0x7fec0a05c615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7febdf4a7734 0x7febdf512389 0x7feb6dbb3665 0x7feb6dbafbca 0x7feb6dbb4079 0x7febdf512922 0x7febdf158cae 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91\n","Epoch 2:  89% 30451/34216 [44:38<05:31, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  89% 30453/34216 [44:38<05:31, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30458/34216 [44:38<05:30, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30463/34216 [44:39<05:30, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30468/34216 [44:39<05:29, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30473/34216 [44:39<05:29, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30478/34216 [44:39<05:28, 11.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30483/34216 [44:39<05:28, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30488/34216 [44:39<05:27, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30493/34216 [44:39<05:27, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30498/34216 [44:39<05:26, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30503/34216 [44:39<05:26, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30508/34216 [44:40<05:25, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30513/34216 [44:40<05:25, 11.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30518/34216 [44:40<05:24, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30523/34216 [44:40<05:24, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30528/34216 [44:40<05:23, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30533/34216 [44:40<05:23, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30538/34216 [44:40<05:22, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30543/34216 [44:40<05:22, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30548/34216 [44:40<05:21, 11.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30553/34216 [44:41<05:21, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30558/34216 [44:41<05:20, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30563/34216 [44:41<05:20, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30568/34216 [44:41<05:20, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30573/34216 [44:41<05:19, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30578/34216 [44:41<05:19, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30583/34216 [44:41<05:18, 11.40it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30588/34216 [44:41<05:18, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30593/34216 [44:41<05:17, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30598/34216 [44:42<05:17, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30603/34216 [44:42<05:16, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30608/34216 [44:42<05:16, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30613/34216 [44:42<05:15, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30618/34216 [44:42<05:15, 11.41it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  89% 30623/34216 [44:42<05:14, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30628/34216 [44:42<05:14, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30633/34216 [44:42<05:13, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30638/34216 [44:42<05:13, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30643/34216 [44:43<05:12, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30648/34216 [44:43<05:12, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30653/34216 [44:43<05:11, 11.42it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30658/34216 [44:43<05:11, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30663/34216 [44:43<05:10, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30668/34216 [44:43<05:10, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30673/34216 [44:43<05:09, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30678/34216 [44:43<05:09, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30683/34216 [44:43<05:09, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30688/34216 [44:44<05:08, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30693/34216 [44:44<05:08, 11.43it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30698/34216 [44:44<05:07, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30703/34216 [44:44<05:07, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30708/34216 [44:44<05:06, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30713/34216 [44:44<05:06, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30718/34216 [44:44<05:05, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30723/34216 [44:44<05:05, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30728/34216 [44:44<05:04, 11.44it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30733/34216 [44:45<05:04, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30738/34216 [44:45<05:03, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30743/34216 [44:45<05:03, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30748/34216 [44:45<05:02, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30753/34216 [44:45<05:02, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30758/34216 [44:45<05:01, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30763/34216 [44:45<05:01, 11.45it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30768/34216 [44:45<05:00, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30773/34216 [44:45<05:00, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30778/34216 [44:46<05:00, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30783/34216 [44:46<04:59, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30788/34216 [44:46<04:59, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30793/34216 [44:46<04:58, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30798/34216 [44:46<04:58, 11.46it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30803/34216 [44:46<04:57, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30808/34216 [44:46<04:57, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30813/34216 [44:46<04:56, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30818/34216 [44:46<04:56, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30823/34216 [44:47<04:55, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30828/34216 [44:47<04:55, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30833/34216 [44:47<04:54, 11.47it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30838/34216 [44:47<04:54, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30843/34216 [44:47<04:53, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30848/34216 [44:47<04:53, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30853/34216 [44:47<04:52, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30858/34216 [44:47<04:52, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30863/34216 [44:47<04:52, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30868/34216 [44:47<04:51, 11.48it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30873/34216 [44:48<04:51, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30878/34216 [44:48<04:50, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30883/34216 [44:48<04:50, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30888/34216 [44:48<04:49, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30893/34216 [44:48<04:49, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30898/34216 [44:48<04:48, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30903/34216 [44:48<04:48, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30908/34216 [44:48<04:47, 11.49it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30913/34216 [44:48<04:47, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30918/34216 [44:49<04:46, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30923/34216 [44:49<04:46, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30928/34216 [44:49<04:45, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30933/34216 [44:49<04:45, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30938/34216 [44:49<04:44, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30943/34216 [44:49<04:44, 11.50it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30948/34216 [44:49<04:44, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30953/34216 [44:49<04:43, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30958/34216 [44:49<04:43, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  90% 30963/34216 [44:50<04:42, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30968/34216 [44:50<04:42, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30973/34216 [44:50<04:41, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30978/34216 [44:50<04:41, 11.51it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30983/34216 [44:50<04:40, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30988/34216 [44:50<04:40, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30993/34216 [44:50<04:39, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 30998/34216 [44:50<04:39, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31003/34216 [44:50<04:38, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31008/34216 [44:50<04:38, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31013/34216 [44:51<04:37, 11.52it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31018/34216 [44:51<04:37, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31023/34216 [44:51<04:36, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31028/34216 [44:51<04:36, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31033/34216 [44:51<04:36, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31038/34216 [44:51<04:35, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31043/34216 [44:51<04:35, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31048/34216 [44:51<04:34, 11.53it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31053/34216 [44:51<04:34, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31058/34216 [44:52<04:33, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31063/34216 [44:52<04:33, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31068/34216 [44:52<04:32, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31073/34216 [44:52<04:32, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31078/34216 [44:52<04:31, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31083/34216 [44:52<04:31, 11.54it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31088/34216 [44:52<04:30, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31093/34216 [44:52<04:30, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31098/34216 [44:52<04:30, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31103/34216 [44:53<04:29, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31108/34216 [44:53<04:29, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31113/34216 [44:53<04:28, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31118/34216 [44:53<04:28, 11.55it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31123/34216 [44:53<04:27, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31128/34216 [44:53<04:27, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31133/34216 [44:53<04:26, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31138/34216 [44:53<04:26, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31143/34216 [44:53<04:25, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31148/34216 [44:53<04:25, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31153/34216 [44:54<04:24, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31158/34216 [44:54<04:24, 11.56it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31163/34216 [44:54<04:23, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31168/34216 [44:54<04:23, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31173/34216 [44:54<04:23, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31178/34216 [44:54<04:22, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31183/34216 [44:54<04:22, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31188/34216 [44:54<04:21, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31193/34216 [44:54<04:21, 11.57it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31198/34216 [44:55<04:20, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31203/34216 [44:55<04:20, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31208/34216 [44:55<04:19, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31213/34216 [44:55<04:19, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31218/34216 [44:55<04:18, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31223/34216 [44:55<04:18, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31228/34216 [44:55<04:17, 11.58it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31233/34216 [44:55<04:17, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31238/34216 [44:55<04:17, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31243/34216 [44:55<04:16, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31248/34216 [44:56<04:16, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31253/34216 [44:56<04:15, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31258/34216 [44:56<04:15, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31263/34216 [44:56<04:14, 11.59it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31268/34216 [44:56<04:14, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31273/34216 [44:56<04:13, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31278/34216 [44:56<04:13, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31283/34216 [44:56<04:12, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31288/34216 [44:56<04:12, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31293/34216 [44:57<04:11, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31298/34216 [44:57<04:11, 11.60it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  91% 31303/34216 [44:57<04:11, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31308/34216 [44:57<04:10, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31313/34216 [44:57<04:10, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31318/34216 [44:57<04:09, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31323/34216 [44:57<04:09, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31328/34216 [44:57<04:08, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31333/34216 [44:57<04:08, 11.61it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31338/34216 [44:58<04:07, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31343/34216 [44:58<04:07, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31348/34216 [44:58<04:06, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31353/34216 [44:58<04:06, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31358/34216 [44:58<04:05, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31363/34216 [44:58<04:05, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31368/34216 [44:58<04:05, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31373/34216 [44:58<04:04, 11.62it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31378/34216 [44:58<04:04, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31383/34216 [44:58<04:03, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31388/34216 [44:59<04:03, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31393/34216 [44:59<04:02, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31398/34216 [44:59<04:02, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31403/34216 [44:59<04:01, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31408/34216 [44:59<04:01, 11.63it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31413/34216 [44:59<04:00, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31418/34216 [44:59<04:00, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31423/34216 [44:59<03:59, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31428/34216 [44:59<03:59, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31433/34216 [45:00<03:59, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31438/34216 [45:00<03:58, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31443/34216 [45:00<03:58, 11.64it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31448/34216 [45:00<03:57, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31453/34216 [45:00<03:57, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31458/34216 [45:00<03:56, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31463/34216 [45:00<03:56, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31468/34216 [45:00<03:55, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31473/34216 [45:00<03:55, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31478/34216 [45:01<03:54, 11.65it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31483/34216 [45:01<03:54, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31488/34216 [45:01<03:54, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31493/34216 [45:01<03:53, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31498/34216 [45:01<03:53, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31503/34216 [45:01<03:52, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31508/34216 [45:01<03:52, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31513/34216 [45:01<03:51, 11.66it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31518/34216 [45:01<03:51, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31523/34216 [45:02<03:50, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31528/34216 [45:02<03:50, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31533/34216 [45:02<03:49, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31538/34216 [45:02<03:49, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31543/34216 [45:02<03:49, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31548/34216 [45:02<03:48, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31553/34216 [45:02<03:48, 11.67it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31558/34216 [45:02<03:47, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31563/34216 [45:02<03:47, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31568/34216 [45:03<03:46, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31573/34216 [45:03<03:46, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31578/34216 [45:03<03:45, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31583/34216 [45:03<03:45, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31588/34216 [45:03<03:44, 11.68it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31593/34216 [45:03<03:44, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31598/34216 [45:03<03:44, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31603/34216 [45:03<03:43, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31608/34216 [45:03<03:43, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31613/34216 [45:04<03:42, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31618/34216 [45:04<03:42, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31623/34216 [45:04<03:41, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31628/34216 [45:04<03:41, 11.69it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31633/34216 [45:04<03:40, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31638/34216 [45:04<03:40, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31643/34216 [45:04<03:39, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  92% 31648/34216 [45:04<03:39, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31653/34216 [45:05<03:39, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31658/34216 [45:05<03:38, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31663/34216 [45:05<03:38, 11.70it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31668/34216 [45:05<03:37, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31673/34216 [45:05<03:37, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31678/34216 [45:05<03:36, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31683/34216 [45:05<03:36, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31688/34216 [45:05<03:35, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31693/34216 [45:05<03:35, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31698/34216 [45:06<03:34, 11.71it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31703/34216 [45:06<03:34, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31708/34216 [45:06<03:34, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31713/34216 [45:06<03:33, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31718/34216 [45:06<03:33, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31723/34216 [45:06<03:32, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31728/34216 [45:06<03:32, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31733/34216 [45:06<03:31, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31738/34216 [45:06<03:31, 11.72it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31743/34216 [45:07<03:30, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31748/34216 [45:07<03:30, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31753/34216 [45:07<03:30, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31758/34216 [45:07<03:29, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31763/34216 [45:07<03:29, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31768/34216 [45:07<03:28, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31773/34216 [45:07<03:28, 11.73it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31778/34216 [45:07<03:27, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31783/34216 [45:08<03:27, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31788/34216 [45:08<03:26, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31793/34216 [45:08<03:26, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31798/34216 [45:08<03:25, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31803/34216 [45:08<03:25, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31808/34216 [45:08<03:25, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31813/34216 [45:08<03:24, 11.74it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31818/34216 [45:08<03:24, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31823/34216 [45:08<03:23, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31828/34216 [45:09<03:23, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31833/34216 [45:09<03:22, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31838/34216 [45:09<03:22, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31843/34216 [45:09<03:21, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31848/34216 [45:09<03:21, 11.75it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31853/34216 [45:09<03:21, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31858/34216 [45:09<03:20, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31863/34216 [45:09<03:20, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31868/34216 [45:09<03:19, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31873/34216 [45:10<03:19, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31878/34216 [45:10<03:18, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31883/34216 [45:10<03:18, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31888/34216 [45:10<03:17, 11.76it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31893/34216 [45:10<03:17, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31898/34216 [45:10<03:16, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31903/34216 [45:10<03:16, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31908/34216 [45:10<03:16, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31913/34216 [45:10<03:15, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31918/34216 [45:11<03:15, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31923/34216 [45:11<03:14, 11.77it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31928/34216 [45:11<03:14, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31933/34216 [45:11<03:13, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31938/34216 [45:11<03:13, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31943/34216 [45:11<03:12, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31948/34216 [45:11<03:12, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31953/34216 [45:11<03:12, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31958/34216 [45:11<03:11, 11.78it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31963/34216 [45:12<03:11, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31968/34216 [45:12<03:10, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31973/34216 [45:12<03:10, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31978/34216 [45:12<03:09, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31983/34216 [45:12<03:09, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  93% 31988/34216 [45:12<03:08, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 31993/34216 [45:12<03:08, 11.79it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 31998/34216 [45:12<03:08, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32003/34216 [45:12<03:07, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32008/34216 [45:13<03:07, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32013/34216 [45:13<03:06, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32018/34216 [45:13<03:06, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32023/34216 [45:13<03:05, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32028/34216 [45:13<03:05, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32033/34216 [45:13<03:04, 11.80it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32038/34216 [45:13<03:04, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32043/34216 [45:13<03:04, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32048/34216 [45:13<03:03, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32053/34216 [45:13<03:03, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32058/34216 [45:14<03:02, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32063/34216 [45:14<03:02, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32068/34216 [45:14<03:01, 11.81it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32073/34216 [45:14<03:01, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32078/34216 [45:14<03:00, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32083/34216 [45:14<03:00, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32088/34216 [45:14<03:00, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32093/34216 [45:14<02:59, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32098/34216 [45:14<02:59, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32103/34216 [45:15<02:58, 11.82it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32108/34216 [45:15<02:58, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32113/34216 [45:15<02:57, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32118/34216 [45:15<02:57, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32123/34216 [45:15<02:56, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32128/34216 [45:15<02:56, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32133/34216 [45:15<02:56, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32138/34216 [45:15<02:55, 11.83it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32143/34216 [45:15<02:55, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32148/34216 [45:16<02:54, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32153/34216 [45:16<02:54, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32158/34216 [45:16<02:53, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32163/34216 [45:16<02:53, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32168/34216 [45:16<02:52, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32173/34216 [45:16<02:52, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32178/34216 [45:16<02:52, 11.84it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32183/34216 [45:16<02:51, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32188/34216 [45:16<02:51, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32193/34216 [45:17<02:50, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32198/34216 [45:17<02:50, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32203/34216 [45:17<02:49, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32208/34216 [45:17<02:49, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32213/34216 [45:17<02:48, 11.85it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32218/34216 [45:17<02:48, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32223/34216 [45:17<02:48, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32228/34216 [45:17<02:47, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32233/34216 [45:17<02:47, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32238/34216 [45:18<02:46, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32243/34216 [45:18<02:46, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32248/34216 [45:18<02:45, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32253/34216 [45:18<02:45, 11.86it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32258/34216 [45:18<02:45, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32263/34216 [45:18<02:44, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32268/34216 [45:18<02:44, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32273/34216 [45:18<02:43, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32278/34216 [45:18<02:43, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32283/34216 [45:19<02:42, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32288/34216 [45:19<02:42, 11.87it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32293/34216 [45:19<02:41, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32298/34216 [45:19<02:41, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32303/34216 [45:19<02:41, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32308/34216 [45:19<02:40, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32313/34216 [45:19<02:40, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32318/34216 [45:19<02:39, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32323/34216 [45:19<02:39, 11.88it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32328/34216 [45:20<02:38, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  94% 32333/34216 [45:20<02:38, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32338/34216 [45:20<02:37, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32343/34216 [45:20<02:37, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32348/34216 [45:20<02:37, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32353/34216 [45:20<02:36, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32358/34216 [45:20<02:36, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32363/34216 [45:20<02:35, 11.89it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32368/34216 [45:20<02:35, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32373/34216 [45:21<02:34, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32378/34216 [45:21<02:34, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32383/34216 [45:21<02:34, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32388/34216 [45:21<02:33, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32393/34216 [45:21<02:33, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32398/34216 [45:21<02:32, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32403/34216 [45:21<02:32, 11.90it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32408/34216 [45:21<02:31, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32413/34216 [45:22<02:31, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32418/34216 [45:22<02:30, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32423/34216 [45:22<02:30, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32428/34216 [45:22<02:30, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32433/34216 [45:22<02:29, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32438/34216 [45:22<02:29, 11.91it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32443/34216 [45:22<02:28, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32448/34216 [45:22<02:28, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32453/34216 [45:22<02:27, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32458/34216 [45:23<02:27, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32463/34216 [45:23<02:27, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32468/34216 [45:23<02:26, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32473/34216 [45:23<02:26, 11.92it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32478/34216 [45:23<02:25, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32483/34216 [45:23<02:25, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32488/34216 [45:23<02:24, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32493/34216 [45:23<02:24, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32498/34216 [45:23<02:23, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32503/34216 [45:23<02:23, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32508/34216 [45:24<02:23, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32513/34216 [45:24<02:22, 11.93it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32518/34216 [45:24<02:22, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32523/34216 [45:24<02:21, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32528/34216 [45:24<02:21, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32533/34216 [45:24<02:20, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32538/34216 [45:24<02:20, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32543/34216 [45:24<02:20, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32548/34216 [45:24<02:19, 11.94it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32553/34216 [45:25<02:19, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32558/34216 [45:25<02:18, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32563/34216 [45:25<02:18, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32568/34216 [45:25<02:17, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32573/34216 [45:25<02:17, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32578/34216 [45:25<02:17, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32583/34216 [45:25<02:16, 11.95it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32588/34216 [45:25<02:16, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32593/34216 [45:25<02:15, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32598/34216 [45:26<02:15, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32603/34216 [45:26<02:14, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32608/34216 [45:26<02:14, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32613/34216 [45:26<02:14, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32618/34216 [45:26<02:13, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32623/34216 [45:26<02:13, 11.96it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32628/34216 [45:26<02:12, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32633/34216 [45:26<02:12, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32638/34216 [45:26<02:11, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32643/34216 [45:27<02:11, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32648/34216 [45:27<02:10, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32653/34216 [45:27<02:10, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32658/34216 [45:27<02:10, 11.97it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32663/34216 [45:27<02:09, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32668/34216 [45:27<02:09, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  95% 32673/34216 [45:27<02:08, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32678/34216 [45:27<02:08, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32683/34216 [45:27<02:07, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32688/34216 [45:28<02:07, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32693/34216 [45:28<02:07, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32698/34216 [45:28<02:06, 11.98it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32703/34216 [45:28<02:06, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32708/34216 [45:28<02:05, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32713/34216 [45:28<02:05, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32718/34216 [45:28<02:04, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32723/34216 [45:28<02:04, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32728/34216 [45:28<02:04, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32733/34216 [45:29<02:03, 11.99it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32738/34216 [45:29<02:03, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32743/34216 [45:29<02:02, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32748/34216 [45:29<02:02, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32753/34216 [45:29<02:01, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32758/34216 [45:29<02:01, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32763/34216 [45:29<02:01, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32768/34216 [45:29<02:00, 12.00it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32773/34216 [45:29<02:00, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32778/34216 [45:29<01:59, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32783/34216 [45:30<01:59, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32788/34216 [45:30<01:58, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32793/34216 [45:30<01:58, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32798/34216 [45:30<01:58, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32803/34216 [45:30<01:57, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32808/34216 [45:30<01:57, 12.01it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32813/34216 [45:30<01:56, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32818/34216 [45:30<01:56, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32823/34216 [45:30<01:55, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32828/34216 [45:31<01:55, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32833/34216 [45:31<01:55, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32838/34216 [45:31<01:54, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32843/34216 [45:31<01:54, 12.02it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32848/34216 [45:31<01:53, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32853/34216 [45:31<01:53, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32858/34216 [45:31<01:52, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32863/34216 [45:31<01:52, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32868/34216 [45:31<01:52, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32873/34216 [45:31<01:51, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32878/34216 [45:32<01:51, 12.03it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32883/34216 [45:32<01:50, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32888/34216 [45:32<01:50, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32893/34216 [45:32<01:49, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32898/34216 [45:32<01:49, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32903/34216 [45:32<01:49, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32908/34216 [45:32<01:48, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32913/34216 [45:32<01:48, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32918/34216 [45:32<01:47, 12.04it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32923/34216 [45:33<01:47, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32928/34216 [45:33<01:46, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32933/34216 [45:33<01:46, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32938/34216 [45:33<01:46, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32943/34216 [45:33<01:45, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32948/34216 [45:33<01:45, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32953/34216 [45:33<01:44, 12.05it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32958/34216 [45:33<01:44, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32963/34216 [45:33<01:43, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32968/34216 [45:34<01:43, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32973/34216 [45:34<01:43, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32978/34216 [45:34<01:42, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32983/34216 [45:34<01:42, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32988/34216 [45:34<01:41, 12.06it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32993/34216 [45:34<01:41, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 32998/34216 [45:34<01:40, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 33003/34216 [45:34<01:40, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 33008/34216 [45:34<01:40, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 33013/34216 [45:35<01:39, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  96% 33018/34216 [45:35<01:39, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33023/34216 [45:35<01:38, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33028/34216 [45:35<01:38, 12.07it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33033/34216 [45:35<01:37, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33038/34216 [45:35<01:37, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33043/34216 [45:35<01:37, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33048/34216 [45:35<01:36, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33053/34216 [45:35<01:36, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33058/34216 [45:36<01:35, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33063/34216 [45:36<01:35, 12.08it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33068/34216 [45:36<01:34, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33073/34216 [45:36<01:34, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33078/34216 [45:36<01:34, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33083/34216 [45:36<01:33, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33088/34216 [45:36<01:33, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33093/34216 [45:36<01:32, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33098/34216 [45:36<01:32, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33103/34216 [45:37<01:32, 12.09it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33108/34216 [45:37<01:31, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33113/34216 [45:37<01:31, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33118/34216 [45:37<01:30, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33123/34216 [45:37<01:30, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33128/34216 [45:37<01:29, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33133/34216 [45:37<01:29, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33138/34216 [45:37<01:29, 12.10it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33143/34216 [45:37<01:28, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33148/34216 [45:37<01:28, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33153/34216 [45:38<01:27, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33158/34216 [45:38<01:27, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33163/34216 [45:38<01:26, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33168/34216 [45:38<01:26, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33173/34216 [45:38<01:26, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33178/34216 [45:38<01:25, 12.11it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33183/34216 [45:38<01:25, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33188/34216 [45:38<01:24, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33193/34216 [45:38<01:24, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33198/34216 [45:39<01:23, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33203/34216 [45:39<01:23, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33208/34216 [45:39<01:23, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33213/34216 [45:39<01:22, 12.12it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33218/34216 [45:39<01:22, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33223/34216 [45:39<01:21, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33228/34216 [45:39<01:21, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33233/34216 [45:39<01:21, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33238/34216 [45:39<01:20, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33243/34216 [45:40<01:20, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33248/34216 [45:40<01:19, 12.13it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33253/34216 [45:40<01:19, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33258/34216 [45:40<01:18, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33263/34216 [45:40<01:18, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33268/34216 [45:40<01:18, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33273/34216 [45:40<01:17, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33278/34216 [45:40<01:17, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33283/34216 [45:40<01:16, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33288/34216 [45:41<01:16, 12.14it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33293/34216 [45:41<01:15, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33298/34216 [45:41<01:15, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33303/34216 [45:41<01:15, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33308/34216 [45:41<01:14, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33313/34216 [45:41<01:14, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33318/34216 [45:41<01:13, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33323/34216 [45:41<01:13, 12.15it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33328/34216 [45:41<01:13, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33333/34216 [45:41<01:12, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33338/34216 [45:42<01:12, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33343/34216 [45:42<01:11, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33348/34216 [45:42<01:11, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33353/34216 [45:42<01:10, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  97% 33358/34216 [45:42<01:10, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33363/34216 [45:42<01:10, 12.16it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33368/34216 [45:42<01:09, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33373/34216 [45:42<01:09, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33378/34216 [45:42<01:08, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33383/34216 [45:43<01:08, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33388/34216 [45:43<01:08, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33393/34216 [45:43<01:07, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33398/34216 [45:43<01:07, 12.17it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33403/34216 [45:43<01:06, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33408/34216 [45:43<01:06, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33413/34216 [45:43<01:05, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33418/34216 [45:43<01:05, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33423/34216 [45:43<01:05, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33428/34216 [45:44<01:04, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33433/34216 [45:44<01:04, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33438/34216 [45:44<01:03, 12.18it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33443/34216 [45:44<01:03, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33448/34216 [45:44<01:03, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33453/34216 [45:44<01:02, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33458/34216 [45:44<01:02, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33463/34216 [45:44<01:01, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33468/34216 [45:44<01:01, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33473/34216 [45:45<01:00, 12.19it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33478/34216 [45:45<01:00, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33483/34216 [45:45<01:00, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33488/34216 [45:45<00:59, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33493/34216 [45:45<00:59, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33498/34216 [45:45<00:58, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33503/34216 [45:45<00:58, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33508/34216 [45:45<00:58, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33513/34216 [45:45<00:57, 12.20it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33518/34216 [45:46<00:57, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33523/34216 [45:46<00:56, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33528/34216 [45:46<00:56, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33533/34216 [45:46<00:55, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33538/34216 [45:46<00:55, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33543/34216 [45:46<00:55, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33548/34216 [45:46<00:54, 12.21it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33553/34216 [45:46<00:54, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33558/34216 [45:46<00:53, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33563/34216 [45:47<00:53, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33568/34216 [45:47<00:53, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33573/34216 [45:47<00:52, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33578/34216 [45:47<00:52, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33583/34216 [45:47<00:51, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33588/34216 [45:47<00:51, 12.22it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33593/34216 [45:47<00:50, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33598/34216 [45:47<00:50, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33603/34216 [45:47<00:50, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33608/34216 [45:47<00:49, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33613/34216 [45:48<00:49, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33618/34216 [45:48<00:48, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33623/34216 [45:48<00:48, 12.23it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33628/34216 [45:48<00:48, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33633/34216 [45:48<00:47, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33638/34216 [45:48<00:47, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33643/34216 [45:48<00:46, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33648/34216 [45:48<00:46, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33653/34216 [45:48<00:45, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33658/34216 [45:49<00:45, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33663/34216 [45:49<00:45, 12.24it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33668/34216 [45:49<00:44, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33673/34216 [45:49<00:44, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33678/34216 [45:49<00:43, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33683/34216 [45:49<00:43, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33688/34216 [45:49<00:43, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33693/34216 [45:49<00:42, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  98% 33698/34216 [45:49<00:42, 12.25it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33703/34216 [45:50<00:41, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33708/34216 [45:50<00:41, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33713/34216 [45:50<00:41, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33718/34216 [45:50<00:40, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33723/34216 [45:50<00:40, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33728/34216 [45:50<00:39, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33733/34216 [45:50<00:39, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33738/34216 [45:50<00:38, 12.26it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33743/34216 [45:50<00:38, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33748/34216 [45:50<00:38, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33753/34216 [45:51<00:37, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33758/34216 [45:51<00:37, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33763/34216 [45:51<00:36, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33768/34216 [45:51<00:36, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33773/34216 [45:51<00:36, 12.27it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33778/34216 [45:51<00:35, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33783/34216 [45:51<00:35, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33788/34216 [45:51<00:34, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33793/34216 [45:51<00:34, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33798/34216 [45:52<00:34, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33803/34216 [45:52<00:33, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33808/34216 [45:52<00:33, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33813/34216 [45:52<00:32, 12.28it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33818/34216 [45:52<00:32, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33823/34216 [45:52<00:31, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33828/34216 [45:52<00:31, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33833/34216 [45:52<00:31, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33838/34216 [45:52<00:30, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33843/34216 [45:53<00:30, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33848/34216 [45:53<00:29, 12.29it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33853/34216 [45:53<00:29, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33858/34216 [45:53<00:29, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33863/34216 [45:53<00:28, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33868/34216 [45:53<00:28, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33873/34216 [45:53<00:27, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33878/34216 [45:53<00:27, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33883/34216 [45:53<00:27, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33888/34216 [45:54<00:26, 12.30it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33893/34216 [45:54<00:26, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33898/34216 [45:54<00:25, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33903/34216 [45:54<00:25, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33908/34216 [45:54<00:25, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33913/34216 [45:54<00:24, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33918/34216 [45:54<00:24, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33923/34216 [45:54<00:23, 12.31it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33928/34216 [45:54<00:23, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33933/34216 [45:55<00:22, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33938/34216 [45:55<00:22, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33943/34216 [45:55<00:22, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33948/34216 [45:55<00:21, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33953/34216 [45:55<00:21, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33958/34216 [45:55<00:20, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33963/34216 [45:55<00:20, 12.32it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33968/34216 [45:55<00:20, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33973/34216 [45:56<00:19, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33978/34216 [45:56<00:19, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33983/34216 [45:56<00:18, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33988/34216 [45:56<00:18, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33993/34216 [45:56<00:18, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 33998/34216 [45:56<00:17, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34003/34216 [45:56<00:17, 12.33it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34008/34216 [45:56<00:16, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34013/34216 [45:56<00:16, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34018/34216 [45:57<00:16, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34023/34216 [45:57<00:15, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34028/34216 [45:57<00:15, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34033/34216 [45:57<00:14, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34038/34216 [45:57<00:14, 12.34it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2:  99% 34043/34216 [45:57<00:14, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34048/34216 [45:57<00:13, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34053/34216 [45:57<00:13, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34058/34216 [45:57<00:12, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34063/34216 [45:58<00:12, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34068/34216 [45:58<00:11, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34073/34216 [45:58<00:11, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34078/34216 [45:58<00:11, 12.35it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34083/34216 [45:58<00:10, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34088/34216 [45:58<00:10, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34093/34216 [45:58<00:09, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34098/34216 [45:58<00:09, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34103/34216 [45:58<00:09, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34108/34216 [45:59<00:08, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34113/34216 [45:59<00:08, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34118/34216 [45:59<00:07, 12.36it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34123/34216 [45:59<00:07, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34128/34216 [45:59<00:07, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34133/34216 [45:59<00:06, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34138/34216 [45:59<00:06, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34143/34216 [45:59<00:05, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34148/34216 [45:59<00:05, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34153/34216 [46:00<00:05, 12.37it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34158/34216 [46:00<00:04, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34163/34216 [46:00<00:04, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34168/34216 [46:00<00:03, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34173/34216 [46:00<00:03, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34178/34216 [46:00<00:03, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34183/34216 [46:00<00:02, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34188/34216 [46:00<00:02, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34193/34216 [46:00<00:01, 12.38it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34198/34216 [46:00<00:01, 12.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34203/34216 [46:01<00:01, 12.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34208/34216 [46:01<00:00, 12.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.920]\n","Epoch 2: 100% 34216/34216 [46:01<00:00, 12.39it/s, loss=8.23, v_num=5, train_loss=8.420, val_loss=8.830]\n","                                                   \u001b[AEpoch 2, global step 91352: val_loss reached 8.82943 (best 8.82943), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=02-val_loss=8.829.ckpt\" as top 3\n","Epoch 3:  89% 30451/34216 [45:23<05:36, 11.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  89% 30455/34216 [45:23<05:36, 11.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30460/34216 [45:23<05:35, 11.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30465/34216 [45:23<05:35, 11.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30470/34216 [45:23<05:34, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30475/34216 [45:24<05:34, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30480/34216 [45:24<05:33, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30485/34216 [45:24<05:33, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30490/34216 [45:24<05:32, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30495/34216 [45:24<05:32, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30500/34216 [45:24<05:31, 11.19it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30505/34216 [45:24<05:31, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30510/34216 [45:24<05:30, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30515/34216 [45:25<05:30, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30520/34216 [45:25<05:30, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30525/34216 [45:25<05:29, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30530/34216 [45:25<05:29, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30535/34216 [45:25<05:28, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30540/34216 [45:25<05:28, 11.20it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30545/34216 [45:25<05:27, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30550/34216 [45:25<05:27, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30555/34216 [45:25<05:26, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30560/34216 [45:26<05:26, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30565/34216 [45:26<05:25, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30570/34216 [45:26<05:25, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30575/34216 [45:26<05:24, 11.21it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30580/34216 [45:26<05:24, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30585/34216 [45:26<05:23, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30590/34216 [45:26<05:23, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30595/34216 [45:26<05:22, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30600/34216 [45:27<05:22, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30605/34216 [45:27<05:21, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30610/34216 [45:27<05:21, 11.22it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30615/34216 [45:27<05:20, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  89% 30620/34216 [45:27<05:20, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30625/34216 [45:27<05:19, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30630/34216 [45:27<05:19, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30635/34216 [45:27<05:18, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30640/34216 [45:27<05:18, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30645/34216 [45:28<05:17, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30650/34216 [45:28<05:17, 11.23it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30655/34216 [45:28<05:16, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30660/34216 [45:28<05:16, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30665/34216 [45:28<05:15, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30670/34216 [45:28<05:15, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30675/34216 [45:28<05:14, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30680/34216 [45:28<05:14, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30685/34216 [45:28<05:14, 11.24it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30690/34216 [45:29<05:13, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30695/34216 [45:29<05:13, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30700/34216 [45:29<05:12, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30705/34216 [45:29<05:12, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30710/34216 [45:29<05:11, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30715/34216 [45:29<05:11, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30720/34216 [45:29<05:10, 11.25it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30725/34216 [45:29<05:10, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30730/34216 [45:29<05:09, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30735/34216 [45:30<05:09, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30740/34216 [45:30<05:08, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30745/34216 [45:30<05:08, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30750/34216 [45:30<05:07, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30755/34216 [45:30<05:07, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30760/34216 [45:30<05:06, 11.26it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30765/34216 [45:30<05:06, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30770/34216 [45:30<05:05, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30775/34216 [45:30<05:05, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30780/34216 [45:31<05:04, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30785/34216 [45:31<05:04, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30790/34216 [45:31<05:03, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30795/34216 [45:31<05:03, 11.27it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30800/34216 [45:31<05:02, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30805/34216 [45:31<05:02, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30810/34216 [45:31<05:01, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30815/34216 [45:31<05:01, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30820/34216 [45:31<05:01, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30825/34216 [45:32<05:00, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30830/34216 [45:32<05:00, 11.28it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30835/34216 [45:32<04:59, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30840/34216 [45:32<04:59, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30845/34216 [45:32<04:58, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30850/34216 [45:32<04:58, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30855/34216 [45:32<04:57, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30860/34216 [45:32<04:57, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30865/34216 [45:32<04:56, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30870/34216 [45:33<04:56, 11.29it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30875/34216 [45:33<04:55, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30880/34216 [45:33<04:55, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30885/34216 [45:33<04:54, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30890/34216 [45:33<04:54, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30895/34216 [45:33<04:53, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30900/34216 [45:33<04:53, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30905/34216 [45:33<04:52, 11.30it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30910/34216 [45:34<04:52, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30915/34216 [45:34<04:51, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30920/34216 [45:34<04:51, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30925/34216 [45:34<04:50, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30930/34216 [45:34<04:50, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30935/34216 [45:34<04:50, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30940/34216 [45:34<04:49, 11.31it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30945/34216 [45:34<04:49, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30950/34216 [45:34<04:48, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30955/34216 [45:35<04:48, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30960/34216 [45:35<04:47, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  90% 30965/34216 [45:35<04:47, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 30970/34216 [45:35<04:46, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 30975/34216 [45:35<04:46, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 30980/34216 [45:35<04:45, 11.32it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 30985/34216 [45:35<04:45, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 30990/34216 [45:35<04:44, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 30995/34216 [45:35<04:44, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31000/34216 [45:36<04:43, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31005/34216 [45:36<04:43, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31010/34216 [45:36<04:42, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31015/34216 [45:36<04:42, 11.33it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31020/34216 [45:36<04:41, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31025/34216 [45:36<04:41, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31030/34216 [45:36<04:40, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31035/34216 [45:36<04:40, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31040/34216 [45:36<04:40, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31045/34216 [45:37<04:39, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31050/34216 [45:37<04:39, 11.34it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31055/34216 [45:37<04:38, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31060/34216 [45:37<04:38, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31065/34216 [45:37<04:37, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31070/34216 [45:37<04:37, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31075/34216 [45:37<04:36, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31080/34216 [45:37<04:36, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31085/34216 [45:37<04:35, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31090/34216 [45:38<04:35, 11.35it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31095/34216 [45:38<04:34, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31100/34216 [45:38<04:34, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31105/34216 [45:38<04:33, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31110/34216 [45:38<04:33, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31115/34216 [45:38<04:32, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31120/34216 [45:38<04:32, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31125/34216 [45:38<04:31, 11.36it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31130/34216 [45:38<04:31, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31135/34216 [45:39<04:31, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31140/34216 [45:39<04:30, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31145/34216 [45:39<04:30, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31150/34216 [45:39<04:29, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31155/34216 [45:39<04:29, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31160/34216 [45:39<04:28, 11.37it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31165/34216 [45:39<04:28, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31170/34216 [45:39<04:27, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31175/34216 [45:39<04:27, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31180/34216 [45:39<04:26, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31185/34216 [45:40<04:26, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31190/34216 [45:40<04:25, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31195/34216 [45:40<04:25, 11.38it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31200/34216 [45:40<04:24, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31205/34216 [45:40<04:24, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31210/34216 [45:40<04:23, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31215/34216 [45:40<04:23, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31220/34216 [45:40<04:23, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31225/34216 [45:40<04:22, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31230/34216 [45:41<04:22, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31235/34216 [45:41<04:21, 11.39it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31240/34216 [45:41<04:21, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31245/34216 [45:41<04:20, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31250/34216 [45:41<04:20, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31255/34216 [45:41<04:19, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31260/34216 [45:41<04:19, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31265/34216 [45:41<04:18, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31270/34216 [45:41<04:18, 11.40it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31275/34216 [45:42<04:17, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31280/34216 [45:42<04:17, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31285/34216 [45:42<04:16, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31290/34216 [45:42<04:16, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31295/34216 [45:42<04:15, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31300/34216 [45:42<04:15, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  91% 31305/34216 [45:42<04:15, 11.41it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31310/34216 [45:42<04:14, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31315/34216 [45:42<04:14, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31320/34216 [45:43<04:13, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31325/34216 [45:43<04:13, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31330/34216 [45:43<04:12, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31335/34216 [45:43<04:12, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31340/34216 [45:43<04:11, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31345/34216 [45:43<04:11, 11.42it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31350/34216 [45:43<04:10, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31355/34216 [45:43<04:10, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31360/34216 [45:43<04:09, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31365/34216 [45:43<04:09, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31370/34216 [45:44<04:08, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31375/34216 [45:44<04:08, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31380/34216 [45:44<04:08, 11.43it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31385/34216 [45:44<04:07, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31390/34216 [45:44<04:07, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31395/34216 [45:44<04:06, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31400/34216 [45:44<04:06, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31405/34216 [45:44<04:05, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31410/34216 [45:44<04:05, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31415/34216 [45:45<04:04, 11.44it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31420/34216 [45:45<04:04, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31425/34216 [45:45<04:03, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31430/34216 [45:45<04:03, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31435/34216 [45:45<04:02, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31440/34216 [45:45<04:02, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31445/34216 [45:45<04:01, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31450/34216 [45:45<04:01, 11.45it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31455/34216 [45:45<04:01, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31460/34216 [45:46<04:00, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31465/34216 [45:46<04:00, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31470/34216 [45:46<03:59, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31475/34216 [45:46<03:59, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31480/34216 [45:46<03:58, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31485/34216 [45:46<03:58, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31490/34216 [45:46<03:57, 11.46it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31495/34216 [45:46<03:57, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31500/34216 [45:46<03:56, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31505/34216 [45:47<03:56, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31510/34216 [45:47<03:55, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31515/34216 [45:47<03:55, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31520/34216 [45:47<03:54, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31525/34216 [45:47<03:54, 11.47it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31530/34216 [45:47<03:54, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31535/34216 [45:47<03:53, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31540/34216 [45:47<03:53, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31545/34216 [45:47<03:52, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31550/34216 [45:48<03:52, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31555/34216 [45:48<03:51, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31560/34216 [45:48<03:51, 11.48it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31565/34216 [45:48<03:50, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31570/34216 [45:48<03:50, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31575/34216 [45:48<03:49, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31580/34216 [45:48<03:49, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31585/34216 [45:48<03:48, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31590/34216 [45:48<03:48, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31595/34216 [45:49<03:48, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31600/34216 [45:49<03:47, 11.49it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31605/34216 [45:49<03:47, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31610/34216 [45:49<03:46, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31615/34216 [45:49<03:46, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31620/34216 [45:49<03:45, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31625/34216 [45:49<03:45, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31630/34216 [45:49<03:44, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31635/34216 [45:49<03:44, 11.50it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31640/34216 [45:50<03:43, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  92% 31645/34216 [45:50<03:43, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31650/34216 [45:50<03:42, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31655/34216 [45:50<03:42, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31660/34216 [45:50<03:42, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31665/34216 [45:50<03:41, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31670/34216 [45:50<03:41, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31675/34216 [45:50<03:40, 11.51it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31680/34216 [45:51<03:40, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31685/34216 [45:51<03:39, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31690/34216 [45:51<03:39, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31695/34216 [45:51<03:38, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31700/34216 [45:51<03:38, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31705/34216 [45:51<03:37, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31710/34216 [45:51<03:37, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31715/34216 [45:51<03:37, 11.52it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31720/34216 [45:51<03:36, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31725/34216 [45:52<03:36, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31730/34216 [45:52<03:35, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31735/34216 [45:52<03:35, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31740/34216 [45:52<03:34, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31745/34216 [45:52<03:34, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31750/34216 [45:52<03:33, 11.53it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31755/34216 [45:52<03:33, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31760/34216 [45:52<03:32, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31765/34216 [45:52<03:32, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31770/34216 [45:53<03:31, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31775/34216 [45:53<03:31, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31780/34216 [45:53<03:31, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31785/34216 [45:53<03:30, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31790/34216 [45:53<03:30, 11.54it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31795/34216 [45:53<03:29, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31800/34216 [45:53<03:29, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31805/34216 [45:53<03:28, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31810/34216 [45:54<03:28, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31815/34216 [45:54<03:27, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31820/34216 [45:54<03:27, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31825/34216 [45:54<03:26, 11.55it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31830/34216 [45:54<03:26, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31835/34216 [45:54<03:26, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31840/34216 [45:54<03:25, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31845/34216 [45:54<03:25, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31850/34216 [45:55<03:24, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31855/34216 [45:55<03:24, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31860/34216 [45:55<03:23, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31865/34216 [45:55<03:23, 11.56it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31870/34216 [45:55<03:22, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31875/34216 [45:55<03:22, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31880/34216 [45:55<03:21, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31885/34216 [45:55<03:21, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31890/34216 [45:55<03:21, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31895/34216 [45:56<03:20, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31900/34216 [45:56<03:20, 11.57it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31905/34216 [45:56<03:19, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31910/34216 [45:56<03:19, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31915/34216 [45:56<03:18, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31920/34216 [45:56<03:18, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31925/34216 [45:56<03:17, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31930/34216 [45:56<03:17, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31935/34216 [45:57<03:16, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31940/34216 [45:57<03:16, 11.58it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31945/34216 [45:57<03:16, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31950/34216 [45:57<03:15, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31955/34216 [45:57<03:15, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31960/34216 [45:57<03:14, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31965/34216 [45:57<03:14, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31970/34216 [45:57<03:13, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31975/34216 [45:57<03:13, 11.59it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31980/34216 [45:58<03:12, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31985/34216 [45:58<03:12, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  93% 31990/34216 [45:58<03:11, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 31995/34216 [45:58<03:11, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32000/34216 [45:58<03:11, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32005/34216 [45:58<03:10, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32010/34216 [45:58<03:10, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32015/34216 [45:58<03:09, 11.60it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32020/34216 [45:58<03:09, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32025/34216 [45:59<03:08, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32030/34216 [45:59<03:08, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32035/34216 [45:59<03:07, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32040/34216 [45:59<03:07, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32045/34216 [45:59<03:06, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32050/34216 [45:59<03:06, 11.61it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32055/34216 [45:59<03:06, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32060/34216 [45:59<03:05, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32065/34216 [45:59<03:05, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32070/34216 [45:59<03:04, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32075/34216 [46:00<03:04, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32080/34216 [46:00<03:03, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32085/34216 [46:00<03:03, 11.62it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32090/34216 [46:00<03:02, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32095/34216 [46:00<03:02, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32100/34216 [46:00<03:01, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32105/34216 [46:00<03:01, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32110/34216 [46:00<03:01, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32115/34216 [46:00<03:00, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32120/34216 [46:01<03:00, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32125/34216 [46:01<02:59, 11.63it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32130/34216 [46:01<02:59, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32135/34216 [46:01<02:58, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32140/34216 [46:01<02:58, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32145/34216 [46:01<02:57, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32150/34216 [46:01<02:57, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32155/34216 [46:01<02:57, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32160/34216 [46:01<02:56, 11.64it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32165/34216 [46:02<02:56, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32170/34216 [46:02<02:55, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32175/34216 [46:02<02:55, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32180/34216 [46:02<02:54, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32185/34216 [46:02<02:54, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32190/34216 [46:02<02:53, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32195/34216 [46:02<02:53, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32200/34216 [46:02<02:52, 11.65it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32205/34216 [46:02<02:52, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32210/34216 [46:02<02:52, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32215/34216 [46:03<02:51, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32220/34216 [46:03<02:51, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32225/34216 [46:03<02:50, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32230/34216 [46:03<02:50, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32235/34216 [46:03<02:49, 11.66it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32240/34216 [46:03<02:49, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32245/34216 [46:03<02:48, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32250/34216 [46:03<02:48, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32255/34216 [46:04<02:48, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32260/34216 [46:04<02:47, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32265/34216 [46:04<02:47, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32270/34216 [46:04<02:46, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32275/34216 [46:04<02:46, 11.67it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32280/34216 [46:04<02:45, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32285/34216 [46:04<02:45, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32290/34216 [46:04<02:44, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32295/34216 [46:04<02:44, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32300/34216 [46:05<02:44, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32305/34216 [46:05<02:43, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32310/34216 [46:05<02:43, 11.68it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32315/34216 [46:05<02:42, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32320/34216 [46:05<02:42, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32325/34216 [46:05<02:41, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  94% 32330/34216 [46:05<02:41, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32335/34216 [46:05<02:40, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32340/34216 [46:05<02:40, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32345/34216 [46:06<02:40, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32350/34216 [46:06<02:39, 11.69it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32355/34216 [46:06<02:39, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32360/34216 [46:06<02:38, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32365/34216 [46:06<02:38, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32370/34216 [46:06<02:37, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32375/34216 [46:06<02:37, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32380/34216 [46:06<02:36, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32385/34216 [46:06<02:36, 11.70it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32390/34216 [46:07<02:35, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32395/34216 [46:07<02:35, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32400/34216 [46:07<02:35, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32405/34216 [46:07<02:34, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32410/34216 [46:07<02:34, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32415/34216 [46:07<02:33, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32420/34216 [46:07<02:33, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32425/34216 [46:07<02:32, 11.71it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32430/34216 [46:07<02:32, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32435/34216 [46:08<02:31, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32440/34216 [46:08<02:31, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32445/34216 [46:08<02:31, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32450/34216 [46:08<02:30, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32455/34216 [46:08<02:30, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32460/34216 [46:08<02:29, 11.72it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32465/34216 [46:08<02:29, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32470/34216 [46:08<02:28, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32475/34216 [46:09<02:28, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32480/34216 [46:09<02:28, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32485/34216 [46:09<02:27, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32490/34216 [46:09<02:27, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32495/34216 [46:09<02:26, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32500/34216 [46:09<02:26, 11.73it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32505/34216 [46:09<02:25, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32510/34216 [46:09<02:25, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32515/34216 [46:09<02:24, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32520/34216 [46:10<02:24, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32525/34216 [46:10<02:24, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32530/34216 [46:10<02:23, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32535/34216 [46:10<02:23, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32540/34216 [46:10<02:22, 11.74it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32545/34216 [46:10<02:22, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32550/34216 [46:10<02:21, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32555/34216 [46:10<02:21, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32560/34216 [46:11<02:20, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32565/34216 [46:11<02:20, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32570/34216 [46:11<02:20, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32575/34216 [46:11<02:19, 11.75it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32580/34216 [46:11<02:19, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32585/34216 [46:11<02:18, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32590/34216 [46:11<02:18, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32595/34216 [46:11<02:17, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32600/34216 [46:12<02:17, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32605/34216 [46:12<02:16, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32610/34216 [46:12<02:16, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32615/34216 [46:12<02:16, 11.76it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32620/34216 [46:12<02:15, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32625/34216 [46:12<02:15, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32630/34216 [46:12<02:14, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32635/34216 [46:12<02:14, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32640/34216 [46:12<02:13, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32645/34216 [46:13<02:13, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32650/34216 [46:13<02:13, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32655/34216 [46:13<02:12, 11.77it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32660/34216 [46:13<02:12, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32665/34216 [46:13<02:11, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32670/34216 [46:13<02:11, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  95% 32675/34216 [46:13<02:10, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32680/34216 [46:13<02:10, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32685/34216 [46:13<02:09, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32690/34216 [46:14<02:09, 11.78it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32695/34216 [46:14<02:09, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32700/34216 [46:14<02:08, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32705/34216 [46:14<02:08, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32710/34216 [46:14<02:07, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32715/34216 [46:14<02:07, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32720/34216 [46:14<02:06, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32725/34216 [46:14<02:06, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32730/34216 [46:15<02:05, 11.79it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32735/34216 [46:15<02:05, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32740/34216 [46:15<02:05, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32745/34216 [46:15<02:04, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32750/34216 [46:15<02:04, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32755/34216 [46:15<02:03, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32760/34216 [46:15<02:03, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32765/34216 [46:15<02:02, 11.80it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32770/34216 [46:15<02:02, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32775/34216 [46:16<02:02, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32780/34216 [46:16<02:01, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32785/34216 [46:16<02:01, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32790/34216 [46:16<02:00, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32795/34216 [46:16<02:00, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32800/34216 [46:16<01:59, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32805/34216 [46:16<01:59, 11.81it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32810/34216 [46:16<01:58, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32815/34216 [46:16<01:58, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32820/34216 [46:17<01:58, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32825/34216 [46:17<01:57, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32830/34216 [46:17<01:57, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32835/34216 [46:17<01:56, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32840/34216 [46:17<01:56, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32845/34216 [46:17<01:55, 11.82it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32850/34216 [46:17<01:55, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32855/34216 [46:17<01:55, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32860/34216 [46:17<01:54, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32865/34216 [46:18<01:54, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32870/34216 [46:18<01:53, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32875/34216 [46:18<01:53, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32880/34216 [46:18<01:52, 11.83it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32885/34216 [46:18<01:52, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32890/34216 [46:18<01:52, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32895/34216 [46:18<01:51, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32900/34216 [46:18<01:51, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32905/34216 [46:18<01:50, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32910/34216 [46:19<01:50, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32915/34216 [46:19<01:49, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32920/34216 [46:19<01:49, 11.84it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32925/34216 [46:19<01:48, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32930/34216 [46:19<01:48, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32935/34216 [46:19<01:48, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32940/34216 [46:19<01:47, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32945/34216 [46:19<01:47, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32950/34216 [46:19<01:46, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32955/34216 [46:20<01:46, 11.85it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32960/34216 [46:20<01:45, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32965/34216 [46:20<01:45, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32970/34216 [46:20<01:45, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32975/34216 [46:20<01:44, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32980/34216 [46:20<01:44, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32985/34216 [46:20<01:43, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32990/34216 [46:20<01:43, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 32995/34216 [46:20<01:42, 11.86it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 33000/34216 [46:21<01:42, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 33005/34216 [46:21<01:42, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 33010/34216 [46:21<01:41, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  96% 33015/34216 [46:21<01:41, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33020/34216 [46:21<01:40, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33025/34216 [46:21<01:40, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33030/34216 [46:21<01:39, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33035/34216 [46:21<01:39, 11.87it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33040/34216 [46:22<01:39, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33045/34216 [46:22<01:38, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33050/34216 [46:22<01:38, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33055/34216 [46:22<01:37, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33060/34216 [46:22<01:37, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33065/34216 [46:22<01:36, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33070/34216 [46:22<01:36, 11.88it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33075/34216 [46:22<01:36, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33080/34216 [46:22<01:35, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33085/34216 [46:23<01:35, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33090/34216 [46:23<01:34, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33095/34216 [46:23<01:34, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33100/34216 [46:23<01:33, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33105/34216 [46:23<01:33, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33110/34216 [46:23<01:32, 11.89it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33115/34216 [46:23<01:32, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33120/34216 [46:23<01:32, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33125/34216 [46:24<01:31, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33130/34216 [46:24<01:31, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33135/34216 [46:24<01:30, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33140/34216 [46:24<01:30, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33145/34216 [46:24<01:29, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33150/34216 [46:24<01:29, 11.90it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33155/34216 [46:24<01:29, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33160/34216 [46:24<01:28, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33165/34216 [46:24<01:28, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33170/34216 [46:25<01:27, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33175/34216 [46:25<01:27, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33180/34216 [46:25<01:26, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33185/34216 [46:25<01:26, 11.91it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33190/34216 [46:25<01:26, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33195/34216 [46:25<01:25, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33200/34216 [46:25<01:25, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33205/34216 [46:25<01:24, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33210/34216 [46:25<01:24, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33215/34216 [46:26<01:23, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33220/34216 [46:26<01:23, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33225/34216 [46:26<01:23, 11.92it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33230/34216 [46:26<01:22, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33235/34216 [46:26<01:22, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33240/34216 [46:26<01:21, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33245/34216 [46:26<01:21, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33250/34216 [46:26<01:20, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33255/34216 [46:26<01:20, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33260/34216 [46:27<01:20, 11.93it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33265/34216 [46:27<01:19, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33270/34216 [46:27<01:19, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33275/34216 [46:27<01:18, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33280/34216 [46:27<01:18, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33285/34216 [46:27<01:17, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33290/34216 [46:27<01:17, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33295/34216 [46:27<01:17, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33300/34216 [46:27<01:16, 11.94it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33305/34216 [46:28<01:16, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33310/34216 [46:28<01:15, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33315/34216 [46:28<01:15, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33320/34216 [46:28<01:14, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33325/34216 [46:28<01:14, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33330/34216 [46:28<01:14, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33335/34216 [46:28<01:13, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33340/34216 [46:28<01:13, 11.95it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33345/34216 [46:28<01:12, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33350/34216 [46:29<01:12, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33355/34216 [46:29<01:11, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  97% 33360/34216 [46:29<01:11, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33365/34216 [46:29<01:11, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33370/34216 [46:29<01:10, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33375/34216 [46:29<01:10, 11.96it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33380/34216 [46:29<01:09, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33385/34216 [46:29<01:09, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33390/34216 [46:29<01:09, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33395/34216 [46:30<01:08, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33400/34216 [46:30<01:08, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33405/34216 [46:30<01:07, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33410/34216 [46:30<01:07, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33415/34216 [46:30<01:06, 11.97it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33420/34216 [46:30<01:06, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33425/34216 [46:30<01:06, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33430/34216 [46:30<01:05, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33435/34216 [46:30<01:05, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33440/34216 [46:31<01:04, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33445/34216 [46:31<01:04, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33450/34216 [46:31<01:03, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33455/34216 [46:31<01:03, 11.98it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33460/34216 [46:31<01:03, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33465/34216 [46:31<01:02, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33470/34216 [46:31<01:02, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33475/34216 [46:31<01:01, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33480/34216 [46:32<01:01, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33485/34216 [46:32<01:00, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33490/34216 [46:32<01:00, 11.99it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33495/34216 [46:32<01:00, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33500/34216 [46:32<00:59, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33505/34216 [46:32<00:59, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33510/34216 [46:32<00:58, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33515/34216 [46:32<00:58, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33520/34216 [46:32<00:57, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33525/34216 [46:33<00:57, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33530/34216 [46:33<00:57, 12.00it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33535/34216 [46:33<00:56, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33540/34216 [46:33<00:56, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33545/34216 [46:33<00:55, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33550/34216 [46:33<00:55, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33555/34216 [46:33<00:55, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33560/34216 [46:33<00:54, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33565/34216 [46:33<00:54, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33570/34216 [46:34<00:53, 12.01it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33575/34216 [46:34<00:53, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33580/34216 [46:34<00:52, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33585/34216 [46:34<00:52, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33590/34216 [46:34<00:52, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33595/34216 [46:34<00:51, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33600/34216 [46:34<00:51, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33605/34216 [46:34<00:50, 12.02it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33610/34216 [46:34<00:50, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33615/34216 [46:35<00:49, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33620/34216 [46:35<00:49, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33625/34216 [46:35<00:49, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33630/34216 [46:35<00:48, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33635/34216 [46:35<00:48, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33640/34216 [46:35<00:47, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33645/34216 [46:35<00:47, 12.03it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33650/34216 [46:35<00:47, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33655/34216 [46:35<00:46, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33660/34216 [46:36<00:46, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33665/34216 [46:36<00:45, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33670/34216 [46:36<00:45, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33675/34216 [46:36<00:44, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33680/34216 [46:36<00:44, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33685/34216 [46:36<00:44, 12.04it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33690/34216 [46:36<00:43, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33695/34216 [46:36<00:43, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  98% 33700/34216 [46:37<00:42, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33705/34216 [46:37<00:42, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33710/34216 [46:37<00:41, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33715/34216 [46:37<00:41, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33720/34216 [46:37<00:41, 12.05it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33725/34216 [46:37<00:40, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33730/34216 [46:37<00:40, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33735/34216 [46:37<00:39, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33740/34216 [46:37<00:39, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33745/34216 [46:38<00:39, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33750/34216 [46:38<00:38, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33755/34216 [46:38<00:38, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33760/34216 [46:38<00:37, 12.06it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33765/34216 [46:38<00:37, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33770/34216 [46:38<00:36, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33775/34216 [46:38<00:36, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33780/34216 [46:38<00:36, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33785/34216 [46:38<00:35, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33790/34216 [46:39<00:35, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33795/34216 [46:39<00:34, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33800/34216 [46:39<00:34, 12.07it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33805/34216 [46:39<00:34, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33810/34216 [46:39<00:33, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33815/34216 [46:39<00:33, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33820/34216 [46:39<00:32, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33825/34216 [46:39<00:32, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33830/34216 [46:39<00:31, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33835/34216 [46:40<00:31, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33840/34216 [46:40<00:31, 12.08it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33845/34216 [46:40<00:30, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33850/34216 [46:40<00:30, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33855/34216 [46:40<00:29, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33860/34216 [46:40<00:29, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33865/34216 [46:40<00:29, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33870/34216 [46:40<00:28, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33875/34216 [46:40<00:28, 12.09it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33880/34216 [46:41<00:27, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33885/34216 [46:41<00:27, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33890/34216 [46:41<00:26, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33895/34216 [46:41<00:26, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33900/34216 [46:41<00:26, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33905/34216 [46:41<00:25, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33910/34216 [46:41<00:25, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33915/34216 [46:41<00:24, 12.10it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33920/34216 [46:41<00:24, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33925/34216 [46:42<00:24, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33930/34216 [46:42<00:23, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33935/34216 [46:42<00:23, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33940/34216 [46:42<00:22, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33945/34216 [46:42<00:22, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33950/34216 [46:42<00:21, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33955/34216 [46:42<00:21, 12.11it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33960/34216 [46:42<00:21, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33965/34216 [46:42<00:20, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33970/34216 [46:43<00:20, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33975/34216 [46:43<00:19, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33980/34216 [46:43<00:19, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33985/34216 [46:43<00:19, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33990/34216 [46:43<00:18, 12.12it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 33995/34216 [46:43<00:18, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34000/34216 [46:43<00:17, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34005/34216 [46:43<00:17, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34010/34216 [46:43<00:16, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34015/34216 [46:44<00:16, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34020/34216 [46:44<00:16, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34025/34216 [46:44<00:15, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34030/34216 [46:44<00:15, 12.13it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34035/34216 [46:44<00:14, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3:  99% 34040/34216 [46:44<00:14, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34045/34216 [46:44<00:14, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34050/34216 [46:44<00:13, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34055/34216 [46:45<00:13, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34060/34216 [46:45<00:12, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34065/34216 [46:45<00:12, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34070/34216 [46:45<00:12, 12.14it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34075/34216 [46:45<00:11, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34080/34216 [46:45<00:11, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34085/34216 [46:45<00:10, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34090/34216 [46:45<00:10, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34095/34216 [46:45<00:09, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34100/34216 [46:46<00:09, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34105/34216 [46:46<00:09, 12.15it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34110/34216 [46:46<00:08, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34115/34216 [46:46<00:08, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34120/34216 [46:46<00:07, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34125/34216 [46:46<00:07, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34130/34216 [46:46<00:07, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34135/34216 [46:46<00:06, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34140/34216 [46:46<00:06, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34145/34216 [46:46<00:05, 12.16it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34150/34216 [46:47<00:05, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34155/34216 [46:47<00:05, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34160/34216 [46:47<00:04, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34165/34216 [46:47<00:04, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34170/34216 [46:47<00:03, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34175/34216 [46:47<00:03, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34180/34216 [46:47<00:02, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34185/34216 [46:47<00:02, 12.17it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34190/34216 [46:47<00:02, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34195/34216 [46:48<00:01, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34200/34216 [46:48<00:01, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34205/34216 [46:48<00:00, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34210/34216 [46:48<00:00, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34215/34216 [46:48<00:00, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.830]\n","Epoch 3: 100% 34216/34216 [46:48<00:00, 12.18it/s, loss=8.24, v_num=5, train_loss=8.340, val_loss=8.710]\n","                                                   \u001b[AEpoch 3, global step 121803: val_loss reached 8.71382 (best 8.71382), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=03-val_loss=8.714.ckpt\" as top 3\n","Epoch 4:  89% 30452/34216 [45:33<05:37, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/3765 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  89% 30454/34216 [45:34<05:37, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30459/34216 [45:34<05:37, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30464/34216 [45:34<05:36, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30469/34216 [45:34<05:36, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30474/34216 [45:34<05:35, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30479/34216 [45:35<05:35, 11.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30484/34216 [45:35<05:34, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30489/34216 [45:35<05:34, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30494/34216 [45:35<05:33, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30499/34216 [45:35<05:33, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30504/34216 [45:35<05:32, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30509/34216 [45:35<05:32, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30514/34216 [45:35<05:31, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30519/34216 [45:35<05:31, 11.15it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30524/34216 [45:36<05:30, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30529/34216 [45:36<05:30, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30534/34216 [45:36<05:29, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30539/34216 [45:36<05:29, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30544/34216 [45:36<05:28, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30549/34216 [45:36<05:28, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30554/34216 [45:36<05:28, 11.16it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30559/34216 [45:36<05:27, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30564/34216 [45:36<05:27, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30569/34216 [45:37<05:26, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30574/34216 [45:37<05:26, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30579/34216 [45:37<05:25, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30584/34216 [45:37<05:25, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30589/34216 [45:37<05:24, 11.17it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30594/34216 [45:37<05:24, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30599/34216 [45:37<05:23, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30604/34216 [45:37<05:23, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30609/34216 [45:37<05:22, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30614/34216 [45:38<05:22, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  89% 30619/34216 [45:38<05:21, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30624/34216 [45:38<05:21, 11.18it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30629/34216 [45:38<05:20, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30634/34216 [45:38<05:20, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30639/34216 [45:38<05:19, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30644/34216 [45:38<05:19, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30649/34216 [45:38<05:18, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30654/34216 [45:38<05:18, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30659/34216 [45:38<05:17, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30664/34216 [45:39<05:17, 11.19it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30669/34216 [45:39<05:16, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30674/34216 [45:39<05:16, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30679/34216 [45:39<05:15, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30684/34216 [45:39<05:15, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30689/34216 [45:39<05:14, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30694/34216 [45:39<05:14, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30699/34216 [45:39<05:13, 11.20it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30704/34216 [45:39<05:13, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30709/34216 [45:40<05:12, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30714/34216 [45:40<05:12, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30719/34216 [45:40<05:11, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30724/34216 [45:40<05:11, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30729/34216 [45:40<05:10, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30734/34216 [45:40<05:10, 11.21it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30739/34216 [45:40<05:10, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30744/34216 [45:40<05:09, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30749/34216 [45:40<05:09, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30754/34216 [45:41<05:08, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30759/34216 [45:41<05:08, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30764/34216 [45:41<05:07, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30769/34216 [45:41<05:07, 11.22it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30774/34216 [45:41<05:06, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30779/34216 [45:41<05:06, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30784/34216 [45:41<05:05, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30789/34216 [45:41<05:05, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30794/34216 [45:41<05:04, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30799/34216 [45:41<05:04, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30804/34216 [45:42<05:03, 11.23it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30809/34216 [45:42<05:03, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30814/34216 [45:42<05:02, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30819/34216 [45:42<05:02, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30824/34216 [45:42<05:01, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30829/34216 [45:42<05:01, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30834/34216 [45:42<05:00, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30839/34216 [45:42<05:00, 11.24it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30844/34216 [45:42<04:59, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30849/34216 [45:43<04:59, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30854/34216 [45:43<04:58, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30859/34216 [45:43<04:58, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30864/34216 [45:43<04:57, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30869/34216 [45:43<04:57, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30874/34216 [45:43<04:56, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30879/34216 [45:43<04:56, 11.25it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30884/34216 [45:43<04:56, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30889/34216 [45:43<04:55, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30894/34216 [45:43<04:55, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30899/34216 [45:44<04:54, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30904/34216 [45:44<04:54, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30909/34216 [45:44<04:53, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30914/34216 [45:44<04:53, 11.26it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30919/34216 [45:44<04:52, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30924/34216 [45:44<04:52, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30929/34216 [45:44<04:51, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30934/34216 [45:44<04:51, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30939/34216 [45:44<04:50, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30944/34216 [45:45<04:50, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30949/34216 [45:45<04:49, 11.27it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30954/34216 [45:45<04:49, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30959/34216 [45:45<04:48, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  90% 30964/34216 [45:45<04:48, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30969/34216 [45:45<04:47, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30974/34216 [45:45<04:47, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30979/34216 [45:45<04:46, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30984/34216 [45:45<04:46, 11.28it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30989/34216 [45:46<04:45, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30994/34216 [45:46<04:45, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 30999/34216 [45:46<04:44, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31004/34216 [45:46<04:44, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31009/34216 [45:46<04:44, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31014/34216 [45:46<04:43, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31019/34216 [45:46<04:43, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31024/34216 [45:46<04:42, 11.29it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31029/34216 [45:46<04:42, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31034/34216 [45:46<04:41, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31039/34216 [45:47<04:41, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31044/34216 [45:47<04:40, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31049/34216 [45:47<04:40, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31054/34216 [45:47<04:39, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31059/34216 [45:47<04:39, 11.30it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31064/34216 [45:47<04:38, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31069/34216 [45:47<04:38, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31074/34216 [45:47<04:37, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31079/34216 [45:47<04:37, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31084/34216 [45:48<04:36, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31089/34216 [45:48<04:36, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31094/34216 [45:48<04:35, 11.31it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31099/34216 [45:48<04:35, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31104/34216 [45:48<04:34, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31109/34216 [45:48<04:34, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31114/34216 [45:48<04:34, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31119/34216 [45:48<04:33, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31124/34216 [45:48<04:33, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31129/34216 [45:49<04:32, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31134/34216 [45:49<04:32, 11.32it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31139/34216 [45:49<04:31, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31144/34216 [45:49<04:31, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31149/34216 [45:49<04:30, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31154/34216 [45:49<04:30, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31159/34216 [45:49<04:29, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31164/34216 [45:49<04:29, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31169/34216 [45:49<04:28, 11.33it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31174/34216 [45:50<04:28, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31179/34216 [45:50<04:27, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31184/34216 [45:50<04:27, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31189/34216 [45:50<04:26, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31194/34216 [45:50<04:26, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31199/34216 [45:50<04:25, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31204/34216 [45:50<04:25, 11.34it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31209/34216 [45:50<04:25, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31214/34216 [45:50<04:24, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31219/34216 [45:51<04:24, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31224/34216 [45:51<04:23, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31229/34216 [45:51<04:23, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31234/34216 [45:51<04:22, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31239/34216 [45:51<04:22, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31244/34216 [45:51<04:21, 11.35it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31249/34216 [45:51<04:21, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31254/34216 [45:51<04:20, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31259/34216 [45:51<04:20, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31264/34216 [45:52<04:19, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31269/34216 [45:52<04:19, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31274/34216 [45:52<04:18, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31279/34216 [45:52<04:18, 11.36it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31284/34216 [45:52<04:17, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31289/34216 [45:52<04:17, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31294/34216 [45:52<04:17, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31299/34216 [45:52<04:16, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  91% 31304/34216 [45:52<04:16, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31309/34216 [45:52<04:15, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31314/34216 [45:53<04:15, 11.37it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31319/34216 [45:53<04:14, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31324/34216 [45:53<04:14, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31329/34216 [45:53<04:13, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31334/34216 [45:53<04:13, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31339/34216 [45:53<04:12, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31344/34216 [45:53<04:12, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31349/34216 [45:53<04:11, 11.38it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31354/34216 [45:53<04:11, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31359/34216 [45:54<04:10, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31364/34216 [45:54<04:10, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31369/34216 [45:54<04:09, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31374/34216 [45:54<04:09, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31379/34216 [45:54<04:09, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31384/34216 [45:54<04:08, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31389/34216 [45:54<04:08, 11.39it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31394/34216 [45:54<04:07, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31399/34216 [45:54<04:07, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31404/34216 [45:55<04:06, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31409/34216 [45:55<04:06, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31414/34216 [45:55<04:05, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31419/34216 [45:55<04:05, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31424/34216 [45:55<04:04, 11.40it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31429/34216 [45:55<04:04, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31434/34216 [45:55<04:03, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31439/34216 [45:55<04:03, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31444/34216 [45:55<04:02, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31449/34216 [45:56<04:02, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31454/34216 [45:56<04:02, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31459/34216 [45:56<04:01, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31464/34216 [45:56<04:01, 11.41it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31469/34216 [45:56<04:00, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31474/34216 [45:56<04:00, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31479/34216 [45:56<03:59, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31484/34216 [45:56<03:59, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31489/34216 [45:57<03:58, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31494/34216 [45:57<03:58, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31499/34216 [45:57<03:57, 11.42it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31504/34216 [45:57<03:57, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31509/34216 [45:57<03:56, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31514/34216 [45:57<03:56, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31519/34216 [45:57<03:55, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31524/34216 [45:57<03:55, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31529/34216 [45:57<03:55, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31534/34216 [45:58<03:54, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31539/34216 [45:58<03:54, 11.43it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31544/34216 [45:58<03:53, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31549/34216 [45:58<03:53, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31554/34216 [45:58<03:52, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31559/34216 [45:58<03:52, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31564/34216 [45:58<03:51, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31569/34216 [45:58<03:51, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31574/34216 [45:59<03:50, 11.44it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31579/34216 [45:59<03:50, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31584/34216 [45:59<03:49, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31589/34216 [45:59<03:49, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31594/34216 [45:59<03:49, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31599/34216 [45:59<03:48, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31604/34216 [45:59<03:48, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31609/34216 [45:59<03:47, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31614/34216 [45:59<03:47, 11.45it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31619/34216 [46:00<03:46, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31624/34216 [46:00<03:46, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31629/34216 [46:00<03:45, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31634/34216 [46:00<03:45, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31639/34216 [46:00<03:44, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31644/34216 [46:00<03:44, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  92% 31649/34216 [46:00<03:43, 11.46it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31654/34216 [46:00<03:43, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31659/34216 [46:01<03:42, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31664/34216 [46:01<03:42, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31669/34216 [46:01<03:42, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31674/34216 [46:01<03:41, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31679/34216 [46:01<03:41, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31684/34216 [46:01<03:40, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31689/34216 [46:01<03:40, 11.47it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31694/34216 [46:01<03:39, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31699/34216 [46:01<03:39, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31704/34216 [46:02<03:38, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31709/34216 [46:02<03:38, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31714/34216 [46:02<03:37, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31719/34216 [46:02<03:37, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31724/34216 [46:02<03:36, 11.48it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31729/34216 [46:02<03:36, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31734/34216 [46:02<03:36, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31739/34216 [46:02<03:35, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31744/34216 [46:02<03:35, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31749/34216 [46:03<03:34, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31754/34216 [46:03<03:34, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31759/34216 [46:03<03:33, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31764/34216 [46:03<03:33, 11.49it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31769/34216 [46:03<03:32, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31774/34216 [46:03<03:32, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31779/34216 [46:03<03:31, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31784/34216 [46:03<03:31, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31789/34216 [46:03<03:31, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31794/34216 [46:03<03:30, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31799/34216 [46:04<03:30, 11.50it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31804/34216 [46:04<03:29, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31809/34216 [46:04<03:29, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31814/34216 [46:04<03:28, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31819/34216 [46:04<03:28, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31824/34216 [46:04<03:27, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31829/34216 [46:04<03:27, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31834/34216 [46:04<03:26, 11.51it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31839/34216 [46:04<03:26, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31844/34216 [46:05<03:25, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31849/34216 [46:05<03:25, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31854/34216 [46:05<03:25, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31859/34216 [46:05<03:24, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31864/34216 [46:05<03:24, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31869/34216 [46:05<03:23, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31874/34216 [46:05<03:23, 11.52it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31879/34216 [46:05<03:22, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31884/34216 [46:05<03:22, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31889/34216 [46:06<03:21, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31894/34216 [46:06<03:21, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31899/34216 [46:06<03:20, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31904/34216 [46:06<03:20, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31909/34216 [46:06<03:20, 11.53it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31914/34216 [46:06<03:19, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31919/34216 [46:06<03:19, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31924/34216 [46:06<03:18, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31929/34216 [46:06<03:18, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31934/34216 [46:07<03:17, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31939/34216 [46:07<03:17, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31944/34216 [46:07<03:16, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31949/34216 [46:07<03:16, 11.54it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31954/34216 [46:07<03:15, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31959/34216 [46:07<03:15, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31964/34216 [46:07<03:14, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31969/34216 [46:07<03:14, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31974/34216 [46:07<03:14, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31979/34216 [46:08<03:13, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31984/34216 [46:08<03:13, 11.55it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  93% 31989/34216 [46:08<03:12, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 31994/34216 [46:08<03:12, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 31999/34216 [46:08<03:11, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32004/34216 [46:08<03:11, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32009/34216 [46:08<03:10, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32014/34216 [46:08<03:10, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32019/34216 [46:09<03:09, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32024/34216 [46:09<03:09, 11.56it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32029/34216 [46:09<03:09, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32034/34216 [46:09<03:08, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32039/34216 [46:09<03:08, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32044/34216 [46:09<03:07, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32049/34216 [46:09<03:07, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32054/34216 [46:09<03:06, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32059/34216 [46:09<03:06, 11.57it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32064/34216 [46:10<03:05, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32069/34216 [46:10<03:05, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32074/34216 [46:10<03:05, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32079/34216 [46:10<03:04, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32084/34216 [46:10<03:04, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32089/34216 [46:10<03:03, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32094/34216 [46:10<03:03, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32099/34216 [46:10<03:02, 11.58it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32104/34216 [46:10<03:02, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32109/34216 [46:10<03:01, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32114/34216 [46:11<03:01, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32119/34216 [46:11<03:00, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32124/34216 [46:11<03:00, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32129/34216 [46:11<03:00, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32134/34216 [46:11<02:59, 11.59it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32139/34216 [46:11<02:59, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32144/34216 [46:11<02:58, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32149/34216 [46:11<02:58, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32154/34216 [46:11<02:57, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32159/34216 [46:12<02:57, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32164/34216 [46:12<02:56, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32169/34216 [46:12<02:56, 11.60it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32174/34216 [46:12<02:55, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32179/34216 [46:12<02:55, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32184/34216 [46:12<02:55, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32189/34216 [46:12<02:54, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32194/34216 [46:12<02:54, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32199/34216 [46:12<02:53, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32204/34216 [46:13<02:53, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32209/34216 [46:13<02:52, 11.61it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32214/34216 [46:13<02:52, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32219/34216 [46:13<02:51, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32224/34216 [46:13<02:51, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32229/34216 [46:13<02:51, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32234/34216 [46:13<02:50, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32239/34216 [46:13<02:50, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32244/34216 [46:13<02:49, 11.62it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32249/34216 [46:14<02:49, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32254/34216 [46:14<02:48, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32259/34216 [46:14<02:48, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32264/34216 [46:14<02:47, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32269/34216 [46:14<02:47, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32274/34216 [46:14<02:46, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32279/34216 [46:14<02:46, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32284/34216 [46:14<02:46, 11.63it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32289/34216 [46:14<02:45, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32294/34216 [46:15<02:45, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32299/34216 [46:15<02:44, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32304/34216 [46:15<02:44, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32309/34216 [46:15<02:43, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32314/34216 [46:15<02:43, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32319/34216 [46:15<02:42, 11.64it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32324/34216 [46:15<02:42, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32329/34216 [46:15<02:42, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  94% 32334/34216 [46:15<02:41, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32339/34216 [46:16<02:41, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32344/34216 [46:16<02:40, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32349/34216 [46:16<02:40, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32354/34216 [46:16<02:39, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32359/34216 [46:16<02:39, 11.65it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32364/34216 [46:16<02:38, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32369/34216 [46:16<02:38, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32374/34216 [46:16<02:37, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32379/34216 [46:16<02:37, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32384/34216 [46:17<02:37, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32389/34216 [46:17<02:36, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32394/34216 [46:17<02:36, 11.66it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32399/34216 [46:17<02:35, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32404/34216 [46:17<02:35, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32409/34216 [46:17<02:34, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32414/34216 [46:17<02:34, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32419/34216 [46:17<02:33, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32424/34216 [46:17<02:33, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32429/34216 [46:18<02:33, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32434/34216 [46:18<02:32, 11.67it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32439/34216 [46:18<02:32, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32444/34216 [46:18<02:31, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32449/34216 [46:18<02:31, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32454/34216 [46:18<02:30, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32459/34216 [46:18<02:30, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32464/34216 [46:18<02:29, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32469/34216 [46:18<02:29, 11.68it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32474/34216 [46:18<02:29, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32479/34216 [46:19<02:28, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32484/34216 [46:19<02:28, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32489/34216 [46:19<02:27, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32494/34216 [46:19<02:27, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32499/34216 [46:19<02:26, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32504/34216 [46:19<02:26, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32509/34216 [46:19<02:25, 11.69it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32514/34216 [46:19<02:25, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32519/34216 [46:20<02:25, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32524/34216 [46:20<02:24, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32529/34216 [46:20<02:24, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32534/34216 [46:20<02:23, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32539/34216 [46:20<02:23, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32544/34216 [46:20<02:22, 11.70it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32549/34216 [46:20<02:22, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32554/34216 [46:20<02:21, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32559/34216 [46:20<02:21, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32564/34216 [46:21<02:21, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32569/34216 [46:21<02:20, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32574/34216 [46:21<02:20, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32579/34216 [46:21<02:19, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32584/34216 [46:21<02:19, 11.71it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32589/34216 [46:21<02:18, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32594/34216 [46:21<02:18, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32599/34216 [46:21<02:17, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32604/34216 [46:21<02:17, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32609/34216 [46:22<02:17, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32614/34216 [46:22<02:16, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32619/34216 [46:22<02:16, 11.72it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32624/34216 [46:22<02:15, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32629/34216 [46:22<02:15, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32634/34216 [46:22<02:14, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32639/34216 [46:22<02:14, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32644/34216 [46:22<02:14, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32649/34216 [46:22<02:13, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32654/34216 [46:23<02:13, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32659/34216 [46:23<02:12, 11.73it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32664/34216 [46:23<02:12, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32669/34216 [46:23<02:11, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  95% 32674/34216 [46:23<02:11, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32679/34216 [46:23<02:10, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32684/34216 [46:23<02:10, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32689/34216 [46:23<02:10, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32694/34216 [46:23<02:09, 11.74it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32699/34216 [46:24<02:09, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32704/34216 [46:24<02:08, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32709/34216 [46:24<02:08, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32714/34216 [46:24<02:07, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32719/34216 [46:24<02:07, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32724/34216 [46:24<02:06, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32729/34216 [46:24<02:06, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32734/34216 [46:24<02:06, 11.75it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32739/34216 [46:24<02:05, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32744/34216 [46:25<02:05, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32749/34216 [46:25<02:04, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32754/34216 [46:25<02:04, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32759/34216 [46:25<02:03, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32764/34216 [46:25<02:03, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32769/34216 [46:25<02:03, 11.76it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32774/34216 [46:25<02:02, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32779/34216 [46:25<02:02, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32784/34216 [46:25<02:01, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32789/34216 [46:25<02:01, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32794/34216 [46:26<02:00, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32799/34216 [46:26<02:00, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32804/34216 [46:26<01:59, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32809/34216 [46:26<01:59, 11.77it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32814/34216 [46:26<01:59, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32819/34216 [46:26<01:58, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32824/34216 [46:26<01:58, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32829/34216 [46:26<01:57, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32834/34216 [46:27<01:57, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32839/34216 [46:27<01:56, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32844/34216 [46:27<01:56, 11.78it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32849/34216 [46:27<01:55, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32854/34216 [46:27<01:55, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32859/34216 [46:27<01:55, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32864/34216 [46:27<01:54, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32869/34216 [46:27<01:54, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32874/34216 [46:27<01:53, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32879/34216 [46:27<01:53, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32884/34216 [46:28<01:52, 11.79it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32889/34216 [46:28<01:52, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32894/34216 [46:28<01:52, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32899/34216 [46:28<01:51, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32904/34216 [46:28<01:51, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32909/34216 [46:28<01:50, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32914/34216 [46:28<01:50, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32919/34216 [46:28<01:49, 11.80it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32924/34216 [46:28<01:49, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32929/34216 [46:29<01:49, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32934/34216 [46:29<01:48, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32939/34216 [46:29<01:48, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32944/34216 [46:29<01:47, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32949/34216 [46:29<01:47, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32954/34216 [46:29<01:46, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32959/34216 [46:29<01:46, 11.81it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32964/34216 [46:29<01:45, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32969/34216 [46:29<01:45, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32974/34216 [46:30<01:45, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32979/34216 [46:30<01:44, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32984/34216 [46:30<01:44, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32989/34216 [46:30<01:43, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32994/34216 [46:30<01:43, 11.82it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 32999/34216 [46:30<01:42, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 33004/34216 [46:30<01:42, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 33009/34216 [46:30<01:42, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  96% 33014/34216 [46:30<01:41, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33019/34216 [46:30<01:41, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33024/34216 [46:31<01:40, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33029/34216 [46:31<01:40, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33034/34216 [46:31<01:39, 11.83it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33039/34216 [46:31<01:39, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33044/34216 [46:31<01:39, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33049/34216 [46:31<01:38, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33054/34216 [46:31<01:38, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33059/34216 [46:31<01:37, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33064/34216 [46:31<01:37, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33069/34216 [46:31<01:36, 11.84it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33074/34216 [46:32<01:36, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33079/34216 [46:32<01:35, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33084/34216 [46:32<01:35, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33089/34216 [46:32<01:35, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33094/34216 [46:32<01:34, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33099/34216 [46:32<01:34, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33104/34216 [46:32<01:33, 11.85it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33109/34216 [46:32<01:33, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33114/34216 [46:32<01:32, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33119/34216 [46:33<01:32, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33124/34216 [46:33<01:32, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33129/34216 [46:33<01:31, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33134/34216 [46:33<01:31, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33139/34216 [46:33<01:30, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33144/34216 [46:33<01:30, 11.86it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33149/34216 [46:33<01:29, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33154/34216 [46:33<01:29, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33159/34216 [46:33<01:29, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33164/34216 [46:34<01:28, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33169/34216 [46:34<01:28, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33174/34216 [46:34<01:27, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33179/34216 [46:34<01:27, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33184/34216 [46:34<01:26, 11.87it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33189/34216 [46:34<01:26, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33194/34216 [46:34<01:26, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33199/34216 [46:34<01:25, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33204/34216 [46:34<01:25, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33209/34216 [46:34<01:24, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33214/34216 [46:35<01:24, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33219/34216 [46:35<01:23, 11.88it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33224/34216 [46:35<01:23, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33229/34216 [46:35<01:23, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33234/34216 [46:35<01:22, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33239/34216 [46:35<01:22, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33244/34216 [46:35<01:21, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33249/34216 [46:35<01:21, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33254/34216 [46:35<01:20, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33259/34216 [46:36<01:20, 11.89it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33264/34216 [46:36<01:20, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33269/34216 [46:36<01:19, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33274/34216 [46:36<01:19, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33279/34216 [46:36<01:18, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33284/34216 [46:36<01:18, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33289/34216 [46:36<01:17, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33294/34216 [46:36<01:17, 11.90it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33299/34216 [46:36<01:17, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33304/34216 [46:37<01:16, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33309/34216 [46:37<01:16, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33314/34216 [46:37<01:15, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33319/34216 [46:37<01:15, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33324/34216 [46:37<01:14, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33329/34216 [46:37<01:14, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33334/34216 [46:37<01:14, 11.91it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33339/34216 [46:37<01:13, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33344/34216 [46:38<01:13, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33349/34216 [46:38<01:12, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33354/34216 [46:38<01:12, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  97% 33359/34216 [46:38<01:11, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33364/34216 [46:38<01:11, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33369/34216 [46:38<01:11, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33374/34216 [46:38<01:10, 11.92it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33379/34216 [46:38<01:10, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33384/34216 [46:38<01:09, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33389/34216 [46:39<01:09, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33394/34216 [46:39<01:08, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33399/34216 [46:39<01:08, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33404/34216 [46:39<01:08, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33409/34216 [46:39<01:07, 11.93it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33414/34216 [46:39<01:07, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33419/34216 [46:39<01:06, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33424/34216 [46:39<01:06, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33429/34216 [46:39<01:05, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33434/34216 [46:40<01:05, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33439/34216 [46:40<01:05, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33444/34216 [46:40<01:04, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33449/34216 [46:40<01:04, 11.94it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33454/34216 [46:40<01:03, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33459/34216 [46:40<01:03, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33464/34216 [46:40<01:02, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33469/34216 [46:40<01:02, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33474/34216 [46:40<01:02, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33479/34216 [46:41<01:01, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33484/34216 [46:41<01:01, 11.95it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33489/34216 [46:41<01:00, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33494/34216 [46:41<01:00, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33499/34216 [46:41<00:59, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33504/34216 [46:41<00:59, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33509/34216 [46:41<00:59, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33514/34216 [46:41<00:58, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33519/34216 [46:41<00:58, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33524/34216 [46:41<00:57, 11.96it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33529/34216 [46:42<00:57, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33534/34216 [46:42<00:56, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33539/34216 [46:42<00:56, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33544/34216 [46:42<00:56, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33549/34216 [46:42<00:55, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33554/34216 [46:42<00:55, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33559/34216 [46:42<00:54, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33564/34216 [46:42<00:54, 11.97it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33569/34216 [46:42<00:54, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33574/34216 [46:43<00:53, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33579/34216 [46:43<00:53, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33584/34216 [46:43<00:52, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33589/34216 [46:43<00:52, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33594/34216 [46:43<00:51, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33599/34216 [46:43<00:51, 11.98it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33604/34216 [46:43<00:51, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33609/34216 [46:43<00:50, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33614/34216 [46:43<00:50, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33619/34216 [46:44<00:49, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33624/34216 [46:44<00:49, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33629/34216 [46:44<00:48, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33634/34216 [46:44<00:48, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33639/34216 [46:44<00:48, 11.99it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33644/34216 [46:44<00:47, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33649/34216 [46:44<00:47, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33654/34216 [46:44<00:46, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33659/34216 [46:45<00:46, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33664/34216 [46:45<00:45, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33669/34216 [46:45<00:45, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33674/34216 [46:45<00:45, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33679/34216 [46:45<00:44, 12.00it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33684/34216 [46:45<00:44, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33689/34216 [46:45<00:43, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33694/34216 [46:45<00:43, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  98% 33699/34216 [46:45<00:43, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33704/34216 [46:46<00:42, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33709/34216 [46:46<00:42, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33714/34216 [46:46<00:41, 12.01it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33719/34216 [46:46<00:41, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33724/34216 [46:46<00:40, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33729/34216 [46:46<00:40, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33734/34216 [46:46<00:40, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33739/34216 [46:46<00:39, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33744/34216 [46:46<00:39, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33749/34216 [46:47<00:38, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33754/34216 [46:47<00:38, 12.02it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33759/34216 [46:47<00:38, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33764/34216 [46:47<00:37, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33769/34216 [46:47<00:37, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33774/34216 [46:47<00:36, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33779/34216 [46:47<00:36, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33784/34216 [46:47<00:35, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33789/34216 [46:47<00:35, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33794/34216 [46:48<00:35, 12.03it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33799/34216 [46:48<00:34, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33804/34216 [46:48<00:34, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33809/34216 [46:48<00:33, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33814/34216 [46:48<00:33, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33819/34216 [46:48<00:32, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33824/34216 [46:48<00:32, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33829/34216 [46:48<00:32, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33834/34216 [46:48<00:31, 12.04it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33839/34216 [46:49<00:31, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33844/34216 [46:49<00:30, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33849/34216 [46:49<00:30, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33854/34216 [46:49<00:30, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33859/34216 [46:49<00:29, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33864/34216 [46:49<00:29, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33869/34216 [46:49<00:28, 12.05it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33874/34216 [46:49<00:28, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33879/34216 [46:49<00:27, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33884/34216 [46:50<00:27, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33889/34216 [46:50<00:27, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33894/34216 [46:50<00:26, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33899/34216 [46:50<00:26, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33904/34216 [46:50<00:25, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33909/34216 [46:50<00:25, 12.06it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33914/34216 [46:50<00:25, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33919/34216 [46:50<00:24, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33924/34216 [46:50<00:24, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33929/34216 [46:51<00:23, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33934/34216 [46:51<00:23, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33939/34216 [46:51<00:22, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33944/34216 [46:51<00:22, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33949/34216 [46:51<00:22, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33954/34216 [46:51<00:21, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33959/34216 [46:51<00:21, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33964/34216 [46:51<00:20, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33969/34216 [46:51<00:20, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33974/34216 [46:52<00:20, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33979/34216 [46:52<00:19, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33984/34216 [46:52<00:19, 12.08it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33989/34216 [46:52<00:18, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33994/34216 [46:52<00:18, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 33999/34216 [46:52<00:17, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34004/34216 [46:52<00:17, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34009/34216 [46:52<00:17, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34014/34216 [46:52<00:16, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34019/34216 [46:53<00:16, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34024/34216 [46:53<00:15, 12.09it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34029/34216 [46:53<00:15, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34034/34216 [46:53<00:15, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34039/34216 [46:53<00:14, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4:  99% 34044/34216 [46:53<00:14, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34049/34216 [46:53<00:13, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34054/34216 [46:53<00:13, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34059/34216 [46:53<00:12, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34064/34216 [46:54<00:12, 12.10it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34069/34216 [46:54<00:12, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34074/34216 [46:54<00:11, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34079/34216 [46:54<00:11, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34084/34216 [46:54<00:10, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34089/34216 [46:54<00:10, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34094/34216 [46:54<00:10, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34099/34216 [46:54<00:09, 12.11it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34104/34216 [46:54<00:09, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34109/34216 [46:55<00:08, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34114/34216 [46:55<00:08, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34119/34216 [46:55<00:08, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34124/34216 [46:55<00:07, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34129/34216 [46:55<00:07, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34134/34216 [46:55<00:06, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34139/34216 [46:55<00:06, 12.12it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34144/34216 [46:55<00:05, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34149/34216 [46:56<00:05, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34154/34216 [46:56<00:05, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34159/34216 [46:56<00:04, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34164/34216 [46:56<00:04, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34169/34216 [46:56<00:03, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34174/34216 [46:56<00:03, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34179/34216 [46:56<00:03, 12.13it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34184/34216 [46:56<00:02, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34189/34216 [46:56<00:02, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34194/34216 [46:57<00:01, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34199/34216 [46:57<00:01, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34204/34216 [46:57<00:00, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34209/34216 [46:57<00:00, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.710]\n","Epoch 4: 100% 34216/34216 [46:57<00:00, 12.14it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.680]\n","                                                   \u001b[AEpoch 4, global step 152254: val_loss reached 8.68267 (best 8.68267), saving model to \"/gdrive/MyDrive/Colab_Notebooks/KoBART-summarization/logs/model_chp/epoch=04-val_loss=8.683.ckpt\" as top 3\n","Epoch 4: 100% 34216/34216 [47:15<00:00, 12.07it/s, loss=8.21, v_num=5, train_loss=8.200, val_loss=8.680]\n","Saving latest checkpoint...\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}