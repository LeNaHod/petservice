{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0403377f"},"outputs":[],"source":["import os\n","import io\n","from zipfile import ZipFile\n","import pandas as pd\n","import tensorflow as tf\n","from PIL import Image\n","import numpy as np\n","import random\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import cv2\n","from sklearn.metrics import *\n","import os\n","import zipfile\n","from google.colab import drive\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"id":"0403377f"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.rcParams['font.family'] = 'NanumGothic'\n","ratio = [6879/27520*100, 6877/27520*100, 6886/27520*100, 6885/27520*100]\n","labels = ['무증상', '초기', '비성숙', '성숙']\n","\n","plt.pie(ratio, labels=labels, autopct='%.2f%%')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"id":"mUzaOFwlXqql","executionInfo":{"status":"ok","timestamp":1674456479461,"user_tz":-540,"elapsed":461,"user":{"displayName":"박준원","userId":"13178446148627772304"}},"outputId":"6b31c7ee-2b0e-48a1-d5a9-c6dae1e59e44"},"id":"mUzaOFwlXqql","execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.font_manager:findfont: Font family ['NanumGothic'] not found. Falling back to DejaVu Sans.\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47924 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51613 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49345 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52488 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44592 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48708 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49457 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49689 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47924 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51613 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49345 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52488 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44592 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48708 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49457 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49689 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"lx-dh941XrMc"},"id":"lx-dh941XrMc","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23367,"status":"ok","timestamp":1673917251091,"user":{"displayName":"박준원","userId":"13178446148627772304"},"user_tz":-540},"id":"MKd4bLhMY9Kb","outputId":"943017a0-f673-4ca6-c046-56fd7a1985fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"],"id":"MKd4bLhMY9Kb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vr5XgKxgZUJF"},"outputs":[],"source":["local_zip = '/content/drive/MyDrive/eyes_train.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/content')\n","zip_ref.close()"],"id":"Vr5XgKxgZUJF"},{"cell_type":"code","execution_count":null,"metadata":{"id":"D_pWqLysByXk"},"outputs":[],"source":["#백내장 무 폴더 정리\n","img_dir0 = '/content/eyes_train/eye_train/0'\n","img0 = os.listdir(img_dir0)\n","image0 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img0))\n","label0 = list(filter(lambda x : x.find('.json')!=-1,img0))\n","image_0 = []\n","image_label0 = []\n","for i in image0:\n","    img = np.array(Image.open('/content/eyes_train/eye_train/0/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im0 = cv2.resize(im,(224,224))\n","    image_0.append(im0)\n","    image_label0.append(0)"],"id":"D_pWqLysByXk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ5HCPjhGPVH"},"outputs":[],"source":["#백내장 초기 폴더 정리\n","img_dir1 = '/content/eyes_train/eye_train/1'\n","img1 = os.listdir(img_dir1)\n","image1 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img1))\n","label1 = list(filter(lambda x : x.find('.json')!=-1,img1))\n","for i in image1:\n","    img = np.array(Image.open('/content/eyes_train/eye_train/1/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im1 = cv2.resize(im,(224,224))\n","    image_0.append(im1)\n","    image_label0.append(1)"],"id":"kJ5HCPjhGPVH"},{"cell_type":"code","source":["len(image_0)"],"metadata":{"id":"7GQHgBu9JD8A","executionInfo":{"status":"ok","timestamp":1673828077993,"user_tz":-540,"elapsed":24,"user":{"displayName":"박준원","userId":"13178446148627772304"}},"outputId":"26a4b992-463d-4357-90d1-b9b7bbb680c9","colab":{"base_uri":"https://localhost:8080/"}},"id":"7GQHgBu9JD8A","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13756"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNrcYry6GuX0"},"outputs":[],"source":["#백내장 비성숙 폴더 정리\n","img_dir2 = '/content/eyes_train/eye_train/2'\n","img2 = os.listdir(img_dir2)\n","image2 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img2))\n","label2 = list(filter(lambda x : x.find('.json')!=-1,img2))\n","for i in image2:\n","    img = np.array(Image.open('/content/eyes_train/eye_train/2/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im2 = cv2.resize(im,(224,224))\n","    image_0.append(im2)\n","    image_label0.append(2)"],"id":"iNrcYry6GuX0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"h76Hzvl8HRqK"},"outputs":[],"source":["#백내장 성숙 폴더 정리\n","img_dir3 = '/content/eyes_train/eye_train/3'\n","img3 = os.listdir(img_dir3)\n","image3 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img3))\n","label3 = list(filter(lambda x : x.find('.json')!=-1,img3))\n","for i in image3:\n","    img = np.array(Image.open('/content/eyes_train/eye_train/3/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im3 = cv2.resize(im,(224,224))\n","    image_0.append(im3)\n","    image_label0.append(3)"],"id":"h76Hzvl8HRqK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ff23a93"},"outputs":[],"source":["x = np.array(image_0)\n","y = np.array(image_label0)"],"id":"9ff23a93"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULV80pESE8iq"},"outputs":[],"source":["#원핫 인코딩\n","y = np_utils.to_categorical(y)"],"id":"ULV80pESE8iq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7912f59"},"outputs":[],"source":["#데이터 분할\n","x_train, x_val, y_train, y_val = train_test_split(x, y, shuffle =True, test_size = 0.2, random_state = 123)"],"id":"d7912f59"},{"cell_type":"code","source":["pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQux2jCgPkaO","executionInfo":{"status":"ok","timestamp":1673917358706,"user_tz":-540,"elapsed":5320,"user":{"displayName":"박준원","userId":"13178446148627772304"}},"outputId":"26296ba9-31ec-4e1e-ebe4-7c46f7280af4"},"id":"hQux2jCgPkaO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow_addons\n","Successfully installed tensorflow_addons-0.19.0\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import layers\n","import math\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D,MaxPool2D, Dense, Flatten, BatchNormalization, Activation\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.nn import silu"],"metadata":{"id":"qkwIFDeHPilu"},"id":"qkwIFDeHPilu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["se_ratio = 4\n","expand_ratio = 6\n","width_coefficient = 1.4\n","depth_coefficient = 1.8\n","default_resolution = 380\n","input_channels = 3\n","depth_divisor= 8 \n","dropout_rate = 0.4\n","drop_connect_rate = 0.2"],"metadata":{"id":"meRuoRYsPin1"},"id":"meRuoRYsPin1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["kernel_size = [3,3,5,3,5,5,3]\n","num_repeat = [1,2,2,3,3,4,1]\n","output_filters = [16,24,40,80,112,192,320]\n","strides = [1,2,2,2,1,2,1]\n","MBConvBlock_1_True  =  [True,False,False,False,False,False,False]"],"metadata":{"id":"9MOSAq2YPiqV"},"id":"9MOSAq2YPiqV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def round_repeats(repeats, depth_coefficient):\n","    return int(math.ceil(depth_coefficient * repeats))"],"metadata":{"id":"vGauMuNSPis5"},"id":"vGauMuNSPis5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def round_filters(filters, width_coefficient, depth_divisor):\n","    filters *= width_coefficient\n","    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n","    new_filters = max(depth_divisor, new_filters)\n","    if new_filters < 0.9 * filters:\n","        new_filters += depth_divisor\n","    return int(new_filters)"],"metadata":{"id":"TlI8OhqZPiu-"},"id":"TlI8OhqZPiu-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DropConnect(layers.Layer):\n","    def __init__(self, drop_connect_rate=0.0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.drop_connect_rate = drop_connect_rate\n","\n","    def call(self, inputs, training):\n","        def _drop_connect():\n","            keep_prob = 1.0 - self.drop_connect_rate\n","\n","            batch_size = tf.shape(inputs)[0]\n","            random_tensor = keep_prob\n","            random_tensor += K.random_uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n","            binary_tensor = tf.floor(random_tensor)\n","            output = tf.math.divide(inputs, keep_prob) * binary_tensor\n","            return output\n","\n","        return K.in_train_phase(_drop_connect, inputs, training=training)"],"metadata":{"id":"WNiipB03PrHO"},"id":"WNiipB03PrHO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def SEBlock(filters,reduced_filters):\n","    def _block(inputs):\n","        x = layers.GlobalAveragePooling2D()(inputs)\n","        x = layers.Reshape((1,1,x.shape[1]))(x)\n","        x = layers.Conv2D(reduced_filters, 1, 1)(x)\n","        x = tfa.activations.mish(x)\n","        x = layers.Conv2D(filters, 1, 1)(x)\n","        x = layers.Activation('sigmoid')(x)\n","        x = layers.Multiply()([x, inputs])\n","        return x\n","    return _block"],"metadata":{"id":"MaqawEfhPrJd"},"id":"MaqawEfhPrJd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def MBConvBlock(x,kernel_size, strides,drop_connect_rate,output_channels,MBConvBlock_1_True=False):\n","    output_channels = round_filters(output_channels,width_coefficient,depth_divisor)\n","    if MBConvBlock_1_True:\n","        block = layers.DepthwiseConv2D(kernel_size, strides,padding='same', use_bias=False)(x)\n","        block = layers.BatchNormalization()(block)\n","        block = tfa.activations.mish(block)\n","        block = SEBlock(x.shape[3],x.shape[3]/se_ratio)(block)\n","        block = layers.Conv2D(output_channels, (1,1), padding='same', use_bias=False)(block)\n","        block = layers.BatchNormalization()(block)\n","        return block\n","\n","    channels = x.shape[3]\n","    expand_channels = channels * expand_ratio\n","    block = layers.Conv2D(expand_channels, (1,1), padding='same', use_bias=False)(x)\n","    block = layers.BatchNormalization()(block)\n","    block = tfa.activations.mish(block)\n","    block = layers.DepthwiseConv2D(kernel_size, strides,padding='same', use_bias=False)(block)\n","    block = layers.BatchNormalization()(block)\n","    block = tfa.activations.mish(block)\n","    block = SEBlock(expand_channels,channels/se_ratio)(block)\n","    block = layers.Conv2D(output_channels, (1,1), padding='same', use_bias=False)(block)\n","    block = layers.BatchNormalization()(block)\n","    if x.shape[3] == output_channels:\n","        block = DropConnect(drop_connect_rate)(block)\n","        block = layers.Add()([block, x])\n","    return block"],"metadata":{"id":"2u2cb2YHPrLc"},"id":"2u2cb2YHPrLc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def EffNet(num_classes):\n","    x_input = layers.Input(shape=(224,224,3))    \n","    x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), (3,3), 2,padding='same', use_bias=False)(x_input)\n","    x = layers.BatchNormalization()(x)\n","    x = tfa.activations.mish(x)\n","    num_blocks_total = sum(num_repeat)\n","    block_num = 0\n","    for i in range(len(kernel_size)):\n","        round_num_repeat = round_repeats(num_repeat[i], depth_coefficient)\n","        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n","        x = MBConvBlock(x,kernel_size[i],strides[i],drop_rate,output_filters[i],MBConvBlock_1_True = MBConvBlock_1_True[i])\n","        block_num += 1\n","        if round_num_repeat > 1:\n","            for bidx in range(round_num_repeat - 1):\n","                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n","                x = MBConvBlock(x,kernel_size[i],1,drop_rate,output_filters[i],MBConvBlock_1_True = MBConvBlock_1_True[i])\n","                block_num += 1\n","    x = layers.Conv2D(round_filters(1280, width_coefficient, depth_divisor), 1,padding='same',use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = tfa.activations.mish(x)\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dropout(dropout_rate)(x)\n","    x = layers.Dense(num_classes,activation='softmax')(x)\n","    model = tf.keras.models.Model(inputs=x_input, outputs=x)\n","    return model"],"metadata":{"id":"KiEXznzyPrNe"},"id":"KiEXznzyPrNe","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = EffNet(4)"],"metadata":{"id":"OBTMJy1ePrPe"},"id":"OBTMJy1ePrPe","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXeZI_9uOVx1"},"outputs":[],"source":["rmsprop = RMSprop(\n","    learning_rate=0.0001,\n",")"],"id":"JXeZI_9uOVx1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6c075ea3","outputId":"94bb8fc8-a1a3-40f8-b32f-d773b0551412","executionInfo":{"status":"error","timestamp":1673917638008,"user_tz":-540,"elapsed":29786,"user":{"displayName":"박준원","userId":"13178446148627772304"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-ecff9e22c25a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 손실 함수 : sparse_categorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics = ['accuracy']) # 모니터링 할 평가지표 : \n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(x_train, y_train, \n\u001b[0m\u001b[1;32m      5\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/batch_normalization_128/FusedBatchNormV3' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-26-ecff9e22c25a>\", line 4, in <module>\n      history = model.fit(x_train, y_train,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py\", line 750, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py\", line 594, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py\", line 571, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_1/batch_normalization_128/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,672,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_128/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_63876]"]}],"source":["model.compile(optimizer=Adam(1e-3), # 옵티마이저 : rmsprop\n","              loss = 'categorical_crossentropy', # 손실 함수 : sparse_categorical_crossentropy\n","              metrics = ['accuracy']) # 모니터링 할 평가지표 : \n","history = model.fit(x_train, y_train, \n","                      epochs = 10, \n","                      batch_size = 32, \n","                      validation_data = (x_val, y_val))"],"id":"6c075ea3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ab4c319c"},"outputs":[],"source":["model.summary()"],"id":"ab4c319c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ace5a8ef"},"outputs":[],"source":["# 정확도와 로스 그래프\n","his_dict = history.history\n","loss = his_dict['loss']\n","val_loss = his_dict['val_loss'] \n","\n","epochs = range(1, len(loss) + 1)\n","fig = plt.figure(figsize = (10, 5))\n","\n","# 훈련 및 검증 손실 그리기\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')\n","ax1.plot(epochs, val_loss, color = 'orange', label = 'val_loss')\n","ax1.set_title('train and val loss')\n","ax1.set_xlabel('epochs')\n","ax1.set_ylabel('loss')\n","ax1.legend()\n","\n","acc = his_dict['accuracy']\n","val_acc = his_dict['val_accuracy']\n","\n","# 훈련 및 검증 정확도 그리기\n","ax2 = fig.add_subplot(1, 2, 2)\n","ax2.plot(epochs, acc, color = 'blue', label = 'train_acc')\n","ax2.plot(epochs, val_acc, color = 'orange', label = 'val_acc')\n","ax2.set_title('train and val acc')\n","ax2.set_xlabel('epochs')\n","ax2.set_ylabel('acc')\n","ax2.legend()\n","\n","plt.show()"],"id":"ace5a8ef"},{"cell_type":"code","execution_count":null,"metadata":{"id":"faa8d401"},"outputs":[],"source":["# 6. 모델 저장하기\n","from tensorflow.keras.models import load_model\n","model.save('/content/drive/MyDrive/EfficientNetB4_6000_tuning11.h5')"],"id":"faa8d401"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCgrinsJTahp"},"outputs":[],"source":["#정확도 f1\n","from sklearn.metrics import *\n","def get_clf_eval(y_test,pred): \n","  f1 = f1_score(y_test,pred,average=\"macro\") \n","  acc = accuracy_score(y_val,predict)   \n","  loss = model.evaluate(x_val, y_val, batch_size=32)\n","  print('정확도 :',acc)\n","  print('f1 score:',f1)\n","  print('loss :',loss )"],"id":"GCgrinsJTahp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_qj9JZ_Ti91"},"outputs":[],"source":["predcit = model.predict(x_val)\n","predict = []\n","for i in np.arange(len(predcit)):\n","  labels = np.argmax(predcit[i])\n","  predict.append(labels)\n","predict = np.array(predict)\n","predict = np_utils.to_categorical(predict)"],"id":"Y_qj9JZ_Ti91"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYwzwM5yTmIp"},"outputs":[],"source":["#EfficientNetB4\n","get_clf_eval(y_val,predict)"],"id":"bYwzwM5yTmIp"},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","model = tf.keras.models.load_model('/content/drive/MyDrive/EfficientNetB4_6000_tuning11.h5')"],"metadata":{"id":"GP35puZ1t2tk"},"id":"GP35puZ1t2tk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["local_zip = '/content/drive/MyDrive/eyes_validation.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/content')\n","zip_ref.close()"],"metadata":{"id":"xJalpRqIuG5x"},"id":"xJalpRqIuG5x","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pred_label(pred):\n","  img = cv2.imread(pred, cv2.IMREAD_COLOR)\n","  im = cv2.resize(img,(224,224))\n","  pred_image = np.expand_dims(im, axis=0)\n","  predict = model.predict(pred_image)\n","  predict_image = np.argmax(predict)\n","  if predict_image == 0:\n","      print('백내장이 아닙니다.')\n","  elif predict_image == 1:\n","      print('백내장 초기단계입니다.')\n","  elif predict_image == 2:\n","      print('백내장 중간 단계입니다.')\n","  else:\n","      print('백내장 심해요')"],"metadata":{"id":"1xOsxX7Jub54"},"id":"1xOsxX7Jub54","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#백내장 무 폴더 정리\n","img_dir0 = '/content/eyes_validation/eye_validation/0'\n","img0 = os.listdir(img_dir0)\n","image0 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img0))\n","label0 = list(filter(lambda x : x.find('.json')!=-1,img0))\n","image_0 = []\n","image_label0 = []\n","for i in image0:\n","    img = np.array(Image.open('/content/eyes_validation/eye_validation/0/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im0 = cv2.resize(im,(224,224))\n","    image_0.append(im0)\n","    image_label0.append(0)"],"metadata":{"id":"IklsAbXKulEQ"},"id":"IklsAbXKulEQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#백내장 초기 폴더 정리\n","img_dir1 = '/content/eyes_validation/eye_validation/1'\n","img1 = os.listdir(img_dir1)\n","image1 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img1))\n","label1 = list(filter(lambda x : x.find('.json')!=-1,img1))\n","for i in image1:\n","    img = np.array(Image.open('/content/eyes_validation/eye_validation/1/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im1 = cv2.resize(im,(224,224))\n","    image_0.append(im1)\n","    image_label0.append(1)"],"metadata":{"id":"ex40Svk1u5Bc"},"id":"ex40Svk1u5Bc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#백내장 비성숙 폴더 정리\n","img_dir2 = '/content/eyes_validation/eye_validation/2'\n","img2 = os.listdir(img_dir2)\n","image2 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img2))\n","label2 = list(filter(lambda x : x.find('.json')!=-1,img2))\n","for i in image2:\n","    img = np.array(Image.open('/content/eyes_validation/eye_validation/2/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im2 = cv2.resize(im,(224,224))\n","    image_0.append(im2)\n","    image_label0.append(2)"],"metadata":{"id":"9aKYI2wiu5EO"},"id":"9aKYI2wiu5EO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#백내장 성숙 폴더 정리\n","img_dir3 = '/content/eyes_validation/eye_validation/3'\n","img3 = os.listdir(img_dir3)\n","image3 = list(filter(lambda x: x.find('.jpg') != -1 or x.find('.png') != -1, img3))\n","label3 = list(filter(lambda x : x.find('.json')!=-1,img3))\n","for i in image3:\n","    img = np.array(Image.open('/content/eyes_validation/eye_validation/3/{}'.format(i)))\n","    im = img[50:350,50:350]\n","    im3 = cv2.resize(im,(224,224))\n","    image_0.append(im3)\n","    image_label0.append(3)"],"metadata":{"id":"0FRxRtFsu5Gq"},"id":"0FRxRtFsu5Gq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_label('/content/eyes_validation/eye_validation/0/{}'.format(image0[40]))"],"metadata":{"id":"ZXlqn4-g1Sar"},"id":"ZXlqn4-g1Sar","execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1LF0-WOjXZ5lPS07G26Em7GLrHWVl0kZk","timestamp":1673916976017},{"file_id":"1EvqkPZzkH7NP5xz6_ZitI9Ttp_I8oL-y","timestamp":1673827890054},{"file_id":"1yLCfzMEA-lq8rvi3CO6uBorUflR5z_nX","timestamp":1673500019406},{"file_id":"1qjO6e-aiGAKah9apVkOEf0ppjTDBKsdH","timestamp":1673394405663},{"file_id":"1FUiqi91sy2zbvqi4isS75vy-OVn8L1-F","timestamp":1673339006687},{"file_id":"1TcmlFConIROmC5HX9CCLpC10MREBR41T","timestamp":1673314675033},{"file_id":"1DQIi6kJEUE77Z0vTw6pS7k9cBoFuby3_","timestamp":1672917123935},{"file_id":"1HiOPnSrKz18GxzzSRsJkxyZjDCZxzNTw","timestamp":1672909382021},{"file_id":"1Syf7lFpwp2OZRMexYV0SELXNwMyBQ9ur","timestamp":1672732366219},{"file_id":"1tdGegwZ7kMdQ8a5oRZF0bVZ_FSZ_XmMX","timestamp":1672729920760},{"file_id":"12dyzlz-sWPzN_baEMBUcCwsI8Z30vmjr","timestamp":1672726913788},{"file_id":"1xvk-Qtl6KiSozNeUi8TqqtKkwDNNMNTD","timestamp":1672705534688}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}